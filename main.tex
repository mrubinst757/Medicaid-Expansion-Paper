\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
%\usepackage{nips_2017}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{booktabs}
\usepackage{float}
\usepackage{amsmath}
\usepackage{psfrag}
\usepackage{epsf}
\usepackage{enumerate}

%\bibliographystyle{apalike}

%\bibliographystyle{unsrt} % Use for unsorted references 
\newcommand{\blind}{0}

%\bibliographystyle{plainnat} % use this to have URLs listed in References

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

% Title Page

\bibliographystyle{natbib}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\if0\blind
{
  \title{\bf The Effect of Medicaid Expansion on Non-Elderly Adult Uninsurance Rates Among States that did not Expand Medicaid}
  \author{Max Rubinstein \hspace{.2cm}\\
    and \\
    Amelia Haviland \\ \\
    Heinz College, Carnegie Mellon University}
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Title}
\end{center}
  \medskip
} \fi

\bigskip

\begin{abstract}

We estimate the foregone effect of Medicaid expansion on non-elderly adult uninsurance rates in states that did not expand Medicaid in 2014 using a novel adaptation of Stable Balancing Weights \cite{zubizarreta2015stable} and the synthetic controls approach (\cite{abadie2010synthetic}). This paper has both a methodological and a substantive contributions. From a substantive standpoint, previous literature focuses on estimating treatment effects among states that did expand Medicaid. However, we believe these effects likely differ: existing literature suggests that Medicaid take-up rates are lower among more conservative states. Because Republicans tended to disproportionately govern states that chose not to expand Medicaid, we hypothesize that the effect on uninsurance rates should be smaller in absolute magnitude in non-expansion states compared to expansion states. Using aggregated data from the American Communities Survey (ACS), we estimate the effect on non-expansion states by re-weighting expansion regions to approximately balance the covariate distribution from non-expansion regions in an extension of the ``synthetic controls'' framework. We also contribute to the literature on balancing weights by accounting for hierarchical nature of the data and measurement error in the covariates in our estimation. We find that Medicaid expansion would have reduced the non-elderly adult uninsurance rate by XXX percentage points (XXX, XXX). These results are indeed smaller in absolute magnitude than existing estimates of the treatment effect on expansion states. We provide evidence that factors associated with Republican governance may drive this differential.

\end{abstract}

\noindent%
{\it Keywords:} Synthetic controls, balancing weights, measurement error, treatment effect on the controls, Medicaid expansion, uninsurance rates
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\maketitle

\section{Introduction}

The 2010 Affordable Care Act (ACA) required states to expand their Medicaid programs by 2014 to offer coverage to all adults with incomes at or below 138 percent of the federal poverty level (FPL). The United States Supreme Court ruled this requirement unconstitutional in 2012, allowing states to decide whether to expand Medicaid coverage. In 2014, twenty-six states and the District of Columbia expanded their Medicaid programs. From 2015 through 2019 an additional ten states elected to expanded their Medicaid programs (\cite{KFF}). This first wave of expansions in 2014 enabled researchers to examine the effects of Medicaid expansion by using expansion states as ``treated'' states, and non-expansion states as ``control'' states. Our goal is to model the effect of 2014 Medicaid expansion on non-elderly adult uninsurance rates among states that did not expand Medicaid.

We predict that the treatment effect on non-expansion effect will be smaller in absolute magnitude than in states that expanded Medicaid in 2014. Medicaid take-up rates are lower than 100 percent and historically have varied across states (\cite{sommers2012understanding}). This variation is partly a function of state discretion in administering programs: for example, program outreach, citizenship verification policies, and application processes differ across states (\cite{courtemanche2017early}). Here we consider how political composition may have driven differences in take-up rates between states. Prior to the 2014 Medicaid expansion, \cite{sommers2012understanding} found that conservative political ideology was associated with lower Medicaid enrollment take-up rates, even after controlling for a variety of correlated policies. Most importantly, political ideology appears to have largely driven a state's decision to expand Medicaid in 2014. Figure \ref{fig1} plots a measure of each state's 2013 institutional ideology by their Medicaid expansion status (\cite{fording}). Higher values of this score correspond to more liberal government institutions. The red dashed line indicates the mean expansion state score and the gray dashed line indicates the mean non-expansion state score. Figure \ref{fig1} illustrates that non-expansion states are more conservative than expansion states.  If these differential take-up rates observed by \cite{sommers2012understanding} continue to hold post-expansion, we should expect treatment effects on non-expansion states to be smaller in absolute magnitude than treatment effects on expansion states. 

\begin{figure}
    \begin{center}
    \includegraphics[scale=0.7]{01_Plots/}
    \caption{Government ideology and Medicaid expansion}
    \label{fig1}
    \end{center}
\end{figure}

This paper makes several methodological contributions. First, we extend the ``synthetic controls'' framework to estimate the treatment effect on the controls (ETC) and to clarify the required assumptions. While balancing on pre-treatment outcomes alone arguably suffices for some synthetic control applications (see, eg, \cite{botosaru2017role}), here we want to estimate treatment response. We therefore assume no unmeasured confounding given a rich covariate set and a linear and additive outcome model that accounts for all interactions between treatment and the covariates. Secondly, we use an implementation of Stable Balancing Weights (\cite{zubizarreta2015stable}) to estimate a set of positive weights to weight the expansion regions to approximately match the covariate distribution of the non-expansion regions. To account for remaining imbalances in the covariates, we also augment these weights with a regression-model following \cite{ben2018augmented}.

Our second contribution is to modify Stable Balancing Weights (SBW) for this setting. In particular, the SBW objective performs well assuming independent data with no measurement error. However, we use data from the American Communities Survey (ACS) aggregated to the consistent public use microdata area (CPUMA) level. These regions nest within states, and using these smaller regions allows us to get better balance on our covariates. However, as a result, our data both has a hierarchical structure (regions within states) and, because our region-level covariates are estimated from underlying survey data, we also have measurement error in the covariates which may bias our treatment effect estimates. We propose a modification of the SBW objective function to account for the hierarchical nature of the data. We leverage the replicate survey weights provided in the ACS data to estimate the covariance matrix associated with this variability and use this information to correct for this bias, following the regression calibration literature CITE. This is the first study we are aware of that attempts to correct for sampling variability in the covariates when using balancing weights. 

The remainder of this paper has the following structure. Section II provides an overview of the data and defines the study period, outcome, covariates, and treatment. Section III discusses our methods, beginning by defining our target estimand, and then outlining our identification, estimation, and inferential procedures. Section IV presents our primary results and sensitivity analyses. Section V provides a brief discussion of the policy relevance of our findings, and Section VI contains a brief concluding summary of the paper. Supplemental materials may be found in the Appendices.

\section{Data}

Our data source is the annual household and person public use microdata files from the American Community Survey (ACS) from 2011 through 2014. The ACS is an annual survey of approximately three million individuals across the United States. The public use microdata files include information on individuals in geographic areas greater than 65,000 people. The smallest geographic unit contained in these data are public-use microdata areas (PUMAs), arbitrary boundaries that nest within states but not within counties or other more commonly used geographic units. One limitation of these data is a 2012 change in the PUMA boundaries, which do not overlap well with the previous boundaries. As a result, the smallest possible geographic areas that nest both PUMA coding systems are known as consistent PUMAs (CPUMAs). The United States contain 1,075 total CPUMAs, with states ranging from having one CPUMA (South Dakota, Montana, and Idaho) to 123 CPUMAs (New York). The total number of sampled individuals per CPUMA in any year during our study period ranged from 531 (representing an area of approximately 96,000 individuals) to 49,046 (representing over 4.5 million individuals). The median sample size for a given CPUMA across the four years of our study is XXX.

\subsection{Study period}

We begin our analysis in 2011 following \cite{courtemanche2017early}, who note that several other aspects of the ACA were implemented in 2010 -- including the provision allowing for dependent coverage until age 26, and the elimination of co-payments for preventative care -- likely induced differential shocks across states. We also restrict our post-treatment period to 2014 only: several additional states expanded Medicaid in 2015, including Indiana, Michigan, and Pennsylvania. However, these states did not expand Medicaid contemporaneously with the 2014 ACA provisions. Without additional assumptions, this second-year expansion therefore represents a different causal estimand. 

\subsection{Covariates}

We use the underlying individual-level ACS survey data and accompanying survey weights to aggregate the data at the CPUMA level. We choose our covariates to approximately align with those considered in \cite{courtemanche2017early} and that believe are potential confounders. Because we are ultimately interested in calculating rates, these variables include both counts that we use for the numerators and denominators of the corresponding rates. 

The denominator counts include: total non-elderly adult population for each year 2011-2014; total labor force for each year 2011-2013; and the total number of households averaged from 2011-2013. We then calculate the total number of: females; whites; people born outside of the United States; citizens; people with less than high school education, high school degrees, some college, or college graduates or higher; people living under 138 percent of the FPL, between 139 and 299 percent, 300 and 499 percent, and more than 500 percent; total number aged 19-29, 30-39, 40-49, 50-64; households with one or more children, no information about children reported. We then average these counts from 2011-2013. For each individual year from 2011-2013, we also calculate the total number of people who were: unemployed, uninsured, and in the labor force at the time of the survey (calculated among all non-elderly adults). We also Census data to calculate the approximate percentage of people living within an ``urban'' area for each CPUMA (\cite{census}). Finally, we include three state-level covariates reflecting the partisan composition of each state's government in 2013. Specifically, we include an indicator for having a Republican governor, an indicator for Republican control over the lower legislative chamber, and an indicator for Republican control over both chambers of the legislature and the governorship.\footnote{Nebraska is the only state with a unicameral legislature; moreover, the legislature is technically non-partisan. We nevertheless classified them as having a Republican control of the legislature.} 

\subsection{Outcome}

Our primary outcome of interest $Y$ is the non-elderly adult uninsurance rate in 2014. We might consider take-up rates among the Medicaid-eligible population to be a more natural outcome. However, we choose the non-elderly adult uninsurance rate for two reasons, one theoretic and one practical. First, Medicaid eligibility in the post-period is likely endogenous: Medicaid expansion may affect an individual's income and poverty levels, which define Medicaid eligibility. A second reason is to align our study to compare our results with the existing literature, and this is the outcome that \cite{courtemanche2017early} use. One drawback of using this outcome is that the simultaneous adoption of other ACA provisions in 2014 more clearly affects this rate in a way that a more targeted group might not.

\subsection{Treatment assignment}

While some states expanded Medicaid and other states did not, in reality assigning a binary treatment status simplifies a more complex reality. There are three reasons to be cautious about this simplification. First, states differed substantially in pre-existing Medicaid coverage policies: with perfect data we might consider Medicaid expansion as a continuous treatment with values proportional to the number of newly eligible individuals. The challenge though is correctly identifying newly eligible individuals in the data (see \cite{frean2017premium}, who attempt to address this). Second, \cite{frean2017premium} note that five states (California, Connecticut, Minnesota, New Jersey, and Washington) and the District of Columbia adopted partial limited Medicaid expansions prior to 2014. \cite{kaestner2017effects} and \cite{courtemanche2017early} also consider Arizona, Colorado, Hawaii, Illinois, Iowa, Maryland, and Oregon to have had early expansions. Lastly, timing is an issue: among the states that expanded Medicaid in 2014, Michigan's expansion did not go into effect until April 2014, while New Hampshire's expansion did not occur until September 2014.

Our primary analysis excludes New York, Vermont, Massachusetts, Delaware, and the District of Columbia from our pool of expansion states, because these states had comparable Medicaid coverage policies prior to 2014 (\cite{kaestner2017effects}). We also exclude New Hampshire because it did not expand Medicaid until September 2014. While Michigan expanded Medicaid in April 2014, we leave this state in our treated pool. We consider the remaining expansion states as ``treated'' and the non-expansion states as ``control'' states. We later consider the sensitivity of our results to these classifications by removing the early expansion states noted by \cite{frean2017premium}. Our primary classification of expansion and non-expansion states is unique among similar studies: \cite{courtemanche2017early} classifies all expansion states as treated, and all non-expansion states as control. \cite{frean2017premium} exclude Massachusetts from expansion states. Lastly, \cite{kaestner2017effects} include Delaware, the District of Columbia, Massachusetts, New York, and Vermont as control states. Our final dataset contains aggregated counts for all of the above variables for 925 CPUMAs in our non-expansion and our pool of expansion states. 414 CPUMAs were in non-expansion states and 511 CPUMAs were in expansion states. When we exclude the early expansion states, we are left with XXX CPUMAs in the expansion region.

\section{Methods}
\label{sec:methods}

In this section we formally present our causal estimand, identifying assumptions, estimation strategy, and inferential procedure. Additional details are available in the Appendix.

\subsection{Estimand}

We seek to estimate the average effect of 2014 Medicaid expansion would have had on the non-elderly adult uninsurance rate in states that did not expand Medicaid.\footnote{We condition on the observed treatment assignment and therefore treat this variable as fixed in our analysis.} The 2014 Medicaid expansion occurred simultaneously with the implementation of several other major ACA provisions, including (but not limited to) the creation of the ACA-marketplace exchanges, the individual mandate, health insurance subsidies, and community-rating and guaranteed issue of insurance plans (\cite{courtemanche2017early}). Almost all states broadly implemented these reforms beginning January 2014. Conceptually we think of the other ACA components as a treatment ($V$) separate from Medicaid expansion ($A$).

Let $i$ index a CPUMA, $j$ index the state, $t$ index the time period. Let $N_t$ be the number of treated CPUMAs, $N_c$ be the number of control CPUMAs, and $M_c + M_t = M$ be the number of states (with $M_c$ and $M_t$ defined analogously). Each state has $n_j$ CPUMAs. Finally, let $Y_{ijT}^{A_{ijT} = a, V_{ijT} = v}$ be the potential uninsurance rate given Medicaid expansion and other ACA-reforms at time $T = 2014$. We then wish to estimate the following contrast:

$$
\psi &= \psi^1 - \psi^0 \\
&=N_t^{-1}\sum_{ij: A_{ijT} = 0, V_{ijT} = 1} Y_{ijT}^{A_{ijT} = 1, V_{ijT} = 1} - Y_{ijT}^{A_{ijT} = 0, V_{ijT} = 1} 
$$

In other words, we want to estimate the difference in the non-elderly adult uninsurance rates among states that did not expand Medicaid, but did implement other aspects of the ACA. Because all states implemented the ACA marketplace expansion in 2014, contrasts with the corresponding potential outcome absent this expansion are not identified. Moreover, since we are only interested in the counterfactual at time $T$, we simplify notation by removing this variable and the subscript in the estimand:

$$
\psi = N_t^{-1}\sum_{ij: A_j = 0} Y_{ij}^{A_{ij} = 1} - Y_{ij}^{A_{ij} = 0}
$$

We therefore seek to identify the effect of Medicaid expansion in the context of the simultaneous implementation of the ACA, but do not attempt to separately identify the effects of these separate treatments. Because we assume that interactions between the ACA implementation and Medicaid expansion may vary over time, we do not seek to generalize these results outside of 2014. 

\subsection{Identification}

We make the following causal assumptions: consistency, no unmeasured confounding, no anticipatory treatment effects, and positivity of treatment assignment. We explain these assumptions in detail and why we think they might be reasonable in this context.

Consistency states that the observed factual outcome under a given treatment assignment is equal to the potential outcome under that same treatment assignment ($Y_{ij}^{A_{ij} = a} = Y_{ij} \mid A_{ij} = a$). In other words, we assume that one regions' treatment assignment didn't affect another regions' observed outcome. This is a standard assumption, but often not realistic. Violations of this assumption are likely in our setting: for example, \cite{frean2017premium} find evidence that Medicaid expansion drove previously eligible but uninsured individuals to enroll in Medicaid in both expansion and non-expansion states. Signing the potential bias from these spillovers requires redefining the causal estimand: for example, we might consider the treatment effect on the untreated given that all states have expanded Medicaid, where the contrast is against where only the observed expansion states expanded Medicaid (ie $N_t^{-1}\sum_{ij: A_j = 0}(Y_{ij}^{A_{11} = ... = A_{N_t} = 1, A_{N_t + 1} = ... = A_{N_t + N_c} = 0} - Y_{ij}^{A_1 = ... = A_N = 1}$). If spillovers occurred in equal proportions in each region, and the magnitude of the spillovers increase with the number of treated regions, then the true effect would be larger in absolute magnitude than the effect estimated using the observed data. We could consider other estimands or assumptions to get different predictions about the sign of the bias, but we leave this as an area for future work.

We next assume that there were no anticipatory treatment effects. Letting treatment occur at time $T_0 + 1$, we have that for $t \le T_0$

$$
Y_{ijt} = Y_{ijt}^0
$$

This assumption is necessary because we are conditioning on pre-treatment outcomes. If these outcomes were affected by the treatment before it were implemented, these covariates would not be exogenous. Anticipatory treatment effects may occur if plans to expand Medicaid induce uninsured but Medicaid-eligible individuals to enroll in Medicaid prior to expansion. We do not think these violations occurred in large enough numbers to substantially affect our results. Instead, we address a more concerning version of this violation: as noted above, several states allowed certain counties to expand Medicaid prior to 2014. We therefore test the sensitivity of our results to the inclusion of these states.

Third, we assume no unmeasured confounding; that is, that at time $T$ the potential outcomes for each CPUMA are independent of the state-level treatment assignment conditional on the true CPUMA and state-level covariates $X_{ij}$ (which includes pre-treatment outcomes):

$$
Y_{ij}^a \perp A_{ij} \mid X_{ij}
$$

While unverifiable, we believe it is reasonable here given our rich covariate set. To be explicit, we believe that the uninsurance rate for each region given treatment is independent of the region's treatment assignment conditional on the percentage of uninsured individuals in the pre-treatment period, the percentage of unemployed individuals in the pre-treatment period, the population growth in 2012 and 2013, the average ratio of households to total population, the state's political composition, the average proportion of households with one or more children during the pre-treatment period, and the average proportion of individuals during the pre-treatment period with given demographics noted above (age, sex, white, hispanic, US citizenship, foreign born, income-to-poverty group, disability status, urban residence, and educational attainment group). If this assumption were violated -- that is, other covariates exist that determine this potential outcome and treatment assignment -- we hope that conditioning on pre-treatment outcomes might help proxy for these covariates, thereby minimizing the potential for bias. 

Having said that, we do not actually observe the true values of $X_{ij}$ but rather an estimate $W_{ij}$. Importantly, $Y_{ij}^a \perp A_{ij} \mid X_{ij} \not\implies Y_{ij}^a \perp A_{ij} \mid W_{ij}$. Therefore, the use of these proxies may also bias our estimates. We rely on several modeling assumptions outlined below in our estimation procedure to correct for this bias.

Finally, we assume positivity of treatment assignment; that is, that all states had some probability of being treated $\pi(X_{1j}, ..., X_{n_jj}) > 0$. Positivity violations can cause a lack covariate overlap in the observed data. As we have noted before, overlap is an issue in this study. We address this in multiple ways that we outline in our estimation strategy below. These assumptions are sufficient to non-parametrically identify our causal estimand if we observed the true covariates $X_{ij}$. 

We next invoke parametric modeling assumptions that help us identify our estimand given that we observe the mean unbiased proxies $W_{ij}$. First, we assume that the potential outcome under treatment is linear and additive in the covariates $X_{ij}$. Specifically, we believe that the following model generates the potential non-elderly adult uninsurance rate under treatment:

$$
\mu_1(X_{ij}) = \mathbb{E}\{Y_{ij} \mid X_{ij}, A_{ij} = 1\} = \alpha + X_{ij}^T\beta
$$

Notice that this allows us to rewrite $\psi^1$ as $\alpha + \mu_0^T\beta$, where $\mu_0$ is the (observed) mean among the control units.\footnote{To be precise, we use the population-weighted mean so as to target the individual-level treatment effect rather than the CPUMA-average treatment effect}. Let $s_{ij}$ be the vector of sample sizes used to calculate $W_{ij}$. We then assume that that $W_{ij} = X_{ij} + v_{ij}$, where $\sqrt{s_{ij}}v_{ij}$ are drawn independently from $MVN(0, \Sigma_{vv})$, and $v_{ij}$ and $\epsilon_{ij}$ are independent. These are reasonable assumptions in our context because we do not believe the errors in the CPUMA level aggregates are correlated and because the outcomes are estimated from a different cross-section of individuals than the covariates. These parameters, and therefore the causal estimand, are identified if we further assume that $X_{ij} \mid A_j = 1$ are drawn iid from a normal distribution and we know $\Sigma_{vv}$ \cite{gleser1992importance}.\footnote{Although we view our parameter as conditional on the true covariates $X_{ij}$, \cite{gleser1992importance} (Theorem 2) shows that under some milder assumptions, even when we view the covariates as fixed and $X_{ij}$ is non-normal, we can still consistently estimate $\alpha$ and $\beta$ using estimates of $\Sigma_{vv}$.} We discuss this further in Appendix A, while connecting these results to weighting estimators that directly estimate $\psi^1$ rather than outcome models that estimate $(\alpha, \beta)$. 

\subsection{Estimation}

We outline our estimation strategy first emphasizing how our method differs from the synthetic controls approach. In particular, we explain why our approach must rely on stronger modeling assumptions than synthetic controls applications and why we therefore choose to use an implementation of Stable Balancing Weights (SBW) for our modeling. Second, we explain a modification we make to the SBW criterion (which we call H-SBW) and show that it reduces the variance of our estimator assuming correlated model errors. Third, we connect our estimator to the regression calibration literature by generating weights that balance on an imputation of the true covariates $\hat{\eta}(W_{ij})$. Finally, we explain how due to remaining imbalances, we debias our estimator using ridge-augmented weights, following the suggestion of \cite{ben2018augmented}.\footnote{We also use overlap weights, suggested by \cite{li2018balancing}, in our sensitivity analyses to check the robustness of our results.}

Similar to synthetic controls applications, we seek to generate a set of positive weights that balance the means of the treated units to the mean of the control units. Assume that we observe the true covariates $X_1$ and $X_0$, and let $\bar{X}_0^p_x$ be the (population-weighted) average of the covariate values in the non-expansion region. Ideally, we could then find some $\gamma^\star$ such that: 

$$
(N_t^{-1})X_1^T\gamma^\star = \bar{X}_0^p, \gamma_i^\star > 0, \sum_{ij} \gamma_{ij}^\star = N_t
$$

Let $p$ be a vector of (normalized) population weights for each CPUMA in the non-expansion region in year $T = 2014$. We could then estimate $\psi$ as

$$
\hat{\psi}^{\gamma} = (N_t^{-1}\sum_{j: A_j = 1}^{M_t}\sum_{i = 1}^{n_j}\gamma_{ij}^\star Y_{ij} - \sum_{j: A_j = 0}\sum_{i = 1}^{n_j}Y_{ij}p_{ij})
$$

While synthetic controls are frequently motivated by the assumption that the outcomes follow a linear factor model, here we assume no unobserved confounding and that $\mu_1(X_{ij}) = X_{ij}^T\beta$. The bias of our estimator is therefore less than or equal to $\beta^T \delta = \beta^T(X_1^T\gamma - \bar{X}_0^p) = 0$ (see, eg, \cite{zubizarreta2015stable}). The challenge, however, is that for any given dataset we have no guarantee that any such $\gamma$ exists that exactly balances the covariates; we therefore need some method of determining how to prioritize which parts of the covariate distribution we wish to balance.

This is where our method to estimate the ETU contrasts with the commonly used synthetic control approach used to estimate the ETT: \cite{abadie2010synthetic} determine how to prioritize covariate balance by training their model on pre-treatment outcomes (\cite{kaul2015synthetic} shows that often the most relevant covariates simply become the pre-treatment outcomes). Because in that setting $Y^0_{ijt}$ is actually observed for $t \le T_0$, \cite{abadie2010synthetic} leverage this data to select the covariates that best predict these values. By contrast we never observe $Y^1_{ijt}$ prior to treatment. Without additional assumptions, we cannot use the pre-treatment data to learn which covariates matter most for determining this potential outcome.

Moreover, the problem of predicting treatment response also makes estimating the ETU more challenging than the ETT. As a result, we may care far more about balancing ``auxillary covariates'' (ie covariates that are not pre-treatment outcomes) in our setting than the traditional synthetic controls setting.\footnote{Recent discussions in the synthetic controls literature often prioritize discussing balancing pre-treatment outcomes alone (see, eg, \cite{doudchenko2016balancing}). This has some theoretic justification: \cite{botosaru2019role} find that when a sufficiently large amount of pre-treatment outcomes, assuming $\mu_0$ follows a linear factor model, the bias of the estimator is still bounded even if imbalances in auxillary covariates remain.} Consider the following example: say for some application there exist two sets of weights, $\gamma_1$ and $\gamma_2$, that exactly balances $k$ pre-treatment means of the controls units to the treated unit(s). $\gamma_1$ additionally exactly balances $p$ auxillary covariates, while $\gamma_2$ does not. Heuristically, estimates using either set of weights may provide reasonable counterfactuals for the treated unit(s) absent treatment. However, once we invert the treatment assignment -- ie the control units are treated and the treated units control -- and consider predicting the outcome under treatment: intuitively, we should choose $\gamma_2$. Why? Because we might worry that these observable characteristics predict treatment response, and the treatment response of these two units might differ substantially. 

More formally, assume that $\mu_0(X_{ij})$ follows a linear outcome model. We might reasonably believe the coefficients on auxillary covariates are close to zero once we condition on pre-treatment outcomes. As a result, the bias induced by imbalances on these covariates would be small. On the other hand, the coefficients on the same covariates for the model $\mu_1(X_{ij})$ could be much larger, even after conditioning on pre-treatment outcomes. If our synthetic control weights fail to balance these covariates, we should expect that our estimates of $\mu_0$ will in general have less bias than our estimates of $\mu_1$. In summary, estimating the ETU requires a greater understanding of how the covariates are related to treatment response than the ETU; moreover, and we cannot learn this information by using pre-treatment outcomes.

We therefore estimate the ETU by using a variation of SBW that we call H-SBW.\footnote{Specifically, we use a modified implementation of Noah Griefer's ``optweight'' package in R, available on github.com/mrubinst757}. This procedure allows us to estimate the minimum variance weights that satisfy certain balance constraints. Let $X_1$ and $X_0$ be the matrices of the observed treatment and control group covariates (and dropping the subscript $t$ for notational convenience), and let $\eta(W_{ij}) = \mathbb{E}\{X_{ij} \mid W_{ij}, A_j = 1\}$. We generate weights that solve the following objective:

$$
\min_{\gamma \in \Gamma} \sum_{j: A_j = 1}^{M_t}(\sum_{i = 1}^{n_j} \gamma_{ij}^2 + \sum_{kj \ne ij}\rho \gamma_{ij}\gamma_{kj})
$$

$$
\Gamma := \{\gamma: \mid N_t^{-1}\hat{\eta}(W_{ij})^T\gamma - \bar{X}_0^p \mid \le \delta, \gamma_{ij} > 0, \sum_{ij}\gamma_{ij} = N_t\}
$$

Unlike the synthetic controls objective, the SBW objective allows the user to specify covariate-level balance constraints using the vector $\delta$. When estimating the ETC, we lean heavily on assumptions to justify our choice of $\delta$; in particular, we use a priori knowledge about which covariates are most likely to be important predictors of treatment effect heterogeneity when setting $\delta$. 

We now discuss how the H-SBW criterion differs from SBW. Notice that the SBW criterion is equivalent to ours when setting $\rho = 0$; in other words, SBW attempts to calculate the minimum variance weights for a fixed $\delta$. This is desirable if, for example, the errors in the outcome model are all independent and identically distributed. In our case, we account for possible state-level dependencies in the outcome model (or, alternatively, depending on one's viewpoint, state-level sampling or state-level treatment assignment). Intuitively, by adding the tuning parameter $\rho$, this objective attempts to ensure that the within state sum of weights is roughly uniform across states as well as across CPUMAs. This is especially desirable if many weights would in some cases be concentrated in only one state. We discuss this objective in more detail and provide simulation results in Rubinstein (2020) (available soon), but note that broadly speaking, we can think of H-SBW to SBW what generalized least squares (GLS) is to ordinary least squares (OLS): both SBW and OLS can produce unbiased estimates of certain parameters, but H-SBW and GLS are more efficient estimators assuming some correlation structure in the data.

A second departure from SBW comes in the constraint set: rather than balancing on the observed covariate values $W_{ij}$, we instead balance on our estimate of $\eta(W_{ij})$. This is because the estimation error in these region-level estimates will bias our estimator. In Appendix A we show that this bias is equivalent to the bias induced in the classical measurement error framework using OLS. We further show that if we had access to $\eta$, we could get an unbiased estimate of $\psi^1$. Here we leverage the person-level replicate survey weights provided in the ACS microdata to estimate the variability in each CPUMA's observed covariate values. We then use a variant of standard regression calibration techniques to estimate $\eta(W_{ij})$ as a linear approximation to the true covariate values. We give further details about this estimation procedure in Appendix B.

This is the first application we are aware of to use regression calibration methods in the context of balancing weights. We emphasize the key assumptions for the theoretical groundings for this procedure: (1) the outcome model is linear in the covariates; (2) the measurement error in the outcome is unrelated to the measurement error in the covariates; (3) the covariates are randomly sampled from some larger super-population. The first assumption is quite strong, though standard in many applications. The second assumption is reasonable, because our outcomes are estimated from a different cross-sections of individuals than our covariates. The final assumption is not strictly necessary; \cite{gleser1992importance} (Theorem 2) shows that regression calibration methods can provide consistent estimates of the outcome model parameters when we view $X_{ij}$ as fixed and only the errors are iid normals. Using the connection we establish in Appendix between regression and weighting estimators, it is likely that these results hold in our setting as well (though formally showing this is beyond the scope of this paper).

Lastly, we are unable to achieve exact balance on our covariates. These imbalances will in general bias our estimator. Following the recent literature on synthetic controls, we reduce this bias by using ridge-regression augmented weights \cite{ben2018augmented}. Letting $\hat{\eta}(W_1)$ be the matrix of imputed covariates, we use regression-augmented weights:

$$
\gamma^{aug} = \gamma^{sbw} + (\hat{\eta}(W_1)^T\gamma^{sbw} - \bar{W}_0^p)^T(\hat{\eta}(W_1)^T\Omega^{-1}\hat{\eta}(W_1) + \lambda I_d)^{-1}\hat{\eta}(W_1)^T\Omega^{-1}
$$

where $\Omega$ is a block diagonal matrix with diagonal entries equal to one and the within-group off diagonals equal to $\rho$. We choose $\lambda$ so that the remaining imbalances all fall within 0.1 percentage points (see \cite{ben2018augmented} for more details on the connection between these weights and ridge-regression). The cost of this procedure is that we must extrapolate from the support of the data, and therefore rely more heavily on our modeling assumptions. Finally, notice that we can also generate Oaxaca-Blinder weights ($\gamma^{ob}$) by setting $\gamma^{sbw} = 1/N_t$ and $\lambda = 0$. These are equivalent to running OLS (or GLS) on the observed outcomes among the treated units and imputing the missing counterfactual using these coefficient estimates. In our results we consider estimators using Stable Balancing Weights ($\rho \in \{0, 0.2\}$), and ridge-augmented versions of SBW and H-SBW. We also generate Oaxaca-Blinder weights setting $\rho \in \{0, 0.2\}$ and provide these results in the Appendix. We focus our discussion on our preferred estimators, H-SBW wand the ridge augmented version (BC-HSBW).

\subsection{Inference}

We treat our estimate of $\psi^1$ as known, since we observe it in the data and the population-weighted average is quite precise relative to the CPUMA-level averages. Our uncertainty therefore arises from our estimate of $\psi^0$. We use the leave-one-cluster-out jackknife to estimate the standard error of our estimator of $\psi^0$. We compute standard errors both recalculating all of the estimators on the adjusted data, and also recalculating the entire adjustment process. We expect that either of these estimators will be conservative: assuming we had access to the true covariates, our target of inference is conditional on the true underlying covariates. By contrast, the leave-one-cluster-out jackknife is an approximation to the bootstrap, which has coverage even when the covariates are random. Moreover, it is not clear that resampling entire states when estimating $\eta(W_i)$ is a sensible procedure when we view the underlying covariates as fixed, since it is plausible that the measurement errors being drawn iid at the CPUMA level. Additional comments on the bias and variance of this estimator are available in Appendix A; obtaining more precise inference in this setting is an interesting question but is beyond the scope of this paper.

\section{Results}

We present the analyses using our transformed covariates $\hat{\eta}(W_{ij})$. Figure \ref{loveplot} shows how our balancing weights reduce the imbalances among covariates with greater than one percentage point difference between the targeted mean in the expansion region and the mean values in the non-expansion region (we target the population-weighted mean of the untreated region). Before applying our weights, we see that there are substantial imbalances in the republican governance indicators, as well as pre-treatment uninsurance and unemployment rates. Our weights drastically reduce these differences; however, some imbalances remain. In particular, the Republican governance indicators are remain quite imbalanced. A full balance table is available in the Appendix. 

\begin{figure}[B]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/balance-plot-etu.png}
    \caption{Balance plot}
    \label{loveplot}
\end{center}
\end{figure}

We therefore use a ridge-augmentation to extrapolate from the data to reduce all imbalances within 0.1 percentage points. Figure \ref{statewghts} shows the total weights summed across states for each estimator: HSBW and BC-HSBW. This figure separately sums the negative weights from the positive weights to make clear the extent of the extrapolation. We see that BC-HSBW does extrapolate somewhat heavily in order to generate counterfactuals, particularly from California. 

\begin{figure}[B]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/weights-by-state-main.png}
    \caption{Total weights summed by state}
    \label{statewghts}
\end{center}
\end{figure}

Our H-SBW estimator yields an estimated effect of -1.89 (-0.86, -2.90).\footnote{This estimator ran the objective function above using $\rho = 0.2$ and imputing the covariates in the second procedure outlined in the Appendix.} In other words, had states that did not expand Medicaid done so, we would have seen a 1.89 percentage point reduction in their uninsurance rates in 2014. Encouragingly, the bias-correction makes almost no difference to the point estimate, although the confidence interval increases to (-0.79, -2.99). These estimates differ somewhat from the estimates we find running the procedure on the observed values $W_i$: here we calculate our preferred weighting estimator as -2.26 (-1.64, -2.87), and the bias corrected estimator yields -2.50 (-1.82, -3.17). Using the corrected dataset appears to both move our estimate closer in absolute magnitude towards zero and increase the estimated confidence intervals. This is expected because the imputation essentially shrinks outlying values of $W_i$ closer to $\bar{W}$; as a result, our weights must become more extreme in order to achieve the same level of covariate balance. Oaxaca-Blinder weights give an estimate of -1.58 (-0.83, -2.32); however, these weights extrapolate most heavily from the data of these three weight sets. Figure \ref{estimators} displays the point estimates from each of our weighting estimators. 

\begin{figure}[B]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/point-estimates-c1.png}
    \caption{Point estimates}
    \label{estimators}
\end{center}
\end{figure}

We next examine how removing specific covariate groups in the weighting procedure changes the estimated contrast between the weighted treatment and control regions (ie the estimated treatment effect when all groups are included). We are especially interested how this contrast changes when we remove the Republican governance indicators: because we hypothesize that regions under Republican governed administrations should have lower Medicaid take-up rates, we expect that removing these covariates should move this estimate farther away from zero. We divide our covariates into six separate groups: pre-treatment uninsurance rates and pre-treatment unemployment rates, Republican governance indicators, and three sets of different demographic indicators.\footnote{Specifically, the first includes: urban residence, age group, education, citizenship, student, disability, female; the second, white race, hispanic, foreign-born, and income-to-poverty ratio bucks; the third, number of children, household to population ratio, and population growth.} We then rerun the analyses excluding each group. 

\begin{figure}[]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/loo-covariates-main-c1.png}
    \caption{Estimates}
    \label{loocovariates}
\end{center}
\end{figure}

Figure \ref{loocovariates} displays the estimated treatment effects when removing each covariate group for our preferred set of weights and the bias corrected version of these same weights. Unsurprisingly, we find that all our estimators are very sensitive to the removal of pre-treatment uninsurance and pre-treatment unemployment rates. When we fail to control for these covariates, our estimated contrast increases substantially in absolute magnitude. We also find that our preferred bias-corrected estimator is somewhat sensitive to the removal of children/population-growth/household ratio group. 

Most importantly, we see a substantial increase in absolute magnitude of our estimated contrast when removing the Republican governance indicators. Specifically, we find that our estimated contrast increases in absolute magnitude by 0.65 for our preferred estimator and by 0.72 for our bias-corrected estimator. A similar differential also occurs on our unadjusted dataset. These results support our hypothesis that Republican governance drives heterogeneity in the treatment effects. A full comparison of the difference in estimates when removing the Republican governance indicators in each dataset is available in FIGURE REF. This plot shows the estimated excluding early expansion states and when estimating the overlap average treatment effect (discussed below). A full comparison across estimators is available in the Appendix.

Finally, we analyze the sensitivity of our results to specific states. Given that the weighting procedure fits heavily to certain states, we are particularly interested in how the estimated causal effect might change when excluding these states.

\subsection{Sensitivity Analyses}

We examine the sensitivity of our estimates to violations of two key causal assumptions: (1) no anticipatory treatment effects, and (2) positivity violations. To the first point, several states had partial limited expansions prior to 2014. Following \cite{frean2017premium}, we consider these states to be California, Connecticut, Minnesota, New Jersey, and Washington. We rerun our analyses excluding CPUMAs from all five of these states. We are unsure how we should expect this to affect our estimates: on the one hand, states that expanded early might have a smaller treatment effect after 2014 because they already enrolled newly eligible individuals. This would bias our previously estimated treatment effect upwards. On the other hand, if these states were also more motivated to enroll people in Medicaid, they might have larger post-expansion coverage gains, leading to a downwards bias. When removing these states, we estimate an effect of -1.35 using H-SBW weights and when we run the bias-corrected version we estimate -1.77.\footnote{We do not provide confidence intervals for these estimates. When leaving out each state from this smaller dataset, we find that in order for the SBW program to converge, the error tolerances to converge they must be relaxed beyond the point where the estimates are centered at the initial estimate.} Our leave-one-out covariate analysis shows similar associations to those in our primary analysis; however, we see a somewhat larger association between Republican governance indicators and our estimated contrast. In particular, we find that removing the Republican governance indicators increases our estimator by XX percentage points for HSBW, and by AA percentage point for HSBW. Figure XXX compares the association between the Republican governance indicators and the estimated treatment effect across four datasets: all treatment units included (our primary results), early expansion excluded, each with imputed and unadjusted covariates. This plot emphasizes that these associations hold regardless of whether or not we imputed the covariates or excluded the early expansion states.

\begin{figure}[]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/repub-diff-c1.png}
    \caption{Removing Republican Governance Indicators}
    \label{repub}
\end{center}
\end{figure}

We next consider positivity violations. To this point we have relied on either (1) leaving a potentially biased estimate from imbalanced weights, or (2) producing a more heavily model-dependent estimate that relies on extrapolation. Overall we found that the results didn't change substantially either way. Here We consider a third option: changing our target estimand. In particular, we consider the overlap average treatment effect (OATE), proposed by \cite{li2018balancing}. This is the treatment effect on the subset of the entire dataset where we have overlap. It is a data-dependent treatment effect, and is not the same as the treatment effect on the untreated; however, we believe that this effect will be more similar to the ETC than the ETT, since there were no Democratic controlled states that did not expand Medicaid. After generating overlap weights on our primary dataset we find that across all covariates, the mean L1 distance from the overlap region to the treated region is 2.5 and to the untreated region is 7.8.\footnote{The distance is between the overlap region calculated as an unweighted mean on the adjusted datasets.} Figure ZZZ displays the distance between covariates with greater than one percentage point distance from the overlap region to either the control or treated region. We see that the overlap region is substantially more Republican than the treated region, as expected. This region is also less hispanic, more white, less rural, and more educated than either the expansion or non-expansion region. A table comparing all covariates is available in the Appendix.

\begin{figure}[]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/oate-imbalances.png}
    \caption{Overlap area compared to treated, untreated regions}
    \label{oateimbalance}
\end{center}
\end{figure}

Figure \ref{oateimbalance} displays the sum of the weights within each state by treatment group. As predicted, we see that it is heavily represented by more conservative states, including Ohio, Arkansas, etc.

\begin{figure}[]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/oate-region.png}
    \caption{Overlap weights by state}
    \label{oatearea}
\end{center}
\end{figure}

We find similar results to our primary analysis: within the overlap region we find an estimated treatment effect of -1.77 (-3.87 -0.06) when including all treatment states in our primary analysis, and of -1.89 (-3.14, -0.91) when excluding ``early expansion'' states (we generate confidence intervals for this analysis by using the block bootstrap across 1000 iterations). We find that these estimates are not particularly sensitive to any one particular state. On the imputed dataset, removing Arkansas and Missouri resulted in the largest change in the estimated effect (moving it closer by 0.36 and 0.27 percentage points closer towards zero, respectively). We again find a negative association between the estimated contrast and the Republican governance indicators, which decrease the estimated effect size by 0.55 percentage points on the primary dataset and by 0.45 percentage points. Additional results are available in the Appendix.

\section{Discussion}

We estimate that had states that did not expand Medicaid in 2014 expanded their programs, they would have seen a VVV (QQQ, XXX) percentage point change in the adult uninsurance rate. Existing estimates place the ETT between -3 and -6 percentage points; these estimates vary depending on the targeted sub-population of interest, the data used, and the modeling approach (see, eg, \cite{courtemanche2017early}, \cite{kaestner2017effects}, \cite{frean2017premium}). This estimate is therefore closer to zero than these  papers, supporting our original hypothesis that the treatment effect on non-expansion states would be smaller in absolute magnitude. Moreover, we also find that we are likely to estimate treatment effects that are larger in absolute magnitude when allowing our comparison states to include states with more Democratic governance. While the differences all lay within the estimated margins of error of the original point estimates, the consistency of this finding in all of our sensitivity analyses provides some evidence that the differing political composition of the expansion versus the non-expansion states may explain these differences. 

We also make several methodological contributions to the literature on balancing weights. First, we extending the synthetic controls literature to estimate the treatment effect on the untreated. The key challenge is that we are trying to predict treatment response rather than the outcome absent treatment. Unlike when estimating the treatment effect on the treated, we cannot use pre-treatment outcomes to conduct variable selection, run placebo tests, or train our model in some other way. This is a fundamentally more difficult problem that requires greater modeling assumptions. Second, we extend the Stable Balancing Weights objective for use with hierarchical data and measurement error. We modify the objective function to ensure that our weights more evenly disperse across states. We also exploit estimates of our region-level covariate estimates to account for bias induced by the measurement error by using a slight modification of standard regression calibration techniques.

Our study's approach also has bearing on estimating the ETT using a differences-in-differences to study the 2014 effects of Medicaid expansion. In particular, the consistent positive association between Republican governance and the estimated contrast between treatment and control states suggests that existing studies that fail to account for the interaction of treatment with measures of governance may incorrectly estimate the targeted treatment effects. We also find that there is likely insufficient overlap to account for these interactions without extrapolating from the data, and we show the ETC requires less extrapolation than the ETT with respect to these covariates. The primary estimand in the existing literature is instead the effect of treatment on the treated (ETT). While it may be tempting to extrapolate these findings to estimate the ETC (see, eg, \cite{miller2019medicaid}), this may lead to inaccurate inferences due to the heterogenous economic, demographic, and political characteristics between these groups of states.

Given that the effects of Medicaid expansion are primarily mediated through insuring the previously uninsured, we can assume that if the ETC were closer to zero than the ETT, then further downstream effects that grow monotonically with the number of insured would attenuate. For example, \cite{miller2019medicaid} use their estimate of the ETT to project that had all states expanded Medicaid in 2014, 15,600 deaths would have been avoided during their study's time-period. If we believe that the ETT were further away from zero than the ETC, we should expect that this number is an overestimate. Directly estimating the ETC in this context can therefore also help us better model interesting downstream effects mediated through increasing the number of insured individuals.

Our results come with the following caveats: (1) we rely on parametric assumptions about the outcome model to estimate our causal effect; (2) our identification assumes no unmeasured confounding, which is a relatively strong assumption; (3) spillovers across states might bias our estimates (and in general without redefining the causal estimand we cannot sign this bias); and (4) our variance estimation does not account for the variability induced by the measurement error in the covariates. 

We conclude by discussing the policy implications of these findings. First, we note that a reduction of adult uninsurance rates by -2.18 percentage points in represents approximately an eleven percent reduction in the pre-existing uninsurance rate for non-expansion states. This estimated treatment effect is closer to zero than corresponding estimates of the ETT (see, eg, \cite{courtemanche2017early}). We may therefore expect that downstream effects that move away from zero monotonically with the number of uninsured are also closer to zero than estimates of the ETT. For example, \cite{miller2019medicaid} estimate that if their set of non-expansion states had expanded Medicaid during their study period, they would have avoided 15,600 deaths. Because these estimates were based on projecting the ETT onto non-expansion states, assuming that avoided deaths increase monotonically with the number of uninsured, our results suggest that this figure may be an overestimate.

Second, we emphasize that the positive association we find between governance and the estimated treatment effect is only an association: this finding does not imply, for example, that states with Republican governments in general make Medicaid enrollment more difficult relative to Democratic states. However, this finding does not rule out this possibility either. Even if this causal story were true, then it is also a normative judgment whether this finding is a ``good'' or a ``bad'' result. To evaluate the policy implications, we compare this result against Congress's goal in implementing Medicaid expansion in the 2010 ACA, which was to increase health insurance coverage. Measured against this intent, this finding suggests that leaving states to implement individual enrollment schemes likely achieves sub-optimal results. Better federal policies should encourage states to adopt some form of automatic Medicaid enrollment, or to make Medicaid enrollment easier in some other way.

On the other hand, Republican governed states in 2014 were also more culturally conservative, and people may have been less likely to enroll in Medicaid due to social stigma and/or personal beliefs about the welfare state (\cite{sommers2012understanding}). If this remains true today, then Republican governments that are committed to expanding access to health care to low-income individuals may again wish to consider policies such as automatic enrollment to help mitigate these effects. Lastly, for Republican administrations who do not see coverage expansion as an important goal of Medicaid expansion, this finding may represent no policy problem at all.

\section{Conclusion}

This is the first study to directly estimate the foregone coverage expansions of Medicaid Expansion on states that did not expand Medicaid in 2014. We also contribute to the methodological literature on synthetic controls by clarifying the assumptions required to use longitudinal data to estimate the ETC rather than the ETT. We estimate that had states that did not expand Medicaid in 2014 done so, they would have seen a -2.18 (-1.31, -3.06) percentage point change in their uninsurance rate. This is substantially closer to zero than existing estimates of the ETT, which range between -3 and -6 percentage points. Regions from Ohio and Arkansa largely drive our initial estimates; however, we calculate similar estimates when excluding regions from any one particular expansion state. These estimates are also robust to sensitivity analyses examining potential violations of the assumptions of no anticipatory treatment effects and positivity violations. 

We also find evidence that Republican governance is associated with estimated effect sizes closer to zero. This association is also robust to the removal of each state, is consistent with existing estimates of the ETT that are also farther away from zero, and the finding that Medicaid take-up rates are lower in Republican-governed states prior to Medicaid expansion in 2014 (\cite{sommers2012understanding}). If the goal of Medicaid expansion is to increase access to insurance for low-income adults, this suggests that state and federal governments may wish to adopt policies that make Medicaid enrollment automatic, or at least easier.

\cleardoublepage
\bibliography{research.bib} 

\cleardoublepage

\section{Appendix}

\subsection{Appendix A: Proofs}

We prove that the bias of the SBW estimator under measurement error is equivalent to the bias of the OLS estimator under the classical errors-in-variables model. We then prove the unbiasedness and asymptotic normality of the estimator when balancing on the imputed covariates when balancing on using $\mathbb{E}\{X_i \mid W_i\}$ instead of $W_i$. This is not meant to be a comprehensive treatment of the properties of this estimator, but rather to introduce the idea that we can apply concepts in the regression-calibration literature in for balancing weights when the covariates are measured with error. We conclude by noting how our application differs from this stylized introduction; Appendix B provides details on how we applied these ideas for our application.

We begin by outlining the classical errors-in-variables setup. Consider the linear model $Y_i^1 = X_i^T\beta + \epsilon_i$ and assume we observe covariates $W_i \in \mathbb{R}^d$ which are a vector of mean-unbiased proxies for the true covariate $X_i$; ie $W_i = X_i + v_i$. Assume that $(\epsilon_i, v_i) \sim MVN((0,0), \Sigma_{uu})$ 

$$
\Sigma_{uu} = \begin{pmatrix} 
\Sigma_{\epsilon\epsilon} & 0 \\ 
0 & \Sigma_{vv} 
\end{pmatrix}
$$ 

In general we can either consider the case where $X_i$ are fixed (functional model) or random (structural model); the structural case typically motivates regression calibration, however, the ideas have desirable properties in the functional case as well \cite{gleser1992importance}. For motivating purposes, we therefore think of $X_i$ as random. In a slight departure from the classical setup, we also consider the binary treatment indicator $A_i$ and we let $(X_i, W_i \mid A_i = a)$ are drawn iid from $MVN((\mu_a, \mu_a), \Sigma)$ where 

$$
\Sigma = \begin{pmatrix} 
\Sigma_{XX} & \Sigma_{XX} \\ 
\Sigma_{XX} & \Sigma_{XX} + \Sigma_{vv} 
\end{pmatrix}
$$ 

For simplicity we have assumed that $\Sigma_{WW \mid A = 1} = \Sigma_{WW \mid A = 0} = \Sigma_{WW}$ and $\Sigma_{XX \mid A = 1} = \Sigma_{XX \mid A = 0} = \Sigma_{XX}$. This is not a necessary assumption, but helps simplify notation. By the joint normality of $X_i$ and $W_i$, we know that that $\mathbb{E}\{X_i \mid W_i, A_i = 1\} = \mu_1 + \kappa^T(W_i - \mu_1)$, where $\kappa = \Sigma_{WW}^{-1}\Sigma_{XX}$.

Recall that the bias of the OLS estimator of $\beta$ is $\beta - \hat{\beta} = \kappa^{-1}\beta$. We can express our causal estimand as $\mu_1^T\beta$, and (accounting for the intercept), we get that the bias of this linear combination is $(\mu_0 - \mu_1)^T(I_d - \kappa)^T\beta$. We now consider the SBW estimator that sets $\delta = 0$ and show that this estimator has the same bias. The intuition for this result is as follows: exact balancing weights estimate an implicit $\beta$ on a subset of the data where we have sufficient overlap. We can think of the implicit beta as the solution to some weighted-least squares problem. Because we assume that the outcome model holds on all of the data, WLS and OLS are estimating the same $\beta$; therefore, the bias that effects the least squares solution will have the same effect on the weighted least squares solution.

More formally, define the SBW estimator as:

$$
\arg\min_{\gamma \in \Gamma} \gamma_i^2
$$

$$
\Gamma := \{\gamma: W_1^T\gamma = W_0^T1, \gamma_i > 0, \gamma^T1 = 1\}
$$

\begin{align*}
    \mathbb{E}\{\hat{\psi}\} - \psi &= \sum_{i: A_i = 1}w_iY_i - \sum_{i: A_i = 0}Y_i^0 \\
    &= \mathbb{E}\{\beta^T(\sum_{i: A_i = 1} \gamma_i (X_i - v_i) - \sum_{i: A_i = 0} (X_i - v_i))\} \\
    &= \beta^T(\sum_{i: A_i = 1} \gamma_i\mathbb{E}\{v_i \mid W_i, A_i = 1\}) \\
    &= \beta^T(\sum_{i: A_i = 1} \gamma_i\mathbb{E}\{(W_i - X_i) \mid W_i, A_i = 1\} \\
    &= \beta^T(\sum_{i: A_i = 1} \gamma_iW_i - \sum_{i: A_i = 1} \gamma_i\mathbb{E}\{X_i \mid W_i, A_i = 1\})
\end{align*}

Substituting our expressions for the conditional distribution of $X_i \mid W_i, A_i = 1$, and taking expectations over $W_i$, we obtain:

\begin{align*}
    &= \beta^T(\mu_0 - \sum_{i: A_i = 1} \gamma_i(\mu_1 + \kappa^T(W_i - \mu_1)) \\
    &= \beta^T(\mu_0 - \mu_1) - \beta^T(\sum_{i: A_i = 1}(\gamma_iW_i - \mu_1))\kappa \\
    &= (\mu_0 - \mu_1)^T\beta - (\mu_0 - \mu_1)^T\kappa\beta \\
    &= (\mu_0 - \mu_1)^T(I_d - \kappa)^T\beta
\end{align*}

Correcting for this bias is a much studied topic. We propose using regression calibration techniques, which are discussed at length in the measurement error literature (see, eg, \cite{carroll2006measurement}). This allows us to adjust our covariates without using the outcomes, in the spirit of the design-based estimation strategy we use here. At its most broad, regression calibration seeks to learn the linear projection $\mathbb{E}\{X_i \mid W_i, A_i = 1\} = \mu_1 + (\kappa^T W_i - \mu_1) = \eta(W_i)$ by learning $\kappa$. Notice that $\kappa = \Sigma_{WW}^{-1}\Sigma_{XX}$, and $\Sigma_{WW} = \Sigma_{XX} + \Sigma_{uu}$. We can learn $\Sigma_{WW}$ directly from the data, and $\Sigma_{uu}$ using auxillary data. For our application, we use the replicate survey weights available on the ACS microdata, to estimate this matrix. 

We now show that balancing on $\eta(W_i)$ results in an unbiased estimate of $\psi$. We make the simplifying assumptions that $\eta(W_i)$ is known and that there is no model error on $Y_i$. By linearity, we know that

\begin{align*}
Y_i &= X_i^T\beta \\
&= \eta(W_i)^T\beta + (X_i - \eta(W_i))^T\beta
\end{align*}

Now let $\gamma \in \Gamma$, where $\Gamma := \{\gamma \mid \sum_i \gamma_i \eta(W_i) = \sum_i X_i\}$. Let $v_i = X_i - \eta(W_i)$. We then see that

\begin{align*}
    \frac{1}{n}\sum_{i}\gamma_{i}Y_{i} - \frac{1}{n}\sum_{i}Y_{i} &= \frac{1}{n}\beta^T\sum_{i}\gamma_{i}(\eta(W_i) - \sum_{i}X_{i}) + \frac{1}{n}\sum_i \gamma_iv_i^T\beta \\
    &= \frac{1}{n}\sum_i \gamma_iv_i^T\beta
\end{align*}

Across repeated draws of $W$, this term is zero in expectation because we know $\eta$ (for fixed $W$, this term has no variance and only contributes to a finite-sample bias that vanishes at a $\sqrt{n}$ rate assuming there exists some constant $C$ such that $\max_i \gamma_i \le C\sqrt{n}$). We also see that this imputation increases the variance of the estimator across repeated draws of $W$:

\begin{align*}
    Var(\frac{1}{n}\sum_i \gamma_i Y_i \mid W_i) &= \frac{1}{n^2}\sum_i Var(\gamma_iv_i^T\beta) \\
    &\le \frac{1}{n^2}\sum_i\mathbb{E}(\gamma_i^2)\beta^TCov(X_i \mid W_i)\beta 
\end{align*}

Our goal is again simply to show that many of the ideas developed in the regression-calibration literature can be used with balancing weights when we assume our covariates are measured with error without using any information about the outcomes. While the validity of this procedure relies on several strong modeling assumptions, perhaps the most crucial is the assumption that any measurement error in the covariates is uncorrelated with any measurement error in the outcome. 

We conclude by noting several key departures in our applied setting to the framework we presented above: first, we view $X_i$ as fixed underlying parameters. Second, we don't know $\eta(W_i)$ and instead approximate it using an estimate $\Sigma_{vv}$ that we derive from the ACS replicate survey weights. Third, we do not believe that $X_i$ is linear in $W_i$; instead, we view this is an approximation. Discussing these issues in detail is beyond the scope of this paper; however, \cite{gleser1992importance} (Theorem 2) shows the conditions for the consistency of the regression-adjusted estimator in a similar context. Using the connection between balancing weights and linear outcome models, we could show the consistency of balancing weights in this setting as well. Finally, we consider our data to be correlated within state but independent across states. We have not formally considered the effect of these dependencies on this estimation procedure, and whether the methods followed here leave room for improvement. We leave this to future work.

\subsection{Appendix B: Calibration Details}

We now discuss our imputation procedure. We first outline the traditional imputation outlined in \cite{carroll2006measurement}, and then explain our preferred departures from this framework. In either case we begin by estimating the covariance matrix $\Sigma_{UU, ij}$, the sampling variability for each CPUMA by estimating

$$
\hat{\Sigma}_{UU, ij} = \frac{4}{80}\sum_{b=1}^{80}(X_{ij}^B - \bar{X}_{ij})(X_{b, ij} - \bar{X}_{ij})^T
$$

Let $\hat{\Sigma}_{WW \mid A_j = 1} = \sum_{j: A_j = 1} (W_{ij} - \bar{W})(W_{ij} - \bar{W})^T$ be an estimator for $\Sigma_{WW \mid A = 1} = \mathbb{E}\{(W_{ij} - \mu_w)(W_{ij} - \mu_w)^T\}$. This estimator is calculated on the original dataset. We then estimate $\Sigma_{XX \mid A = 1} = \mathbb{E}\{(X_i - \bar{X})(X_i - \bar{X})^T \mid A_j = 1\}$ using:

$$
\hat{\Sigma}_{XX \mid A = 1} = \Sigma_{WW} - \sum_{ij: A_j = 1} \Sigma_{UU, ij}
$$

Define

$$
\hat{\kappa} = (\hat{\Sigma}_{WW})^{-1}(\hat{\Sigma_{XX}})
$$

We can think of this matrix as an estimate coefficient vector of a linear regression of the (unobserved) vector $X_{ij}$ on (observed) $W_{ij}$. We can impute $\hat{X}_{ij}$ as

$$
\hat{X}_{ij} = \bar{W} + \kappa^T(W_{ij} - \bar{W})
$$

This is the standard imputation suggested by \cite{carroll2006measurement}. However, in our setting we know that there is substantial heterogeneity in the measurement error: in particular, regions with large populations are estimated quite precisely, while others are estimated much less precisely. Even for a given CPUMA, some covariates are measured using three years of data, and others only one. From 2011 through 2013, STATISTICS on sample sizes!! As a result, using the conventional regression calibration approach will affect estimates that we know are precisely estimated and ones that we know aren't in a similar way. 

Our preferred estimators therefore use an alternative approach where we model $\Sigma_{vv, ij}$ as a function of the sample sizes used to estimate each covariate. In particular, let $s_{ij}$ be the d-dimensional vector of the sample sizes used to estimate each covariate value for a given CPUMA. Let $S_{ij} = \sqrt{s_{ij}}\sqrt{s_{ij}}^T$. We then assume that $\sqrt{s_ij}v_{ij} \sim N(0, \Sigma_{vv})$. We then know that $\Sigma_{vv, ij} = \Sigma_{vv} \oslash S_{ij}$. 

To estimate these matrices, we pool our initial estimates of the CPUMA-level covariance matrices ($\hat{\Sigma}_{UU, ij}$) to generate $\hat{\Sigma}_{UU}^m = N_t^{-1}\sum_{ij} S_{ij} \circ \Sigma_{UU, ij}$. We then estimate $\hat{\Sigma}_{UU, ij}^m = \Sigma_{UU}^m \oslash S_{ij}$. From this we estimate $\hat{\Sigma}^m_{XX} = \hat{\Sigma}_{WW} - N_t^{-1}\sum_{ij}\hat{\Sigma}^m_{UU, ij}$. Finally, we calculate $\hat{\kappa}_{ij} = (\hat{\Sigma}^m_{XX} + \hat{\Sigma}^m_{UU, ij})^{-1}\hat{\Sigma}^m_{XX}$, which we use to estimate $\hat{X}_ij$. 

Again the benefit of using this estimator is that we account for unit-level heterogeneity in the measurement error. Specifically, this adjustment will primarily affect outlying values of imprecisely estimated covariates, while leaving precisely estimated covariates largely unchanged. Moreover, we can do this while getting the full efficiency of using all of the units in the modeling. 

One cost of this procedure is that this aggregation models all differences as a function of the sample sizes, and averages over any potential heterogeneity due to heteroskedasticity (ie the measurement error covariance matrix changes depending on the true value of $X_{ij}$). A second cost is that we do not account for the hierarchical nature of the data; if we did, we could likely improve the efficiency this estimation procedure. We leave this as future work.

\subsection{Appendix B: Complete Balance Tables}

Tables \ref{baltab1} and \ref{baltab2} presents the differences between the population-weighted untreated mean covariate values and the weighted and unweighted non-expansion region (calculated on on our adjusted dataset). The weights presented here are from the H-SBW $(\rho = 0.2)$ estimator. Additional results are available on request.

\begin{table}[ht]
\centering
\begin{tabular}{lrr}
  \hline
variable & Unweighted Difference & Weighted Difference \\ 
  \hline
age\_cat2\_19\_29\_pct & 0.51 & 0.26 \\ 
  age\_cat2\_30\_39\_pct & 0.22 & 0.34 \\ 
  age\_cat2\_40\_49\_pct & -0.09 & 0.59 \\ 
  avg\_adult\_hh\_ratio & -10.11 & 0.25 \\ 
  citizenship\_pct & 2.19 & 2.00 \\ 
  disability\_pct & 1.01 & -0.49 \\ 
  educ\_hs\_degree\_pct & 2.38 & -1.40 \\ 
  educ\_less\_than\_hs\_pct & 0.74 & -1.21 \\ 
  educ\_some\_college\_pct & -0.01 & -0.83 \\ 
  female\_pct & 0.34 & 0.76 \\ 
  foreign\_born\_pct & -5.26 & -2.00 \\ 
  hins\_unins\_pct\_2011 & 4.33 & -0.05 \\ 
  hins\_unins\_pct\_2012 & 4.08 & 0.01 \\ 
  hins\_unins\_pct\_2013 & 3.90 & 0.05 \\ 
  hispanic\_pct & -1.70 & -1.00 \\ 
  inc\_pov2\_138\_pct & 1.93 & -0.67 \\ 
  inc\_pov2\_139\_299\_pct & 2.42 & -0.74 \\ 
  inc\_pov2\_300\_499\_pct & 0.26 & 0.08 \\ 
  inc\_pov2\_500\_plus\_pct & -5.01 & 2.00 \\ 
  married\_pct & 0.67 & 0.94 \\ 
  missing\_children\_pct & 0.00 & -2.13 \\ 
  one\_child\_pct & 88.28 & 89.04 \\ 
  pop\_growth\_2012 & 0.93 & -0.89 \\ 
  pop\_growth\_2013 & -82.44 & -84.69 \\ 
   \hline
\end{tabular}
\caption{Balance Table (1)}
\label{baltab1}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lrr}
  \hline
variable & Unweighted Difference & Weighted Difference \\ 
  \hline
  race\_white\_pct & 1.49 & -1.00 \\ 
  repub\_gov & 65.02 & 16.91 \\ 
  repub\_lower\_control & 74.91 & 18.41 \\ 
  repub\_total\_control & 73.72 & 20.00 \\ 
  student\_pct & -0.18 & 0.61 \\ 
  three\_plus\_child\_pct & 0.00 & 0.10 \\ 
  two\_child\_pct & -0.63 & 0.40 \\ 
  unemployed\_pct\_2011 & -0.83 & -0.10 \\ 
  unemployed\_pct\_2012 & -0.85 & 0.10 \\ 
  unemployed\_pct\_2013 & -0.61 & 0.10 \\ 
  urban\_pct & -6.52 & 2.00 \\ 
   \hline
\end{tabular}
\caption{Balance Table (2)}
\label{baltab2}
\end{table}

Tables \ref{oatedist1} and \ref{oatedist2} display the difference in means from the overlap region (calculated on our preferred adjusted datasets) and the treated and untreated regions (unweighted). 

\begin{table}[ht]
\centering
\begin{tabular}{lrr}
  \hline
Variable & Distance from Control & Distance from Treatment \\ 
  \hline
age\_cat2\_19\_29\_pct & -1.41 & -1.03 \\ 
  age\_cat2\_30\_39\_pct & -0.90 & -1.12 \\ 
  age\_cat2\_40\_49\_pct & 0.31 & -0.06 \\ 
  avg\_adult\_hh\_ratio & -3.99 & -14.93 \\ 
  citizenship\_pct & 1.71 & 5.25 \\ 
  disability\_pct & 0.27 & 1.72 \\ 
  educ\_hs\_degree\_pct & 1.26 & 4.49 \\ 
  educ\_less\_than\_hs\_pct & -1.76 & -1.25 \\ 
  educ\_some\_college\_pct & 0.41 & 0.65 \\ 
  female\_pct & -0.10 & 0.24 \\ 
  foreign\_born\_pct & -2.29 & -9.74 \\ 
  hins\_unins\_pct\_2011 & -0.98 & -0.06 \\ 
  hins\_unins\_pct\_2012 & -3.55 & -0.19 \\ 
  hins\_unins\_pct\_2013 & -5.43 & -0.66 \\ 
  hispanic\_pct & -4.43 & -8.79 \\ 
  inc\_pov2\_138\_pct & -1.44 & 0.63 \\ 
  inc\_pov2\_139\_299\_pct & 0.34 & 2.12 \\ 
  inc\_pov2\_300\_499\_pct & 0.11 & 1.68 \\ 
  inc\_pov2\_500\_plus\_pct & 1.22 & -4.68 \\ 
  married\_pct & 1.31 & 2.27 \\ 
  missing\_children\_pct & -0.85 & 2.41 \\ 
  one\_child\_pct & -0.12 & -1.09 \\ 
  pop\_growth\_2012 & 5.40 & 1.15 \\ 
  pop\_growth\_2013 & 4.73 & 1.24 \\ 
   \hline
    \end{tabular}
    \caption{Overlap region distance from treated, control regions (1)}
    \label{oatedist1}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lrr}
  \hline
Variable & Distance from Control & Distance from Treatment \\ 
  \hline
  race\_white\_pct & 4.47 & 8.34 \\ 
  repub\_gov & -11.05 & 53.97 \\ 
  repub\_lower\_control & -4.99 & 69.92 \\ 
  repub\_total\_control & -16.04 & 57.68 \\ 
  student\_pct & -0.39 & -0.75 \\ 
  three\_plus\_child\_pct & -0.12 & -0.21 \\ 
  two\_child\_pct & -0.38 & -0.85 \\ 
  unemployed\_pct\_2011 & 0.23 & -0.53 \\ 
  unemployed\_pct\_2012 & 0.41 & -0.69 \\ 
  unemployed\_pct\_2013 & -0.60 & -0.65 \\ 
  urban\_pct & -4.64 & -12.72 \\ 
   \hline
\end{tabular}
\caption{Overlap region distance from treated, control regions (2)}
\label{oatedist2}
\end{table}

\subsection{Appendix C: Additional Results}

Table \ref{maintable1} displays the point estimates from all estimators as well as confidence intervals calculated either (a) leave-one-state-out jackknife on the imputed dataset (CI Data); (b) leave-one-state-out jackknife repeating the entire imputation leaving each state out (CI Proc). In general the second set of confidence intervals are much larger. 

This table also includes the Oaxaca-Blinder weights (OB and H-OB), and also all analyses calculated on a second version of the imputed data where we use a common $\kappa$ for all values (sigma\_uu\_avg), which is the imputation suggested by \cite{carroll2006measurement}. Notice that they are identical for ``sigma\_zero'' because this is the unadjusted dataset. ``sigma\_uu\_i'' is our preferred imputation that we report results from in the paper.

\begin{table}[ht]
\centering
\begin{tabular}{llrll}
  \hline
Estimator & Sigma Estimate & Psihat & CI Data & CI Proc \\ 
  \hline
BC-HSBW & sigma\_uu\_i & -1.89 & (-2.54, -1.24) & (-3.45, -0.33) \\ 
  BC-HSBW & sigma\_uu\_avg & -1.61 & (-2.2, -1.01) & (-5.41, 2.2) \\ 
  BC-HSBW & sigma\_zero & -2.50 & (-3.41, -1.58) & (-3.41, -1.58) \\ 
  BC-SBW & sigma\_uu\_i & -1.77 & (-2.37, -1.17) & (-3.26, -0.28) \\ 
  BC-SBW & sigma\_uu\_avg & -1.58 & (-2.21, -0.94) & (-6.35, 3.2) \\ 
  BC-SBW & sigma\_zero & -2.37 & (-3.1, -1.64) & (-3.1, -1.64) \\ 
  H-OB & sigma\_uu\_i & -1.58 & (-2.16, -1) & (-2.75, -0.42) \\ 
  H-OB & sigma\_uu\_avg & -1.42 & (-2.21, -0.64) & (-5.38, 2.53) \\ 
  H-OB & sigma\_zero & -2.55 & (-3.31, -1.78) & (-3.31, -1.78) \\ 
  H-SBW & sigma\_uu\_i & -1.89 & (-3.37, -0.41) & (-3.89, 0.11) \\ 
  H-SBW & sigma\_uu\_avg & -1.95 & (-3.51, -0.39) & (-4.02, 0.12) \\ 
  H-SBW & sigma\_zero & -2.26 & (-3.23, -1.29) & (-3.23, -1.29) \\ 
  OB & sigma\_uu\_i & -1.53 & (-2.1, -0.96) & (-2.91, -0.16) \\ 
  OB & sigma\_uu\_avg & -1.40 & (-2.07, -0.72) & (-6.67, 3.88) \\ 
  OB & sigma\_zero & -2.47 & (-3.11, -1.83) & (-3.11, -1.83) \\ 
  SBW & sigma\_uu\_i & -1.76 & (-3.36, -0.16) & (-4.02, 0.49) \\ 
  SBW & sigma\_uu\_avg & -1.89 & (-3.41, -0.37) & (-4.15, 0.37) \\ 
  SBW & sigma\_zero & -2.25 & (-3.34, -1.16) & (-3.34, -1.16) \\ 
   \hline
\end{tabular}
\caption{Primary point estimates and confidence intervals}
\label{maintable1}
\end{table}

Table \ref{pointesttable} presents all versions of the estimators that we calculated. The variables excluded column indicates which variables were excluded from the estimation: 0 includes all variables; 1 removes Republican governance indicators; 2 pre-treatment uninsurance and unemployment rates; 3 urban, age, education, citizenship, marital status, student, disability, or female; 4 race, ethnicity, income, foreign born; 5 children, population growth, and household to person ratio.

\begin{table}[ht]
\centering
\begin{tabular}{rlrrrrrr}
  \hline
Variables Excluded & Sigma Estimate & BC-HSBW & BC-SBW & H-OB & H-SBW & OB & SBW \\ 
  \hline
0 & sigma\_uu\_i & -1.89 & -1.77 & -1.58 & -1.89 & -1.53 & -1.76 \\ 
  0 & sigma\_uu\_avg & -1.61 & -1.58 & -1.42 & -1.95 & -1.40 & -1.89 \\ 
  0 & sigma\_zero & -2.50 & -2.37 & -2.55 & -2.26 & -2.47 & -2.25 \\ 
  1 & sigma\_uu\_i & -2.61 & -2.27 & -2.73 & -2.53 & -2.45 & -2.63 \\ 
  1 & sigma\_uu\_avg & -2.76 & -2.28 & -3.03 & -2.59 & -2.44 & -2.67 \\ 
  1 & sigma\_zero & -2.99 & -2.71 & -2.98 & -2.90 & -2.67 & -2.95 \\ 
  2 & sigma\_uu\_i & -4.69 & -4.39 & -4.58 & -5.59 & -4.22 & -5.20 \\ 
  2 & sigma\_uu\_avg & -4.68 & -4.39 & -4.54 & -5.66 & -4.18 & -5.33 \\ 
  2 & sigma\_zero & -5.46 & -5.15 & -5.46 & -5.61 & -5.15 & -5.19 \\ 
  3 & sigma\_uu\_i & -1.80 & -1.68 & -1.59 & -1.91 & -1.56 & -1.84 \\ 
  3 & sigma\_uu\_avg & -1.56 & -1.48 & -1.46 & -1.92 & -1.44 & -1.82 \\ 
  3 & sigma\_zero & -2.00 & -1.99 & -2.13 & -2.16 & -2.14 & -2.22 \\ 
  4 & sigma\_uu\_i & -2.04 & -1.90 & -2.00 & -2.10 & -1.99 & -1.92 \\ 
  4 & sigma\_uu\_avg & -1.80 & -1.73 & -1.64 & -2.24 & -1.60 & -2.21 \\ 
  4 & sigma\_zero & -2.50 & -2.37 & -2.61 & -2.23 & -2.59 & -2.19 \\ 
  5 & sigma\_uu\_i & -2.50 & -2.50 & -2.73 & -1.84 & -2.81 & -1.91 \\ 
  5 & sigma\_uu\_avg & -2.47 & -2.43 & -2.42 & -1.88 & -2.45 & -1.92 \\ 
  5 & sigma\_zero & -2.44 & -2.44 & -2.64 & -2.14 & -2.58 & -2.23 \\ 
   \hline
\end{tabular}
\label{pointesttable}
\caption{Point estimates by estimator, primary dataset}
\end{table}

Table \ref{pointesttablec2} is identical to the structure of Table \ref{pointesttable} except we exclude the ``early expansion states.''

\begin{table}[ht]
\centering
\begin{tabular}{rlrrrrrr}
  \hline
Variables Excluded & Sigma Estimate & BC-HSBW & BC-SBW & H-OB & H-SBW & OB & SBW \\ 
  \hline
0 & sigma\_uu\_avg & -2.25 & -2.48 & -2.59 & -1.33 & -2.58 & -1.30 \\ 
  0 & sigma\_uu\_i & -2.52 & -2.40 & -2.89 & -1.53 & -2.88 & -1.41 \\ 
  0 & sigma\_zero & -2.27 & -2.14 & -2.53 & -1.73 & -2.49 & -1.58 \\ 
  1 & sigma\_uu\_avg & -1.90 & -1.74 & -1.74 & -1.91 & -1.65 & -1.69 \\ 
  1 & sigma\_uu\_i & -1.78 & -1.72 & -1.75 & -1.35 & -1.71 & -1.32 \\ 
  1 & sigma\_zero & -2.53 & -2.42 & -2.70 & -1.83 & -2.66 & -1.76 \\ 
  2 & sigma\_uu\_avg & -1.95 & -1.69 & -1.68 & -1.99 & -1.52 & -1.84 \\ 
  2 & sigma\_uu\_i & -1.91 & -1.73 & -1.87 & -1.86 & -1.79 & -1.78 \\ 
  2 & sigma\_zero & -2.55 & -2.41 & -2.81 & -1.93 & -2.68 & -1.95 \\ 
  3 & sigma\_uu\_avg & -2.74 & -2.43 & -2.87 & -2.59 & -2.55 & -2.65 \\ 
  3 & sigma\_uu\_i & -2.64 & -2.35 & -2.63 & -2.57 & -2.55 & -2.60 \\ 
  3 & sigma\_zero & -3.14 & -2.83 & -3.05 & -2.87 & -2.91 & -2.83 \\ 
  4 & sigma\_uu\_avg & -4.74 & -4.60 & -4.40 & -5.59 & -4.32 & -5.11 \\ 
  4 & sigma\_uu\_i & -4.70 & -4.54 & -4.40 & -5.54 & -4.34 & -5.02 \\ 
  4 & sigma\_zero & -5.31 & -5.14 & -5.04 & -5.53 & -5.13 & -5.01 \\ 
  5 & sigma\_uu\_avg & -1.72 & -1.62 & -1.50 & -1.90 & -1.47 & -1.69 \\ 
  5 & sigma\_uu\_i & -1.69 & -1.63 & -1.55 & -1.36 & -1.51 & -1.21 \\ 
  5 & sigma\_zero & -1.82 & -1.75 & -2.20 & -1.77 & -2.11 & -1.75 \\ 
   \hline
\end{tabular}
   \caption{Point estimates for all specifications, early expansion excluded}
   \label{pointesttablec2}
\end{table}

Table \ref{oatearea} displays all point estimates and corresponding confidence intervals calculate for the OATE.

\begin{table}[ht]
\centering
\begin{tabular}{rlrll}
  \hline
Psihat & Sigma Estimate & Variables Subset & CI Data & CI Proc \\ 
  \hline
-1.64 & sigma\_uu\_i & 0.00 & (-2.41, -0.88) & (-2.51, -0.77) \\ 
  -1.58 & sigma\_avg & 0.00 & (-2.18, -0.98) & (-2.42, -0.74) \\ 
  -1.80 & sigma\_zero & 0.00 & (-2.49, -1.1) & (-2.49, -1.1) \\ 
  -2.60 & sigma\_uu\_i & 1.00 & (-3.57, -1.64) & (-3.74, -1.47) \\ 
  -2.62 & sigma\_avg & 1.00 & (-3.67, -1.57) & (-3.83, -1.42) \\ 
  -2.55 & sigma\_zero & 1.00 & (-3.44, -1.66) & (-3.44, -1.66) \\ 
  -2.96 & sigma\_uu\_i & 2.00 & (-5.41, -0.51) & (-6.16, 0.24) \\ 
  -2.85 & sigma\_avg & 2.00 & (-5.28, -0.42) & (-5.61, -0.09) \\ 
  -3.11 & sigma\_zero & 2.00 & (-5.59, -0.63) & (-5.59, -0.63) \\ 
  -1.86 & sigma\_uu\_i & 3.00 & (-2.98, -0.74) & (-3.18, -0.54) \\ 
  -1.76 & sigma\_avg & 3.00 & (-3.03, -0.48) & (-3.06, -0.45) \\ 
  -1.98 & sigma\_zero & 3.00 & (-2.71, -1.24) & (-2.71, -1.24) \\ 
  -1.86 & sigma\_uu\_i & 4.00 & (-2.52, -1.21) & (-2.93, -0.8) \\ 
  -1.76 & sigma\_avg & 4.00 & (-2.55, -0.98) & (-2.7, -0.83) \\ 
  -1.94 & sigma\_zero & 4.00 & (-2.7, -1.18) & (-2.7, -1.18) \\ 
  -1.77 & sigma\_uu\_i & 5.00 & (-3.05, -0.5) & (-11.85, 8.3) \\ 
  -1.78 & sigma\_avg & 5.00 & (-2.67, -0.88) & (-2.69, -0.86) \\ 
  -1.83 & sigma\_zero & 5.00 & (-2.61, -1.04) & (-2.61, -1.04) \\ 
   \hline
\end{tabular}
   \caption{OATE treatment effect estimates and inference, primary dataset}
   \label{oateprimary}
\end{table}



Table \ref{oatesensitive} presents all point estimates calculate using the overlap weights.

\begin{table}[ht]
\centering
\begin{tabular}{lrrr}
  \hline
Sigma Estimate & Variables Subset & Early Expansion Removed & Preferred \\ 
  \hline
sigma\_uu\_i & 0 & -1.81 & -1.64 \\ 
  sigma\_avg & 0 & -1.74 & -1.58 \\ 
  sigma\_zero & 0 & -1.95 & -1.80 \\ 
  sigma\_uu\_i & 1 & -2.53 & -2.60 \\ 
  sigma\_avg & 1 & -2.54 & -2.62 \\ 
  sigma\_zero & 1 & -2.51 & -2.55 \\ 
  sigma\_uu\_i & 2 & -3.10 & -2.96 \\ 
  sigma\_avg & 2 & -3.00 & -2.85 \\ 
  sigma\_zero & 2 & -3.25 & -3.11 \\ 
  sigma\_uu\_i & 3 & -2.18 & -1.86 \\ 
  sigma\_avg & 3 & -2.10 & -1.76 \\ 
  sigma\_zero & 3 & -2.12 & -1.98 \\ 
  sigma\_uu\_i & 4 & -2.04 & -1.86 \\ 
  sigma\_avg & 4 & -1.96 & -1.76 \\ 
  sigma\_zero & 4 & -2.10 & -1.94 \\ 
  sigma\_uu\_i & 5 & -1.96 & -1.77 \\ 
  sigma\_avg & 5 & -1.95 & -1.78 \\ 
  sigma\_zero & 5 & -2.00 & -1.83 \\ 
   \hline
\end{tabular}
\caption{OATE sensitivity analyses}
\label{oatesensitive}
\end{table}


\subsection{Appendix D: SBW Program Details}

We implement SBW using a modification of Noah Griefer's ``optweight'' package available in R. The modifications are available on ``github.com/mrubinst757'', but are not documented. We use this program to generate weights that balance the means of the following covariates in the treated group to the control group within an error tolerance, $\delta$. When estimating the weights on different subsets of the data, $\delta^\star$ is not guaranteed to converge. We therefore modify the program so that if it does converge, it relaxes some of the constraints until the program converges. The program is available on github.com/mrubinst757/Medicaid-Expansion-Project/03\_RPrograms/03\_Analysis/02\_model-estimation.R and all R programs used to complete this analysis are available in the parent directory.

\end{document}






