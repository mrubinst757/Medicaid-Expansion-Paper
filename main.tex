\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
%\usepackage{nips_2017}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{booktabs}
\usepackage{float}
\usepackage{amsmath}
\usepackage{psfrag}
\usepackage{epsf}
\usepackage{enumerate}

%\bibliographystyle{apalike}

%\bibliographystyle{unsrt} % Use for unsorted references 
\newcommand{\blind}{0}

%\bibliographystyle{plainnat} % use this to have URLs listed in References

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

% Title Page

\bibliographystyle{natbib}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\if0\blind
{
  \title{\bf The Effect of Medicaid Expansion on Non-Elderly Adult Uninsurance Rates Among States that did not Expand Medicaid}
  \author{Max Rubinstein \hspace{.2cm}\\
    and \\
    Amelia Haviland \\ \\
    Heinz College and the Department of Statistics and Data Science \\ Carnegie Mellon University}
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
  \title{\bf The Effect of Medicaid Expansion on Non-Elderly Adult Uninsurance Rates Among States that did not Expand Medicaid}
\end{center}
  \medskip
} \fi

\bigskip

\begin{abstract}

We estimate the effect of Medicaid expansion on the adult uninsurance rates in states that did not expand Medicaid in 2014 (ETC) using a novel extension of the synthetic controls approach (\cite{abadie2010synthetic}). Previous literature estimates treatment effects on states that expanded Medicaid (ETT). We hypothesize these effects differ: evidence suggests that Medicaid take-up rates are lower among conservative states, and Republicans were more likely to govern non-expansion states. We hypothesize that the ETC is closer to zero than the ETT. Using data from the American Communities Survey (ACS), we estimate the effect on non-expansion states by re-weighting expansion regions to approximately balance the covariates from non-expansion regions. We contribute to the literature on balancing weights by accounting for hierarchical data and measurement error in the covariates in our estimation. We find that Medicaid expansion would have changed the uninsurance rate by -2.14 percentage points (-3.57, -0.71). These results are smaller in absolute magnitude than existing estimates of the ETT. We provide evidence that factors associated with Republican governance may drive this difference.

\end{abstract}

\noindent%
{\it Keywords:} Balancing weights, synthetic controls, measurement error, regression calibration, treatment effect on the controls, Medicaid expansion, uninsurance rates
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\maketitle

\section{Introduction}

The 2010 Affordable Care Act (ACA) required states to expand their Medicaid eligibility requirements by 2014 to offer coverage to all adults with incomes at or below 138 percent of the federal poverty level (FPL). The United States Supreme Court ruled this requirement unconstitutional in 2012, allowing states to decide whether to expand Medicaid coverage. In 2014, twenty-six states and the District of Columbia expanded their Medicaid programs. From 2015 through 2019 an additional ten states elected to expanded their Medicaid programs (\cite{KFF}). This first wave of expansions in 2014 enabled researchers to examine the effects of Medicaid expansion by using expansion states as ``treated'' states, and non-expansion states as ``control'' states. Our goal is to model the effect of 2014 Medicaid expansion on non-elderly adult uninsurance rates among states that did not expand Medicaid.

We predict that the treatment effect on non-expansion effect will be smaller in absolute magnitude than in states that expanded Medicaid in 2014. Medicaid take-up rates are lower than 100 percent and historically have varied across states (\cite{sommers2012understanding}). This variation is partly a function of state discretion in administering programs: for example, program outreach, citizenship verification policies, and application processes differ across states (\cite{courtemanche2017early}). Here we consider how political composition may have driven differences in take-up rates between states. Prior to the 2014 Medicaid expansion, \cite{sommers2012understanding} found that conservative political ideology was associated with lower Medicaid enrollment take-up rates, even after controlling for a variety of correlated policies. Most importantly, political ideology appears to have largely driven a state's decision to expand Medicaid in 2014. Figure \ref{fig1} plots a measure of each state's 2013 institutional ideology by their Medicaid expansion status (\cite{fording}). Higher values of this score correspond to more liberal government institutions. The red dashed line indicates the mean expansion state score and the gray dashed line indicates the mean non-expansion state score. Figure \ref{fig1} illustrates that non-expansion states are more conservative than expansion states.  If these differential take-up rates observed by \cite{sommers2012understanding} continue to hold post-expansion, we should expect treatment effects on non-expansion states to be smaller in absolute magnitude than treatment effects on expansion states. 

\begin{figure}
    \begin{center}
    \includegraphics[scale=0.7]{01_Plots/political-expansion-plot.png}
    \caption{Government ideology and Medicaid expansion}
    \label{fig1}
    \end{center}
\end{figure}

This paper makes several methodological contributions. First, we extend the ``synthetic controls'' framework to estimate the treatment effect on the controls (ETC) and to clarify the required assumptions. While balancing on pre-treatment outcomes alone arguably suffices for some synthetic control applications (see, eg, \cite{botosaru2017role}), here we want to estimate treatment response. We therefore assume no unmeasured confounding given a rich covariate set and a linear and additive outcome model that accounts for all interactions between treatment and the covariates. Secondly, we use an implementation of Stable Balancing Weights (\cite{zubizarreta2015stable}) to estimate a set of positive weights to weight the expansion regions to approximately match the covariate distribution of the non-expansion regions. To account for remaining imbalances in the covariates, we also augment these weights with a regression-model following \cite{ben2018augmented}.

Our second contribution is to modify Stable Balancing Weights (SBW) for this setting. In particular, the SBW objective performs well assuming independent data with no measurement error. However, we use data from the American Communities Survey (ACS) aggregated to the consistent public use microdata area (CPUMA) level. These regions nest within states, and using these smaller regions allows us to get better balance on our covariates. However, as a result, our data both has a hierarchical structure (regions within states) and, because our region-level covariates are estimated from underlying survey data, we also have measurement error in the covariates which may bias our treatment effect estimates. We propose a modification of the SBW objective function to account for the hierarchical nature of the data. We leverage the replicate survey weights provided in the ACS data to estimate the covariance matrix associated with this variability and use this information to correct for this bias, following the regression calibration literature CITE. This is the first study we are aware of that attempts to correct for sampling variability in the covariates when using balancing weights. 

The remainder of this paper has the following structure. Section II provides an overview of the data and defines the study period, outcome, covariates, and treatment. Section III discusses our methods, beginning by defining our target estimand, and then outlining our identification, estimation, and inferential procedures. Section IV presents our primary results and sensitivity analyses. Section V provides a brief discussion of the policy relevance of our findings, and Section VI contains a brief concluding summary of the paper. Supplemental materials may be found in the Appendices.

\section{Data}

Our data source is the annual household and person public use microdata files from the American Community Survey (ACS) from 2011 through 2014. The ACS is an annual survey of approximately three million individuals across the United States. The public use microdata files include information on individuals in geographic areas greater than 65,000 people. The smallest geographic unit contained in these data are public-use microdata areas (PUMAs), arbitrary boundaries that nest within states but not within counties or other more commonly used geographic units. One limitation of these data is a 2012 change in the PUMA boundaries, which do not overlap well with the previous boundaries. As a result, the smallest possible geographic areas that nest both PUMA coding systems are known as consistent PUMAs (CPUMAs). The United States contain 1,075 total CPUMAs, with states ranging from having one CPUMA (South Dakota, Montana, and Idaho) to 123 CPUMAs (New York). The total number of sampled individuals per CPUMA across the four years within our primary dataset of 929 CPUMAs (discussed in Section \ref{sssec:txassign}) is 1,001; the minimum number of people sampled was 334 and the maximum is 23,990.

\subsection{Study period}

We begin our analysis in 2011 following \cite{courtemanche2017early}, who note that several other aspects of the ACA were implemented in 2010 -- including the provision allowing for dependent coverage until age 26, and the elimination of co-payments for preventative care -- likely induced differential shocks across states. We also restrict our post-treatment period to 2014 only: several additional states expanded Medicaid in 2015, including Indiana, Michigan, and Pennsylvania. However, these states did not expand Medicaid contemporaneously with the 2014 ACA provisions. Without additional assumptions, this second-year expansion therefore represents a different causal estimand. 

\subsection{Covariates}

We use the underlying individual-level ACS survey data and accompanying survey weights to aggregate the data at the CPUMA level. We choose our covariates to approximately align with those considered in \cite{courtemanche2017early} and that are likely to be believe are potential confounders. Because we are ultimately interested in calculating rates, these variables include both the numerator and denominator counts of the corresponding rates.\footnote{We note that these ratio estimators will in general be biased; however, this bias decreases very quickly with the sample size; given that our CPUMA sample sizes are all over 300 we treat these as unbiased for the purposes of this analysis.}

The denominator counts include: total non-elderly adult population for each year 2011-2014; total labor force for each year 2011-2013; and the total number of households averaged from 2011-2013. We then calculate the total number of: females; whites; people born outside of the United States; citizens; people with less than high school education, high school degrees, some college, or college graduates or higher; people living under 138 percent of the FPL, between 139 and 299 percent, 300 and 499 percent, and more than 500 percent; total number aged 19-29, 30-39, 40-49, 50-64; households with one or more children, and no information about children reported. We then average these counts from 2011-2013. For each individual year from 2011-2013, we also calculate the total number of people who were: unemployed, uninsured, and in the labor force at the time of the survey (calculated among all non-elderly adults). We divide the numerator counts by the corresponding denominator counts to estimate the percentage in each category. For the demographics, these include the average number of non-elderly adults from 2011-2013. For the time-varying variables, we use the corresponding year (uninsurance rates are calculated as a fraction of the labor force rather than the non-elderly adult population). We also calculate the 2011-2012 and 2012-2013 population growth, and the average number of households to adult from 2011-2013. 

In addition to the ACS microdata, we use Census data to calculate the approximate percentage of people living within an ``urban'' area for each CPUMA (\cite{census}). Finally, we include three state-level covariates reflecting the partisan composition of each state's government in 2013. Specifically, we include an indicator for having a Republican governor, an indicator for Republican control over the lower legislative chamber, and an indicator for Republican control over both chambers of the legislature and the governorship.\footnote{Nebraska is the only state with a unicameral legislature; moreover, the legislature is technically non-partisan. We nevertheless classified them as having a Republican control of the legislature.} 

\subsection{Outcome}

Our primary outcome of interest $Y$ is the non-elderly adult uninsurance rate in 2014. We might consider take-up rates among the Medicaid-eligible population to be a more natural outcome. However, we choose the non-elderly adult uninsurance rate for two reasons, one theoretic and one practical. First, Medicaid eligibility in the post-period is likely endogenous: Medicaid expansion may affect an individual's income and poverty levels, which define Medicaid eligibility. A second reason is to align our study to compare our results with the existing literature, and this is the outcome that \cite{courtemanche2017early} use. One implication of using this outcome is that the simultaneous adoption of other ACA provisions in 2014 more clearly affects this rate in a way that a more targeted group might not.

\subsection{Treatment assignment} \label{sssec:txassign}

While some states expanded Medicaid and other states did not, in reality assigning a binary treatment status simplifies a more complex reality. There are three reasons to be cautious about this simplification. First, states differed substantially in prior Medicaid coverage policies: with perfect data we might consider Medicaid expansion as a continuous treatment with values proportional to the number of newly eligible individuals. The challenge though is correctly identifying newly eligible individuals in the data (see \cite{frean2017premium}, who attempt to address this). Second, \cite{frean2017premium} note that five states (California, Connecticut, Minnesota, New Jersey, and Washington) and the District of Columbia adopted partial limited Medicaid expansions prior to 2014. \cite{kaestner2017effects} and \cite{courtemanche2017early} also consider Arizona, Colorado, Hawaii, Illinois, Iowa, Maryland, and Oregon to have had early expansions. Lastly, timing is an issue: among the states that expanded Medicaid in 2014, Michigan's expansion did not go into effect until April 2014, while New Hampshire's expansion did not occur until September 2014.

Our primary analysis excludes New York, Vermont, Massachusetts, Delaware, and the District of Columbia from our pool of expansion states, because these states had comparable Medicaid coverage policies prior to 2014 (\cite{kaestner2017effects}). We also exclude New Hampshire because it did not expand Medicaid until September 2014. While Michigan expanded Medicaid in April 2014, we leave this state in our treated pool. We consider the remaining expansion states as ``treated'' and the non-expansion states as ``control'' states. We later consider the sensitivity of our results to these classifications by removing the early expansion states noted by \cite{frean2017premium}. Our primary classification of expansion and non-expansion states is unique among similar studies: \cite{courtemanche2017early} classifies all expansion states as treated, and all non-expansion states as control. \cite{frean2017premium} exclude Massachusetts from expansion states. Lastly, \cite{kaestner2017effects} include Delaware, the District of Columbia, Massachusetts, New York, and Vermont as control states. Our final dataset contains aggregated statistics for all of the above variables for 925 CPUMAs in our non-expansion and our pool of expansion states. 414 CPUMAs among 24 non-expansion states and 515 CPUMAs among 22 expansion states. When we exclude the early expansion states, we are left with 296 CPUMAs across 17 states.

\section{Methods}
\label{sec:methods}

In this section we present our causal estimand, identifying assumptions, estimation strategy, and inferential procedure. Additional details are available in the Appendix.

\subsection{Estimand}

We seek to estimate the average effect 2014 Medicaid expansion would have had on the non-elderly adult uninsurance rate in states that did not expand Medicaid.\footnote{We condition on the observed treatment assignment and therefore treat this variable as fixed in our analysis.} The 2014 Medicaid expansion occurred simultaneously with the implementation of several other major ACA provisions, including (but not limited to) the creation of the ACA-marketplace exchanges, the individual mandate, health insurance subsidies, and community-rating and guaranteed issue of insurance plans (\cite{courtemanche2017early}). Almost all states broadly implemented these reforms beginning January 2014. Conceptually we think of the other ACA components as a state-level treatment ($V$) separate from Medicaid expansion ($A$).

Let $i$ index a CPUMA, $j$ index the state, and $T$ index the time period. Let $N_1$ be the number of treated CPUMAs, $N_0$ be the number of control CPUMAs, and $N$ be the total number of CPUMAs. Similarly, let and $M = M_0 + M_1$ states (with $M_0$ and $M_1$ defined analogously). Each state has $n_j$ CPUMAs. Finally, let $Y_{ijT}^{A_{ijT} = a, V_{ijT} = v}$ be the potential uninsurance rate given Medicaid expansion and other ACA-reforms at time $T = 2014$. We then wish to estimate the following contrast:

$$
\psi &= \psi^1 - \psi^0 \\
&=N_0^{-1}\sum_{j: A_{jT} = 0, V_{jT} = 1}^{M_0}\sum_{i = 1}^{n_j} Y_{ijT}^{A_{ijT} = 1, V_{ijT} = 1} - Y_{ijT}^{A_{ijT} = 0, V_{ijT} = 1} 
$$

In other words, we want to estimate the difference in the non-elderly adult uninsurance rates among states that did not expand Medicaid, but did implement other aspects of the ACA. Because all states implemented the ACA marketplace expansion in 2014, contrasts with the corresponding potential outcome absent this expansion are not identified. Moreover, since we are only interested in the counterfactual at time $T$, we simplify notation by removing this variable and the subscript in the estimand:

$$
\psi = N_0^{-1}\sum_{ij: A_j = 0} Y_{ij}^{A_{ij} = 1} - Y_{ij}^{A_{ij} = 0}
$$

We therefore seek to identify the effect of Medicaid expansion in the context of the simultaneous implementation of the ACA, but do not attempt to separately identify the effects of these separate treatments. Because interactions between the ACA implementation and Medicaid expansion may vary over time, we do not seek to generalize these results outside of 2014. 

\subsection{Identification}

We make the following causal assumptions: consistency, no unmeasured confounding, no anticipatory treatment effects, and positivity of treatment assignment. We explain these assumptions in detail and why we think they might be reasonable in this context. We additionally make several parametric assumptions to help us identify our parameter given the problem of measurement error in our covariates.

Consistency states that the observed factual outcome under a given treatment assignment is equal to the potential outcome under that same treatment assignment ($Y_{ij}^{A_{ij} = a} = Y_{ij} \mid A_{ij} = a$). In other words, we assume that one regions' treatment assignment didn't affect another regions' observed outcome. This is a standard assumption, but often not realistic. Violations of this assumption are likely in our setting: for example, \cite{frean2017premium} find evidence that Medicaid expansion drove previously eligible but uninsured individuals to enroll in Medicaid in both expansion and non-expansion states. Signing the potential bias from these spillovers requires redefining the causal estimand: for example, we might consider the treatment effect on the untreated given that all states have expanded Medicaid, where the contrast is against where only the observed expansion states expanded Medicaid. If spillovers occurred in equal proportions in each region, and the magnitude of the spillovers increase with the number of treated regions, then the true effect would be larger in absolute magnitude than the effect estimated using the observed data. We could consider other estimands or assumptions to get different predictions about the sign of the bias, but we leave this as an area for future work.

We next assume that there were no anticipatory treatment effects. Letting treatment occur at time $T_0 + 1$, we have that for $t \le T_0$:

$$
Y_{ijt} = Y_{ijt}^0
$$

This assumption is necessary because we are conditioning on pre-treatment outcomes. If these outcomes were affected by the treatment before it were implemented, these covariates would not be exogenous. Anticipatory treatment effects may occur if plans to expand Medicaid induce uninsured but Medicaid-eligible individuals to enroll in Medicaid prior to expansion. We do not think these violations occurred in large enough numbers to substantially affect our results. Instead, we address a more concerning version of this violation: as noted above, several states allowed certain counties to expand Medicaid prior to 2014. We therefore test the sensitivity of our results to the inclusion of these states.

Third, we assume no unmeasured confounding; that is, that at time $T$ the potential outcomes for each CPUMA are independent of the state-level treatment assignment conditional on the population-level CPUMA and state-level covariates $X_{ij}$ (which includes pre-treatment outcomes):

$$
Y_{ij}^a \perp A_{ij} \mid X_{ij}
$$

While unverifiable, we believe it is reasonable here given our rich covariate set. To be explicit, we believe that the uninsurance rate for each region given treatment is independent of the region's treatment assignment conditional on the percentage of uninsured individuals in the pre-treatment period, the percentage of unemployed individuals in the pre-treatment period, the population growth in 2012 and 2013, the average ratio of households to total population, the state's political composition, the average proportion of households with one or more children during the pre-treatment period, the average number of households who did not respond about children, and the average proportion of individuals during the pre-treatment period with given demographics noted above (age, sex, white, Hispanic ethnicity, US citizenship, foreign born, income-to-poverty group (including non-response), disability status, urban residence, and educational attainment group). If this assumption were violated -- that is, other covariates exist that determine this potential outcome and treatment assignment -- conditioning on pre-treatment outcomes is likely to help proxy for these covariates, thereby minimizing the potential for bias. 

Having said that, we do not actually observe the true values of $X_{ij}$ but rather an estimate $W_{ij}$. Importantly, $Y_{ij}^a \perp A_{ij} \mid X_{ij} \not\implies Y_{ij}^a \perp A_{ij} \mid W_{ij}$. Therefore, the use of these proxies may also bias our estimates. We rely on several modeling assumptions outlined below in our estimation procedure to correct for this bias.

Finally, we assume positivity of treatment assignment; that is, that all states had some probability of being treated $\pi(X_{1j}, ..., X_{n_jj}) > 0$. Positivity violations can cause a lack of covariate overlap in the observed data. As we have noted before, overlap is an issue in this study. We address this in multiple ways that we outline in our estimation strategy below. 
These assumptions are sufficient to non-parametrically identify our causal estimand if we observed the true covariates $X_{ij}$. We next invoke parametric modeling assumptions that help us identify our estimand given that we observe the  mean unbiased sample estimates $W_{ij}$. First, we assume that the potential outcome under treatment is linear and additive in the covariates $X_{ij}$. Specifically, we assume that the following model generates the potential non-elderly adult uninsurance rate under treatment:

$$
Y_{ij}^1 = \alpha + X_{ij}^T\beta + \epsilon_{ij} + c_{j}
$$

We assume that the errors $\epsilon_{ij}$ and $c_j$ are independent from each other and across time (ie we rule out serial-correlation), and that these errors are invariant under the intervention. This model then allows us to rewrite $\psi^1$ as $\alpha + \mu_0^T\beta$, where $\mu_0$ is the (observed) mean among the control units.\footnote{To be precise, we use the population-weighted mean so as to target the individual-level treatment effect rather than the CPUMA-average treatment effect.} Let $s_{ij}$ be the vector of sample sizes used to calculate $W_{ij}$. We then assume that that $W_{ij} = X_{ij} + v_{ij}$, where $\sqrt{s_{ij}}v_{ij}$ are drawn independently from $MVN(0, \Sigma_{vv})$, and $v_{ij}$ and $\epsilon_{ij}$ are independent.  These are reasonable assumptions in our context because we do not believe the errors in the CPUMA level aggregates are correlated and because the outcomes are estimated from a different cross-section of individuals than the covariates. Moreover, because the measurement error comes from sampling variability, assuming that the error is normally distributed is reasonable.\footnote{While the sample sizes for each CPUMA are all relatively large, the variance is still higher than one might expect due to the design effect of the survey.} These parameters, and therefore the causal estimand, are identified if we further assume that $X_{ij} \mid A_j = 1$ are drawn iid from a normal distribution and we know $\Sigma_{vv}$ \cite{gleser1992importance}.\footnote{Although we view our parameter as conditional on the true covariates, \cite{gleser1992importance} (Theorem 2) shows that under some milder assumptions, even when we view the covariates as fixed and $X_{ij}$ is non-normal, we can still consistently estimate $\alpha$ and $\beta$ using estimates of $\Sigma_{vv}$.} We discuss this further in Appendix A, while connecting these results to weighting estimators that directly estimate $\psi^1$ rather than outcome models that estimate $(\alpha, \beta)$. 

\subsection{Estimation}

We outline our estimation strategy first emphasizing how our method differs from the synthetic controls approach. In particular, we explain why estimated the treatment effect on the controls (ETC) must rely on arguably stronger assumptions than the ETT. We then explain these how these assumptions differ from synthetic control applications and why we therefore choose to use an implementation of Stable Balancing Weights (SBW) for our modeling. Second, we explain a modification we make to the SBW criterion (which we call H-SBW) to address the hierarchical data structure and show that it reduces the variance of our estimator under our assumption of within-state correlation of our model errors. Third, we connect our estimator to the regression calibration literature by generating weights that balance on an imputation of the true covariates $\hat{\eta}(W_{ij})$. Finally, we explain how due to remaining imbalances, we debias our estimator using ridge-augmented weights, following the suggestion of \cite{ben2018augmented}. As a sensitivity check, we also use overlap weights, to estimate a different parameter -- the overlap average treatment effect (OATE) -- as suggested by \cite{li2018balancing}, to check the robustness of our results.

Similar to synthetic controls applications, we seek to generate a set of positive weights that balance the means of covariates for the treated units to the mean of covariates for the control units. Assume that we observe the true covariates $X_1$ and $X_0$, and let $\bar{X}_0^p$ be the (population-weighted) average of the covariate values in the non-expansion region. Ideally, we could then find some $\gamma^\star$ such that: 

$$
(N_0^{-1})X_1^T\gamma^\star = \bar{X}_0^p, \gamma_i^\star > 0, \sum_{ij} \gamma_{ij}^\star = N_0
$$

Let $p$ be a vector of (normalized) population weights for each CPUMA in the non-expansion region in year $T = 2014$. We could then estimate $\psi$ as

$$
\hat{\psi} = (N_0^{-1}\sum_{j: A_j = 1}^{M_1}\sum_{i = 1}^{n_j}\gamma_{ij}^\star Y_{ij} - \sum_{j: A_j = 0}\sum_{i = 1}^{n_j}Y_{ij}p_{ij})
$$

While synthetic controls are frequently motivated by the assumption that the outcomes follow a linear factor model, here we assume no unobserved confounding and that $\mu_1(X_{ij}) = \alpha + X_{ij}^T\beta$. The bias of our estimator is therefore less than or equal to $\beta^T \delta = \beta^T(X_1^T\gamma - \bar{X}_0^p) = 0$ (see, eg, \cite{zubizarreta2015stable}). The challenge, however, is that for any given dataset we have no guarantee that any such $\gamma$ exists that exactly balances the covariates; we therefore need some method of determining how to prioritize which parts of the covariate distribution we wish to balance.

This is where our method to estimate the ETC contrasts with the commonly used synthetic control approach used to estimate the ETT: \cite{abadie2010synthetic} determine how to prioritize covariate balance by training their model on pre-treatment outcomes (\cite{kaul2015synthetic} shows that often the most relevant covariates simply become the pre-treatment outcomes). Because in that setting $Y^0_{ijt}$ is actually observed for $t \le T_0$, \cite{abadie2010synthetic} leverage this data to select the covariates that best predict these values. By contrast we never observe $Y^1_{ijt}$ prior to treatment. Without additional assumptions, we cannot use the pre-treatment data to learn which covariates matter most for determining this potential outcome.

Moreover, the problem of predicting treatment response also makes estimating the ETC more challenging than the ETT. As a result, we may care far more about balancing ``auxillary covariates'' (ie covariates that are not pre-treatment outcomes) in our setting than the traditional synthetic controls setting.\footnote{Recent discussions in the synthetic controls literature often prioritize discussing balancing pre-treatment outcomes alone (see, eg, \cite{doudchenko2016balancing}). This has some theoretic justification: \cite{botosaru2019role} find that when a sufficiently large number of pre-treatment outcomes are available, assuming $\mu_0$ follows a linear factor model, the bias of the estimator is still bounded even if imbalances in auxillary covariates remain.} Consider the following example: say for some application there exist two sets of weights, $\gamma_1$ and $\gamma_2$, that exactly balances $k$ pre-treatment means of the controls units to the treated unit(s). $\gamma_1$ additionally exactly balances $p$ auxillary covariates, while $\gamma_2$ does not. Heuristically, estimates using either set of weights may provide reasonable estimates of the counterfactuals for the treated unit(s) absent treatment. However, once we invert the treatment group of interest assignment -- ie the control units are treated and the treated units control -- and consider predicting the outcome under treatment for those not treated: intuitively, we should choose $\gamma_2$. Why? Because we might worry that these observable characteristics predict not just outcome levels without treatment but also treatment response, and the treatment response of these two units might differ substantially. 

More formally, assume that $\mu_0(X_{ij})$ is linear in the covariates. We might reasonably believe the coefficients on auxillary covariates are close to zero once we condition on pre-treatment outcomes. As a result, the bias induced by imbalances on these covariates would be small. On the other hand, the coefficients on the same covariates for the model $\mu_1(X_{ij})$ could be much larger, even after conditioning on pre-treatment outcomes. If our synthetic control weights fail to balance these covariates, we should expect that our estimates of $\mu_0$ will in general have less bias than our estimates of $\mu_1$. In summary, estimating the ETC requires a greater understanding of how the covariates are related to treatment response than the ETT; moreover, and we cannot learn this information by using pre-treatment outcomes.

We therefore estimate the ETC by using a variation of SBW that we call H-SBW.\footnote{Specifically, we use a modified implementation of Noah Griefer's ``optweight'' package in R, available on github.com/mrubinst757}. This procedure allows us to estimate the minimum variance weights that satisfy certain balance constraints. Let $\eta(W_{ij}) = \mathbb{E}\{X_{ij} \mid W_{ij}, A_j = 1\}$, and $\hat{\eta}(W_1)$ be a matrix of estimates of $\eta(W_1)$. Let $\bar{W}_0^p$ be a vector of population-weighted estimates of the covariates for the non-expansion region.\footnote{Because $\bar{W}_0^p$ is in expectation equal to $\bar{X}_0^p$, the use of this target will not bias our estimator.} We generate weights that solve the following objective:

$$
\min_{\gamma \in \Gamma} \sum_{j: A_j = 1}^{M_1}(\sum_{i = 1}^{n_j} \gamma_{ij}^2 + \sum_{kj \ne ij}\rho \gamma_{ij}\gamma_{kj})
$$

$$
\Gamma := \{\gamma \mid N_0^{-1}\hat{\eta}(W_{ij})^T\gamma - \bar{W}_0^p \mid \le \delta, \gamma_{ij} > 0, \sum_{ij}\gamma_{ij} = N_0\}
$$

Unlike the synthetic controls objective, the SBW objective allows the user to specify covariate-level balance constraints using the vector $\delta$. When estimating the ETC, we lean heavily on assumptions to justify our choice of $\delta$; in particular, we use a priori domain knowledge about which covariates are most likely to be important predictors of treatment effect heterogeneity when setting $\delta$. 

We now discuss how the H-SBW criterion differs from SBW. Notice that the SBW criterion is equivalent to ours when setting $\rho = 0$; in other words, SBW attempts to calculate the minimum variance weights for a fixed $\delta$. This is desirable if, for example, the errors in the outcome model are all independent and identically distributed. In our case, we account for possible state-level dependencies in the outcome model (or, alternatively, depending on one's viewpoint, state-level sampling or state-level treatment assignment). Intuitively, by adding the tuning parameter $\rho$, this objective attempts to ensure that the within state sum of weights is roughly uniform across states as well as across CPUMAs. This is especially desirable if many weights would in some cases be concentrated in only one state. We discuss this objective in more detail and provide simulation results in Rubinstein (2021) (not yet available), but note that broadly speaking, we can think of H-SBW being to SBW what generalized least squares (GLS) is to ordinary least squares (OLS): both SBW and OLS can produce unbiased estimates of certain parameters, but H-SBW and GLS are more efficient estimators assuming some correlation structure in the model.

A second departure from SBW comes in the constraint set: rather than balancing on the observed covariate values $W_{ij}$, we instead balance on our estimate of $\eta(W_{ij})$. This is because the estimation error in these region-level estimates will bias our estimator. In Appendix A we show that this bias is equivalent to the bias induced in the classical measurement error framework using OLS. We further show that if we had access to $\eta$, we could get an unbiased estimate of $\psi^1$. Here we leverage the person-level replicate survey weights provided in the ACS microdata to estimate the variability in each CPUMA's observed covariate values. We then use a variant of regression calibration techniques to estimate $\eta(W_{ij})$ as a linear approximation to the true covariate values. We give further details about this estimation procedure in Appendix B.

This is the first application we are aware of to use regression calibration methods in the context of balancing weights. We emphasize the key assumptions for the theoretical groundings for this procedure: (1) the outcome model is linear in the covariates; (2) the measurement error in the outcome is unrelated to the measurement error in the covariates; (3) the covariates are randomly sampled from some larger super-population. The first assumption is quite strong, though standard in many applications. The second assumption is reasonable, because our outcomes are estimated from a different cross-section of individuals than our covariates. The final assumption is not strictly necessary; \cite{gleser1992importance} (Theorem 2) shows that regression calibration methods can provide consistent estimates of the outcome model parameters when we view $X_{ij}$ as fixed and the errors are iid normals.

Lastly, we are unable to achieve exact balance. These imbalances may well bias our estimator. Following the recent literature on synthetic controls, we reduce this bias by using ridge-regression augmented weights \cite{ben2018augmented}. Letting $\hat{\eta}(W_1)$ be the matrix of imputed covariates, we standardize our weights to sum to one and use the regression-augmented weights:

$$
\gamma^{aug} = \gamma^{sbw} + (\hat{\eta}(W_1)^T\gamma^{sbw} - \bar{W}_0^p)^T(\hat{\eta}(W_1)^T\Omega^{-1}\hat{\eta}(W_1) + \lambda I_d)^{-1}\hat{\eta}(W_1)^T\Omega^{-1}
$$

where $\Omega$ is a block diagonal matrix with diagonal entries equal to one and the within-group off diagonals equal to $\rho$. We choose $\lambda$ so that the remaining imbalances all fall within 0.1 percentage points (see \cite{ben2018augmented} for more details on the connection between these weights and ridge-regression). The cost of this de-biasing procedure is that we must extrapolate from the support of the data, and therefore rely more heavily on our modeling assumptions. Finally, notice that we can also generate Oaxaca-Blinder weights ($\gamma^{ob}$) by setting $\gamma^{sbw} = 1/N_1$ and $\lambda = 0$. These are equivalent to running OLS (or GLS) on the observed outcomes among the treated units and imputing the missing counterfactual using these coefficient estimates. In our results we consider estimators using SBW ($\rho = 0$), $H-SBW$ ($\rho = 0.2$), and ridge-augmented versions of SBW and H-SBW that we call BC-SBW and HC-HSBW. We also generate Oaxaca-Blinder weights setting $\rho \in \{0, 0.2\}$ (OB and H-OB) and provide these results in Appendix D. We focus our discussion on our preferred estimators, H-SBW and the ridge augmented version (BC-HSBW).

\subsection{Inference}

We treat our estimate of $\psi^1$ as known, since the population-weighted CPUMA average of observed values is quite precisely estimated relative to the CPUMA-level averages. Our uncertainty therefore arises from our estimate of $\psi^0$ and $\eta(W_{ij})$. We use the leave-one-state-out jackknife to estimate the standard error of our estimator of $\psi^0$. We compute standard errors both recalculating all of the estimators on the adjusted data, and also recalculating the entire adjustment process. We expect that either of these estimators will be conservative: assuming we had access to the true covariates, our target of inference is conditional on the true underlying covariates and the observed treatment assignment. By contrast, the leave-one-cluster-out jackknife is an approximation to the bootstrap, which has asymptotic coverage even when the covariates are random. Moreover, it is not clear that resampling entire states when estimating $\eta(W_{ij})$ is a sensible procedure when we view the underlying covariates as fixed, since, conditional on $X_{ij}$, it is reasonable to assume that the measurement errors are being drawn iid at the CPUMA level. Additional comments on the bias and variance of this estimator are available in Appendix A; obtaining more precise inference in this setting is an interesting question that is beyond the scope of this paper.

\section{Results}

We present the analyses using our adjusted covariates $\hat{\eta}(W_{ij})$. Figure \ref{loveplot} shows how our balancing weights reduce the imbalances among covariates with greater than one percentage point difference between the targeted mean in the expansion region and the mean values in the non-expansion region (we target the population-weighted mean of the untreated region). Before applying our weights, we see that there are substantial imbalances in the republican governance indicators, as well as pre-treatment uninsurance and unemployment rates. Our weights drastically reduce these differences; however, some imbalances remain. In particular, imbalances remain in the Republican governance indicators. A full balance table is available in Appendix C. 

\begin{figure}[B]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/balance-plot-etu.png}
    \caption{Balance plot}
    \label{loveplot}
\end{center}
\end{figure}

As discussed above, we use a ridge-augmentation to extrapolate from the data in order to reduce all imbalances within 0.1 percentage points. Figure \ref{statewghts} shows the total weights summed across states for each estimator: HSBW and BC-HSBW. This figure sums the negative weights separately from the positive weights to make clear the extent of the extrapolation. We see that BC-HSBW does extrapolate somewhat heavily in order to generate estimates of the counterfactuals, particularly for CPUMAS in California. 

\begin{figure}[B]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/weights-by-state-main.png}
    \caption{Total weights summed by state}
    \label{statewghts}
\end{center}
\end{figure}

Our H-SBW estimator yields an estimated effect of -1.89 (-3.37, -0.41).\footnote{This estimator ran the objective function above using $\rho = 0.2$ and imputing the covariates in the second procedure outlined in the Appendix.} In other words, had states that did not expand Medicaid done so, we would have seen a 1.89 percentage point reduction in their uninsurance rates in 2014. Encouragingly, the bias-correction makes almost no difference to the point estimate, although the confidence interval decreases to (-2.54, -1.24). These estimates differ somewhat from the estimates we find running the procedure on the observed values $W_i$: here we calculate our preferred weighting estimator as -2.26 (-3.23, -1.29), and the bias corrected estimator yields -2.50 (-3.41, -1.58). Using the adjusted dataset appears to both move our estimate closer in absolute magnitude towards zero and increase the estimated confidence intervals. This is expected because the imputation essentially shrinks outlying values of $W_i$ closer to $\bar{W}$; as a result, our weights must become more extreme in order to achieve the same level of covariate balance. We also generate Oaxaca-Blinder weights; they are substantively similar and available in Appendix D. Figure \ref{estimators} displays the point estimates from each of our weighting estimators. 

\begin{figure}[B]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/point-estimates-c1.png}
    \caption{Point estimates}
    \label{estimators}
\end{center}
\end{figure}

We next examine how removing specific covariate groups in the weighting procedure changes the estimated contrast between the weighted treatment and control regions (ie the estimated treatment effect when all groups are included). We are especially interested in how this contrast changes when we remove the Republican governance indicators: because we hypothesize that regions under Republican governed administrations will have lower Medicaid take-up rates, we expect that removing these covariates will move this estimate farther away from zero. We divide our covariates into six separate groups: pre-treatment uninsurance rates and pre-treatment unemployment rates, Republican governance indicators, and three sets of different demographic indicators. Specifically, the first group includes: urban residence, age group, education, citizenship, student, disability, female; the second, white race, Hispanic ethnicity, foreign-born, and income-to-poverty ratio; the third, number of children, household to population ratio, and population growth. We then rerun the analyses excluding each group. 

\begin{figure}[]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/loo-covariates-main-c1.png}
    \caption{Estimates}
    \label{loocovariates}
\end{center}
\end{figure}

Figure \ref{loocovariates} displays the estimated treatment effects when removing each covariate group for our preferred set of weights and the bias corrected version of these same weights. We find that all our estimates are very sensitive to the removal of pre-treatment uninsurance and pre-treatment unemployment rates. When we fail to control for these covariates, our estimated contrast increases substantially in absolute magnitude. We also find that our preferred bias-corrected estimator is somewhat sensitive to the removal of children/population-growth/household ratio group. 

Most importantly for our research hypothesis, we see a relatively large increase in absolute magnitude of our estimated contrast when removing the Republican governance indicators. Specifically, we find that our estimated contrast increases in absolute magnitude by 0.65 for our preferred estimator and by 0.72 for our bias-corrected estimator. We see similar differentials on our unadjusted dataset (0.64 and 0.49, respectively). These results are consistent with our hypothesis that Republican governance drives heterogeneity in the treatment effects. However, we caveat that all of these changes fall well within the margin of error of our estimates. Figure \ref{repub} shows the difference in our estimates for our primary dataset. A full comparison of the difference in estimates when removing the Republican governance indicators is available in Appendix D, Tables \ref{pointesttable} and \ref{pointesttablec2}.

\begin{figure}[]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/repub-diff-c1.png}
    \caption{Removing Republican Governance Indicators}
    \label{repub}
\end{center}
\end{figure}


\subsection{Sensitivity Analyses}

We examine the sensitivity of our estimates to violations of two key causal assumptions: (1) no anticipatory treatment effects, and (2) positivity violations. To the first point, several states had partial limited expansions prior to 2014. Following \cite{frean2017premium}, we consider these states to be California, Connecticut, Minnesota, New Jersey, and Washington. We rerun our analyses excluding CPUMAs from all five of these states. It is unclear how this should affect our estimates: on the one hand, states that expanded early might have a smaller treatment effect after 2014 because they already enrolled newly eligible individuals. This would bias our previously estimated treatment effect upwards. On the other hand, if these states were also more motivated to enroll people in Medicaid, they might have larger post-expansion coverage gains, leading to a downwards bias. When removing these states, we estimate an effect of -1.35 using H-SBW weights and when we run the bias-corrected version we estimate -1.77. Our leave-one-out covariate analysis shows similar associations to those in our primary analysis; however, we see a somewhat larger association between Republican governance indicators and our estimated contrast. Table \ref{pointesttablec2} in Appendix D displays these results. 

We next consider positivity violations. To this point we have relied on either (1) retaining a potentially biased estimate from weights that do not provide exact balance, or (2) producing a more heavily model-dependent estimate that relies on extrapolation. Overall we found that the results didn't change substantially either way. Here we consider a third option: changing our target estimand. In particular, we consider the overlap average treatment effect (OATE), proposed by \cite{li2018balancing}. This is the treatment effect on the subset of the entire dataset where we have overlap. It is a data-dependent treatment effect, and is not the same as the treatment effect on the untreated; however, we believe that this effect will be more similar to the ETC than the ETT, since there were no Democratic controlled states that did not expand Medicaid. Indeed, after generating overlap weights on our primary dataset we find that across all covariates, the mean L1 distance from the overlap region to the untreated region is 2.5 and to the treated region is 7.8.\footnote{The distance is between the overlap region calculated as an unweighted mean on the adjusted datasets.} Figure \ref{oatearea} displays the distance between covariates with greater than one percentage point distance from the overlap region to either the control or treated region. We see that the overlap region is substantially more Republican than the treated region, as expected. This region is also less Hispanic, more white, less rural, and more educated than either the expansion or non-expansion region. Tables \ref{oatedist1} and \ref{oatedist2} in Appendix C show statistics on the OATE region versus the treatment and control regions for all covariates.

\begin{figure}[]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/oate-imbalances.png}
    \caption{Overlap area compared to treated, untreated regions}
    \label{oateimbalance}
\end{center}
\end{figure}

Figure \ref{oateimbalance} displays the sum of the weights within each state by treatment group. As predicted, we see that it is heavily represented by more conservative states, including Ohio, Arkansas, etc.

\begin{figure}[]
\begin{center}
    \includegraphics[scale=0.6]{01_Plots/oate-region.png}
    \caption{Overlap weights by state}
    \label{oatearea}
\end{center}
\end{figure}

We find similar results to our primary analysis: within the overlap region we find an estimated treatment effect of -1.64 (-2.41 -0.88) when including all treatment states in our primary analysis, and of -1.81 when excluding ``early expansion'' states. We again find a negative association between the estimated contrast and the Republican governance indicators, which decrease the estimated effect size by 0.96 percentage points on the primary dataset and by 0.72 percentage points when removing early expansion states. The primary results are most sensitive to the inclusion of Ohio, Maine, New Jersey, Wisconsin, and Arkansas. Removing any of these first four states decreases the point estimate by 0.13 to 0.22 percentage points, while removing Arkansas increases the estimate by 0.11 percentage points. The estimates when removing the Republican governance indicators are most sensitive to Kentucky. Excluding this state increases the point estimate by 0.37 percentage points. The results when rerunning the entire covariate adjustment procedure (rather than simply omitting each state) are largely similar. Additional point estimates and confidence intervals are available in Appendix D, Tables \ref{oateprimary} and \ref{oatesensitive}. Additional leave-one-state-out sensitivity analyses are available in REF and REF.

Finally, we consider potential violations of our parametric modeling assumptions. We therefore use trajectory balancing to again estimate this effect. The assumption here is that our model for the potential outcome is approximable in an RHKS feature expansion. We 

\section{Discussion}

We estimate that had states that did not expand Medicaid in 2014 expanded their programs, they would have seen a -1.89 (-2.54, -1.24) percentage point change in the adult uninsurance rate. Existing estimates place the ETT between -3 and -6 percentage points; these estimates vary depending on the targeted sub-population of interest, the data used, and the modeling approach (see, eg, \cite{courtemanche2017early}, \cite{kaestner2017effects}, \cite{frean2017premium}). This ETC estimate is therefore closer to zero than these ETT papers, supporting our original hypothesis that the treatment effect on non-expansion states would be smaller in absolute magnitude. Moreover, we also find that we are likely to estimate treatment effects that are larger in absolute magnitude when allowing our comparison states to include states with more Democratic governance. While the differences all lay within the estimated margins of error of the original point estimates, the consistency of this finding in all of our sensitivity analyses provides evidence that the differing political composition of the expansion versus the non-expansion states may explain these differences. 

We also make several methodological contributions to the literature on balancing weights. First, we extend the synthetic controls literature to estimate the treatment effect on the controls. The key challenge is that we need to predict treatment response rather than the outcome absent treatment. Unlike when estimating the treatment effect on the treated, we cannot use pre-treatment outcomes to conduct variable selection, run placebo tests, or train our model in some other way. This is a fundamentally more difficult problem, if there is heterogeneity in treatment effects, that requires greater modeling assumptions. Second, we extend the Stable Balancing Weights objective function for use with hierarchical data and measurement error. We modify the criterion with the result that our weights more evenly disperse across states. We also exploit estimates of our region-level covariate estimates to account for bias induced by the measurement error by using regression calibration techniques and balancing on these imputations in our constraint set.

Our study's approach also has bearing on estimating the ETT using a differences-in-differences analysis to study the 2014 effects of Medicaid expansion. If we believe that Republican governance is associated with changes in trends over time, then we need to control for this variable. However, there is likely insufficient overlap to control for these factors without significant extrapolation from the data. We see that the ETC requires less extrapolation than the ETT with respect to governance, and is in some sense then a more estimable quantity, though estimating this effect requires a different set of identifying assumptions (specifically, we cannot use the standard parallel trends assumption). Setting this problem aside, assume that we do have a reasonable estimate of the ETT for some outcome. Since we show that there is likely treatment effect heterogeneity across governance and other variables that differ between the expansion and non-expansion regions, projecting findings from an estimate of the ETT to the ETC would likely lead to inaccurate inferences. For example, \cite{miller2019medicaid} use their estimate of the ETT to project that had all states expanded Medicaid in 2014, 15,600 deaths would have been avoided during their study's time-period. If we believe that the ETT were further away from zero than the ETC, we should expect that this number is too large. Directly estimating the ETC in this context can therefore also help us better model interesting downstream effects mediated through increasing the number of insured individuals. 

Our results come with the following caveats: (1) we rely on parametric assumptions about the outcome model to estimate our causal effect; (2) our identification assumes no unmeasured confounding given the true covariates; (3) all of our estimated associations between Republican governance and the estimated contrast between treatment and control states fall within our estimated margins of error. 

We conclude by discussing the policy implications of these findings. First, we note that a reduction of adult uninsurance rates by -1.89 percentage points represents approximately a 9.5 percent reduction in the uninsurance rate among non-expansion states. This estimated treatment effect is closer to zero than corresponding estimates of the ETT (see, eg, \cite{courtemanche2017early}). We may therefore expect that downstream effects that move away from zero monotonically with the number of uninsured are also closer to zero than estimates of the ETT. Second, we emphasize that the positive association we find between governance and the estimated treatment effect is only an association: this finding does not imply, for example, that states with Republican governments in general make Medicaid enrollment more difficult relative to Democratic states. However, this finding does not rule out this possibility either. Even if this causal story were true, then it is also a normative judgment whether this finding is a ``good'' or a ``bad'' result. To evaluate the policy implications, we compare this result against Congress's goal in implementing Medicaid expansion in the 2010 ACA, which was to increase health insurance coverage. Measured against this intent, this finding suggests that leaving states to implement individual enrollment schemes likely achieves sub-optimal results. Better federal policies should encourage states to adopt some form of automatic Medicaid enrollment, or to make Medicaid enrollment easier in some other way. On the other hand, Republican governed states in 2014 were also more culturally conservative, and people may have been less likely to enroll in Medicaid due to social stigma and/or personal beliefs about the welfare state (\cite{sommers2012understanding}). If this remains true today, then Republican governments that are committed to expanding access to health care to low-income individuals may again wish to consider policies such as automatic enrollment to help mitigate these effects. Lastly, for administrations that do not see coverage expansion as an important goal of Medicaid expansion, this finding may represent no policy problem at all.

\section{Conclusion}

This is the first study to directly estimate the foregone coverage expansions of Medicaid Expansion on states that did not expand Medicaid in 2014. We also contribute to the methodological literature on synthetic controls by clarifying the assumptions required to use longitudinal data to estimate the ETC rather than the ETT, and to the balancing weights literature more generally by considering the case where we have hierarchical data and covariates measured with error. We estimate that had states that did not expand Medicaid in 2014 done so, they would have seen a -1.89 (-1.24, -2.54) percentage point change in their uninsurance rate. This is substantially closer to zero than existing estimates of the ETT, which range between -3 and -6 percentage points. These estimates are also robust to sensitivity analyses examining potential violations of the assumptions of no anticipatory treatment effects and positivity violations. 

We also find evidence that Republican governance is associated with estimated effect sizes closer to zero. This association is also robust our sensitivity analyses, and is consistent with existing estimates of the ETT that are also farther away from zero, and the finding that Medicaid take-up rates are lower in Republican-governed states prior to Medicaid expansion in 2014 (\cite{sommers2012understanding}). If the goal of Medicaid expansion is to increase access to insurance for low-income adults, this suggests that state and federal governments may wish to adopt policies that make Medicaid enrollment automatic, or at least easier.

\section{Acknowledgements}

The authors gratefully aknowledge invaluable advice and comments from Zachary Branson, Dave Choi, Edward Kennedy, Brian Kovak, Akshaya Jha, Lowell Taylor, and Jose Zubizaretta.

\cleardoublepage
\bibliography{research.bib} 

\cleardoublepage

\section{Appendix}

\subsection{Appendix A: Proofs}

We prove that the bias of the SBW estimator under measurement error is equivalent to the bias of the OLS estimator under the classical errors-in-variables model. For the purposes of this proof we assume that the outcome model holds beyond the support of the data. We then prove the unbiasedness and asymptotic normality of the estimator when balancing on the imputed covariates when balancing on using $\mathbb{E}\{X_i \mid W_i\}$ instead of $W_i$. This is not meant to be a comprehensive treatment of the properties of this estimator, but rather to introduce the idea that we can apply concepts in the regression-calibration literature in for balancing weights when the covariates are measured with error. We conclude by noting how our application differs from this stylized introduction; Appendix B provides details on how we applied these ideas for our application.

We begin by outlining the classical errors-in-variables setup. Consider the linear model $Y_i^1 = \alpha + X_i^T\beta + \epsilon_i$ and assume we observe covariates $W_i \in \mathbb{R}^d$ which are a vector of mean-unbiased proxies for the true covariate $X_i$; ie $W_i = X_i + v_i$. Assume that $(\epsilon_i, v_i) \sim MVN((0,0), \Sigma_{uu})$ 

$$
\Sigma_{uu} = \begin{pmatrix} 
\Sigma_{\epsilon\epsilon} & 0 \\ 
0 & \Sigma_{vv} 
\end{pmatrix}
$$ 

In general we can either consider the case where $X_i$ are fixed (functional model) or random (structural model); the structural case typically motivates regression calibration, however, the ideas have desirable properties in the functional case as well \cite{gleser1992importance}. For motivating purposes, we therefore think of $X_i$ as random. In a slight departure from the classical setup, we also consider the binary treatment indicator $A_i$ and we let $(X_i, W_i \mid A_i = a)$ are drawn iid from $MVN((\mu_a, \mu_a), \Sigma)$ where 

$$
\Sigma = \begin{pmatrix} 
\Sigma_{XX} & \Sigma_{XX} \\ 
\Sigma_{XX} & \Sigma_{XX} + \Sigma_{vv} 
\end{pmatrix}
$$ 

For simplicity we have assumed that $\Sigma_{WW \mid A = 1} = \Sigma_{WW \mid A = 0} = \Sigma_{WW}$ and $\Sigma_{XX \mid A = 1} = \Sigma_{XX \mid A = 0} = \Sigma_{XX}$. This is not a necessary assumption, but helps simplify notation. By the joint normality of $X_i$ and $W_i$, we know that that $\mathbb{E}\{X_i \mid W_i, A_i = 1\} = \mu_1 + \kappa^T(W_i - \mu_1)$, where $\kappa = \Sigma_{WW}^{-1}\Sigma_{XX}$.

Recall that the bias of the OLS estimator of $\beta$ is $\hat{\beta} - \beta = (\kappa - I_d)\beta$. Our goal is to estimate the treatment effect on the controls, so we can express our causal estimand as $\alpha + \mu_0^T\beta$; recalling that $\alpha = \mu_y - \mu_1^T\beta$, we see the bias of the linear combination is $(\mu_0 - \mu_1)^T(\kappa - I_d)\beta$. We now consider the SBW estimator that sets $\delta = 0$ and show that this estimator has the same bias. The intuition for this result is as follows: exact balancing weights estimate an implicit $\beta$ on a subset of the data where we have sufficient overlap. We can think of the implicit beta as the solution to some weighted-least squares problem. Because we assume that the outcome model holds on all of the data, WLS and OLS are estimating the same $\beta$; therefore, the bias that effects the least squares solution will have the same effect on the weighted least squares solution.

More formally, define the SBW estimator as:

$$
\arg\min_{\gamma \in \Gamma} \gamma_i^2
$$

$$
\Gamma := \{\gamma: W_1^T\gamma = W_0^T1, \gamma_i > 0, \gamma^T1 = 1\}
$$

\begin{align*}
    \mathbb{E}\{\hat{\psi}\} - \psi &= \sum_{i: A_i = 1}w_iY_i - \sum_{i: A_i = 0}Y_i^0 \\
    &= \mathbb{E}\{\beta^T(\sum_{i: A_i = 1} \gamma_i (X_i - v_i) - \sum_{i: A_i = 0} (X_i - v_i))\} \\
    &= \beta^T(\sum_{i: A_i = 1} \gamma_i\mathbb{E}\{v_i \mid W_i, A_i = 1\}) \\
    &= \beta^T(\sum_{i: A_i = 1} \gamma_i\mathbb{E}\{(W_i - X_i) \mid W_i, A_i = 1\} \\
    &= \beta^T(\sum_{i: A_i = 1} \gamma_iW_i - \sum_{i: A_i = 1} \gamma_i\mathbb{E}\{X_i \mid W_i, A_i = 1\})
\end{align*}

Substituting our expressions for the conditional distribution of $\mathbb{E}\{X_i \mid W_i, A_i = 1\}$, using the fact the in expectation, $\sum_{i: A_i = 1}\gamma_iW_i = \mu_0$, and taking expectations over $W_i$, we obtain the desired result.

Correcting for this bias is a much studied topic. We propose using regression calibration techniques, which are discussed at length in the measurement error literature (see, eg, \cite{carroll2006measurement}). This allows us to adjust our covariates without using the outcomes, in the spirit of the design-based estimation strategy we use here. At its most broad, regression calibration seeks to learn the linear projection $\mathbb{E}\{X_i \mid W_i, A_i = 1\} = \mu_1 + (\kappa^T W_i - \mu_1) = \eta(W_i)$ by learning $\kappa$. Notice that $\kappa = \Sigma_{WW}^{-1}\Sigma_{XX}$, and $\Sigma_{WW} = \Sigma_{XX} + \Sigma_{uu}$. We can learn $\Sigma_{WW}$ directly from the data, and $\Sigma_{uu}$ using auxillary data. For our application, we use the replicate survey weights available on the ACS microdata, to estimate this matrix. 

We now show that balancing on $\eta(W_i)$ results in an unbiased estimate of $\psi$. We make the simplifying assumptions that $\eta(W_i)$ is known and that there is no model error on $Y_i$. By linearity, we know that

\begin{align*}
Y_i &= X_i^T\beta \\
&= \eta(W_i)^T\beta + (X_i - \eta(W_i))^T\beta
\end{align*}

Now let $\gamma \in \Gamma$, where $\Gamma := \{\gamma \mid \sum_i \gamma_i \eta(W_i) = \sum_i X_i, \gamma^T1 = n\}$. Let $v_i = X_i - \eta(W_i)$. We then see that

\begin{align*}
    \frac{1}{n}\sum_{i}\gamma_{i}Y_{i} - \frac{1}{n}\sum_{i}Y_{i} &= \frac{1}{n}\beta^T\sum_{i}\gamma_{i}(\eta(W_i) - \sum_{i}X_{i}) + \frac{1}{n}\sum_i \gamma_iv_i^T\beta \\
    &= \frac{1}{n}\sum_i \gamma_iv_i^T\beta
\end{align*}

Across repeated draws of $W$, this term is zero in expectation because we know $\eta$. For fixed $W$ and $X$, this term has no variance and only contributes to a finite-sample bias that vanishes at a $\sqrt{n}$ rate assuming there exists some constant $C$ such that $\max_i \gamma_i \le C\sqrt{n}$. We also see that this imputation increases the variance of the estimator across repeated draws of $W$:

\begin{align*}
    Var(\frac{1}{n}\sum_i \gamma_i Y_i \mid W_i) &= \frac{1}{n^2}\sum_i Var(\gamma_iv_i^T\beta) \\
    &\le \frac{1}{n^2}\sum_i\mathbb{E}(\gamma_i^2)\beta^TCov(X_i \mid W_i)\beta 
\end{align*}

Our goal is again simply to show that many of the ideas developed in the regression-calibration literature can be used with balancing weights when we assume our covariates are measured with error without using any information about the outcomes. While the validity of this procedure relies on several strong modeling assumptions, perhaps the most crucial is the assumption that any measurement error in the covariates is uncorrelated with any measurement error in the outcome. 

We conclude by noting several key departures in our applied setting to the framework we presented above: first, we view $X_i$ as fixed underlying parameters. Second, we don't know $\eta(W_i)$ and instead approximate it using an estimate $\Sigma_{vv}$ that we derive from the ACS replicate survey weights. Third, we do not believe that $X_i$ is linear in $W_i$; instead, we view this is an approximation. Discussing these issues in detail is beyond the scope of this paper; however, \cite{gleser1992importance} (Theorem 2) shows the conditions for the consistency of the regression-adjusted estimator in a similar context. Finally, we consider our data to be correlated within state but independent across states. We have not formally considered the effect of these dependencies on this imputation procedure, and under whether the methods followed here leave room for improvement. 

\subsection{Appendix B: Calibration Details}

We now discuss our imputation procedure. We first outline the traditional imputation outlined in \cite{carroll2006measurement}, and then explain our preferred departures from this framework. In either case we begin by estimating the covariance matrix $\Sigma_{UU, ij}$, the sampling variability for each CPUMA by estimating

$$
\hat{\Sigma}_{UU, ij} = \frac{4}{80}\sum_{b=1}^{80}(X_{ij}^B - \bar{X}_{ij})(X_{b, ij} - \bar{X}_{ij})^T
$$

Let $\hat{\Sigma}_{WW \mid A_j = 1} = \sum_{j: A_j = 1} (W_{ij} - \bar{W})(W_{ij} - \bar{W})^T$ be an estimator for $\Sigma_{WW \mid A = 1} = \mathbb{E}\{(W_{ij} - \mu_w)(W_{ij} - \mu_w)^T\}$. This estimator is calculated on the original dataset. We then estimate $\Sigma_{XX \mid A = 1} = \mathbb{E}\{(X_i - \bar{X})(X_i - \bar{X})^T \mid A_j = 1\}$ using:

$$
\hat{\Sigma}_{XX \mid A = 1} = \Sigma_{WW} - \sum_{ij: A_j = 1} \Sigma_{UU, ij}
$$

Define

$$
\hat{\kappa} = (\hat{\Sigma}_{WW})^{-1}(\hat{\Sigma_{XX}})
$$

We can think of this matrix as an estimate coefficient vector of a linear regression of the (unobserved) vector $X_{ij}$ on (observed) $W_{ij}$. We can impute $\hat{X}_{ij}$ as

$$
\hat{X}_{ij} = \bar{W} + \kappa^T(W_{ij} - \bar{W})
$$

This is the standard imputation suggested by \cite{carroll2006measurement}. However, in our setting we know that there is substantial heterogeneity in the measurement error: in particular, regions with large populations are estimated quite precisely, while others are estimated much less precisely. Even for a given CPUMA, some covariates are measured using three years of data, and others only one. From 2011 through 2013, STATISTICS on sample sizes!! As a result, using the conventional regression calibration approach will affect estimates that we know are precisely estimated and ones that we know aren't in a similar way. 

Our preferred estimators therefore use an alternative approach where we model $\Sigma_{vv, ij}$ as a function of the sample sizes used to estimate each covariate. In particular, let $s_{ij}$ be the d-dimensional vector of the sample sizes used to estimate each covariate value for a given CPUMA. Let $S_{ij} = \sqrt{s_{ij}}\sqrt{s_{ij}}^T$. We then assume that $\sqrt{s_ij}v_{ij} \sim N(0, \Sigma_{vv})$. We then know that $\Sigma_{vv, ij} = \Sigma_{vv} \oslash S_{ij}$. 

To estimate these matrices, we pool our initial estimates of the CPUMA-level covariance matrices ($\hat{\Sigma}_{UU, ij}$) to generate $\hat{\Sigma}_{UU}^m = N_1^{-1}\sum_{ij} S_{ij} \circ \Sigma_{UU, ij}$. We then estimate $\hat{\Sigma}_{UU, ij}^m = \Sigma_{UU}^m \oslash S_{ij}$. From this we estimate $\hat{\Sigma}^m_{XX} = \hat{\Sigma}_{WW} - N_1^{-1}\sum_{ij}\hat{\Sigma}^m_{UU, ij}$. Finally, we calculate $\hat{\kappa}_{ij} = (\hat{\Sigma}^m_{XX} + \hat{\Sigma}^m_{UU, ij})^{-1}\hat{\Sigma}^m_{XX}$, which we use to estimate $\hat{X}_{ij}$. 

Again the benefit of using this estimator is that we account for unit-level heterogeneity in the measurement error. Specifically, this adjustment will primarily affect outlying values of imprecisely estimated covariates, while leaving precisely estimated covariates largely unchanged. Moreover, we can do this while getting the full efficiency of using all of the units in the modeling. 

One cost of this procedure is that this aggregation models all differences as a function of the sample sizes, and averages over any potential heterogeneity due to heteroskedasticity (ie the measurement error covariance matrix changes depending on the true value of $X_{ij}$). A second cost is that we do not account for the hierarchical nature of the data; if we did, we could likely improve the efficiency this estimation procedure. We leave this as future work.

\subsection{Appendix C: Complete Balance Tables}

Tables \ref{baltab1} and \ref{baltab2} presents the differences between the population-weighted untreated mean covariate values and the weighted and unweighted non-expansion region (calculated on on our adjusted dataset). The weights presented here are from the H-SBW $(\rho = 0.2)$ estimator. Additional results are available on request.

\begin{table}[ht]
\centering
\begin{tabular}{lrr}
  \hline
variable & Unweighted Difference & Weighted Difference \\ 
  \hline
age\_cat2\_19\_29\_pct & 0.51 & 0.26 \\ 
  age\_cat2\_30\_39\_pct & 0.22 & 0.34 \\ 
  age\_cat2\_40\_49\_pct & -0.09 & 0.59 \\ 
  avg\_adult\_hh\_ratio & -10.11 & 0.25 \\ 
  citizenship\_pct & 2.19 & 2.00 \\ 
  disability\_pct & 1.01 & -0.49 \\ 
  educ\_hs\_degree\_pct & 2.38 & -1.40 \\ 
  educ\_less\_than\_hs\_pct & 0.74 & -1.21 \\ 
  educ\_some\_college\_pct & -0.01 & -0.83 \\ 
  female\_pct & 0.34 & 0.76 \\ 
  foreign\_born\_pct & -5.26 & -2.00 \\ 
  hins\_unins\_pct\_2011 & 4.33 & -0.05 \\ 
  hins\_unins\_pct\_2012 & 4.08 & 0.01 \\ 
  hins\_unins\_pct\_2013 & 3.90 & 0.05 \\ 
  hispanic\_pct & -1.70 & -1.00 \\ 
  inc\_pov2\_138\_pct & 1.93 & -0.67 \\ 
  inc\_pov2\_139\_299\_pct & 2.42 & -0.74 \\ 
  inc\_pov2\_300\_499\_pct & 0.26 & 0.08 \\ 
  inc\_pov2\_500\_plus\_pct & -5.01 & 2.00 \\ 
  married\_pct & 0.67 & 0.94 \\ 
  missing\_children\_pct & 0.00 & -2.13 \\ 
  one\_child\_pct & 88.28 & 89.04 \\ 
  pop\_growth\_2012 & 0.93 & -0.89 \\ 
  pop\_growth\_2013 & -82.44 & -84.69 \\ 
   \hline
\end{tabular}
\caption{Balance Table (1)}
\label{baltab1}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lrr}
  \hline
variable & Unweighted Difference & Weighted Difference \\ 
  \hline
  race\_white\_pct & 1.49 & -1.00 \\ 
  repub\_gov & 65.02 & 16.91 \\ 
  repub\_lower\_control & 74.91 & 18.41 \\ 
  repub\_total\_control & 73.72 & 20.00 \\ 
  student\_pct & -0.18 & 0.61 \\ 
  three\_plus\_child\_pct & 0.00 & 0.10 \\ 
  two\_child\_pct & -0.63 & 0.40 \\ 
  unemployed\_pct\_2011 & -0.83 & -0.10 \\ 
  unemployed\_pct\_2012 & -0.85 & 0.10 \\ 
  unemployed\_pct\_2013 & -0.61 & 0.10 \\ 
  urban\_pct & -6.52 & 2.00 \\ 
   \hline
\end{tabular}
\caption{Balance Table (2)}
\label{baltab2}
\end{table}

Tables \ref{oatedist1} and \ref{oatedist2} display the difference in means from the overlap region (calculated on our preferred adjusted datasets) and the treated and untreated regions (unweighted). 

\begin{table}[ht]
\centering
\begin{tabular}{lrr}
  \hline
Variable & Distance from Control & Distance from Treatment \\ 
  \hline
age\_cat2\_19\_29\_pct & -1.41 & -1.03 \\ 
  age\_cat2\_30\_39\_pct & -0.90 & -1.12 \\ 
  age\_cat2\_40\_49\_pct & 0.31 & -0.06 \\ 
  avg\_adult\_hh\_ratio & -3.99 & -14.93 \\ 
  citizenship\_pct & 1.71 & 5.25 \\ 
  disability\_pct & 0.27 & 1.72 \\ 
  educ\_hs\_degree\_pct & 1.26 & 4.49 \\ 
  educ\_less\_than\_hs\_pct & -1.76 & -1.25 \\ 
  educ\_some\_college\_pct & 0.41 & 0.65 \\ 
  female\_pct & -0.10 & 0.24 \\ 
  foreign\_born\_pct & -2.29 & -9.74 \\ 
  hins\_unins\_pct\_2011 & -0.98 & -0.06 \\ 
  hins\_unins\_pct\_2012 & -3.55 & -0.19 \\ 
  hins\_unins\_pct\_2013 & -5.43 & -0.66 \\ 
  hispanic\_pct & -4.43 & -8.79 \\ 
  inc\_pov2\_138\_pct & -1.44 & 0.63 \\ 
  inc\_pov2\_139\_299\_pct & 0.34 & 2.12 \\ 
  inc\_pov2\_300\_499\_pct & 0.11 & 1.68 \\ 
  inc\_pov2\_500\_plus\_pct & 1.22 & -4.68 \\ 
  married\_pct & 1.31 & 2.27 \\ 
  missing\_children\_pct & -0.85 & 2.41 \\ 
  one\_child\_pct & -0.12 & -1.09 \\ 
  pop\_growth\_2012 & 5.40 & 1.15 \\ 
  pop\_growth\_2013 & 4.73 & 1.24 \\ 
   \hline
    \end{tabular}
    \caption{Overlap region distance from treated, control regions (1)}
    \label{oatedist1}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lrr}
  \hline
Variable & Distance from Control & Distance from Treatment \\ 
  \hline
  race\_white\_pct & 4.47 & 8.34 \\ 
  repub\_gov & -11.05 & 53.97 \\ 
  repub\_lower\_control & -4.99 & 69.92 \\ 
  repub\_total\_control & -16.04 & 57.68 \\ 
  student\_pct & -0.39 & -0.75 \\ 
  three\_plus\_child\_pct & -0.12 & -0.21 \\ 
  two\_child\_pct & -0.38 & -0.85 \\ 
  unemployed\_pct\_2011 & 0.23 & -0.53 \\ 
  unemployed\_pct\_2012 & 0.41 & -0.69 \\ 
  unemployed\_pct\_2013 & -0.60 & -0.65 \\ 
  urban\_pct & -4.64 & -12.72 \\ 
   \hline
\end{tabular}
\caption{Overlap region distance from treated, control regions (2)}
\label{oatedist2}
\end{table}

\subsection{Appendix D: Complete Results}

Table \ref{maintable1} displays the point estimates from all estimators as well as confidence intervals calculated either (a) leave-one-state-out jackknife on the imputed dataset (CI Data); (b) leave-one-state-out jackknife repeating the entire imputation leaving each state out (CI Proc). In general the second set of confidence intervals are much larger. 

This table also includes the Oaxaca-Blinder weights (OB and H-OB), and also all analyses calculated on a second version of the imputed data where we use a common $\kappa$ for all values (sigma\_uu\_avg), which is the imputation suggested by \cite{carroll2006measurement}. Notice that they are identical for ``sigma\_zero'' because this is the unadjusted dataset. ``sigma\_uu\_i'' is our preferred imputation that we report results from in the paper.

\begin{table}[ht]
\centering
\begin{tabular}{llrll}
  \hline
Estimator & Sigma Estimate & Psihat & CI Data & CI Proc \\ 
  \hline
BC-HSBW & sigma\_uu\_i & -1.89 & (-2.54, -1.24) & (-3.45, -0.33) \\ 
  BC-HSBW & sigma\_uu\_avg & -1.61 & (-2.2, -1.01) & (-5.41, 2.2) \\ 
  BC-HSBW & sigma\_zero & -2.50 & (-3.41, -1.58) & (-3.41, -1.58) \\ 
  BC-SBW & sigma\_uu\_i & -1.77 & (-2.37, -1.17) & (-3.26, -0.28) \\ 
  BC-SBW & sigma\_uu\_avg & -1.58 & (-2.21, -0.94) & (-6.35, 3.2) \\ 
  BC-SBW & sigma\_zero & -2.37 & (-3.1, -1.64) & (-3.1, -1.64) \\ 
  H-OB & sigma\_uu\_i & -1.58 & (-2.16, -1) & (-2.75, -0.42) \\ 
  H-OB & sigma\_uu\_avg & -1.42 & (-2.21, -0.64) & (-5.38, 2.53) \\ 
  H-OB & sigma\_zero & -2.55 & (-3.31, -1.78) & (-3.31, -1.78) \\ 
  H-SBW & sigma\_uu\_i & -1.89 & (-3.37, -0.41) & (-3.89, 0.11) \\ 
  H-SBW & sigma\_uu\_avg & -1.95 & (-3.51, -0.39) & (-4.02, 0.12) \\ 
  H-SBW & sigma\_zero & -2.26 & (-3.23, -1.29) & (-3.23, -1.29) \\ 
  OB & sigma\_uu\_i & -1.53 & (-2.1, -0.96) & (-2.91, -0.16) \\ 
  OB & sigma\_uu\_avg & -1.40 & (-2.07, -0.72) & (-6.67, 3.88) \\ 
  OB & sigma\_zero & -2.47 & (-3.11, -1.83) & (-3.11, -1.83) \\ 
  SBW & sigma\_uu\_i & -1.76 & (-3.36, -0.16) & (-4.02, 0.49) \\ 
  SBW & sigma\_uu\_avg & -1.89 & (-3.41, -0.37) & (-4.15, 0.37) \\ 
  SBW & sigma\_zero & -2.25 & (-3.34, -1.16) & (-3.34, -1.16) \\ 
   \hline
\end{tabular}
\caption{Primary point estimates and confidence intervals}
\label{maintable1}
\end{table}

Table \ref{pointesttable} presents all versions of the estimators that we calculated. The variables excluded column indicates which variables were excluded from the estimation: 0 includes all variables; 1 removes Republican governance indicators; 2 pre-treatment uninsurance and unemployment rates; 3 urban, age, education, citizenship, marital status, student, disability, or female; 4 race, ethnicity, income, foreign born; 5 children, population growth, and household to person ratio.

\begin{table}[ht]
\centering
\begin{tabular}{rlrrrrrr}
  \hline
Variables Excluded & Sigma Estimate & BC-HSBW & BC-SBW & H-OB & H-SBW & OB & SBW \\ 
  \hline
0 & sigma\_uu\_i & -1.89 & -1.77 & -1.58 & -1.89 & -1.53 & -1.76 \\ 
  0 & sigma\_uu\_avg & -1.61 & -1.58 & -1.42 & -1.95 & -1.40 & -1.89 \\ 
  0 & sigma\_zero & -2.50 & -2.37 & -2.55 & -2.26 & -2.47 & -2.25 \\ 
  1 & sigma\_uu\_i & -2.61 & -2.27 & -2.73 & -2.53 & -2.45 & -2.63 \\ 
  1 & sigma\_uu\_avg & -2.76 & -2.28 & -3.03 & -2.59 & -2.44 & -2.67 \\ 
  1 & sigma\_zero & -2.99 & -2.71 & -2.98 & -2.90 & -2.67 & -2.95 \\ 
  2 & sigma\_uu\_i & -4.69 & -4.39 & -4.58 & -5.59 & -4.22 & -5.20 \\ 
  2 & sigma\_uu\_avg & -4.68 & -4.39 & -4.54 & -5.66 & -4.18 & -5.33 \\ 
  2 & sigma\_zero & -5.46 & -5.15 & -5.46 & -5.61 & -5.15 & -5.19 \\ 
  3 & sigma\_uu\_i & -1.80 & -1.68 & -1.59 & -1.91 & -1.56 & -1.84 \\ 
  3 & sigma\_uu\_avg & -1.56 & -1.48 & -1.46 & -1.92 & -1.44 & -1.82 \\ 
  3 & sigma\_zero & -2.00 & -1.99 & -2.13 & -2.16 & -2.14 & -2.22 \\ 
  4 & sigma\_uu\_i & -2.04 & -1.90 & -2.00 & -2.10 & -1.99 & -1.92 \\ 
  4 & sigma\_uu\_avg & -1.80 & -1.73 & -1.64 & -2.24 & -1.60 & -2.21 \\ 
  4 & sigma\_zero & -2.50 & -2.37 & -2.61 & -2.23 & -2.59 & -2.19 \\ 
  5 & sigma\_uu\_i & -2.50 & -2.50 & -2.73 & -1.84 & -2.81 & -1.91 \\ 
  5 & sigma\_uu\_avg & -2.47 & -2.43 & -2.42 & -1.88 & -2.45 & -1.92 \\ 
  5 & sigma\_zero & -2.44 & -2.44 & -2.64 & -2.14 & -2.58 & -2.23 \\ 
   \hline
\end{tabular}
\label{pointesttable}
\caption{Point estimates by estimator, primary dataset}
\end{table}

Table \ref{pointesttablec2} is identical to the structure of Table \ref{pointesttable} except we exclude the ``early expansion states.''

\begin{table}[ht]
\centering
\begin{tabular}{rlrrrrrr}
  \hline
Variables Excluded & Sigma Estimate & BC-HSBW & BC-SBW & H-OB & H-SBW & OB & SBW \\ 
  \hline
0 & sigma\_uu\_i\_modeled & -1.78 & -1.72 & -1.75 & -1.35 & -1.71 & -1.32 \\ 
  0 & sigma\_uu\_avg & -1.90 & -1.74 & -1.74 & -1.91 & -1.65 & -1.69 \\ 
  0 & sigma\_zero & -2.53 & -2.42 & -2.70 & -1.83 & -2.66 & -1.76 \\ 
  1 & sigma\_uu\_i\_modeled & -2.64 & -2.35 & -2.63 & -2.57 & -2.55 & -2.60 \\ 
  1 & sigma\_uu\_avg & -2.74 & -2.43 & -2.87 & -2.59 & -2.55 & -2.65 \\ 
  1 & sigma\_zero & -3.14 & -2.83 & -3.05 & -2.87 & -2.91 & -2.83 \\ 
  2 & sigma\_uu\_i\_modeled & -4.70 & -4.54 & -4.40 & -5.54 & -4.34 & -5.02 \\ 
  2 & sigma\_uu\_avg & -4.74 & -4.60 & -4.40 & -5.59 & -4.32 & -5.11 \\ 
  2 & sigma\_zero & -5.31 & -5.14 & -5.04 & -5.53 & -5.13 & -5.01 \\ 
  3 & sigma\_uu\_i\_modeled & -1.69 & -1.63 & -1.55 & -1.36 & -1.51 & -1.21 \\ 
  3 & sigma\_uu\_avg & -1.72 & -1.62 & -1.50 & -1.90 & -1.47 & -1.69 \\ 
  3 & sigma\_zero & -1.82 & -1.75 & -2.20 & -1.77 & -2.11 & -1.75 \\ 
  4 & sigma\_uu\_i\_modeled & -1.91 & -1.73 & -1.87 & -1.86 & -1.79 & -1.78 \\ 
  4 & sigma\_uu\_avg & -1.95 & -1.69 & -1.68 & -1.99 & -1.52 & -1.84 \\ 
  4 & sigma\_zero & -2.55 & -2.41 & -2.81 & -1.93 & -2.68 & -1.95 \\ 
  5 & sigma\_uu\_i\_modeled & -2.52 & -2.40 & -2.89 & -1.53 & -2.88 & -1.41 \\ 
  5 & sigma\_uu\_avg & -2.25 & -2.48 & -2.59 & -1.33 & -2.58 & -1.30 \\ 
  5 & sigma\_zero & -2.27 & -2.14 & -2.53 & -1.73 & -2.49 & -1.58 \\ 
   \hline
\end{tabular}
   \label{pointesttablec2}
   \caption{Point estimates for all specifications, early expansion excluded}
\end{table}

Table \ref{oatearea} displays all point estimates and corresponding confidence intervals calculate for the OATE.

\begin{table}[ht]
\centering
\begin{tabular}{rlrll}
  \hline
Psihat & Sigma Estimate & Variables Excluded & CI Data & CI Proc \\ 
  \hline
-1.64 & sigma\_uu\_i & 0 & (-2.41, -0.88) & (-5.75, 2.46) \\ 
  -1.58 & sigma\_avg & 0 & (-2.18, -0.98) & (-2.39, -0.78) \\ 
  -1.80 & sigma\_zero & 0 & (-2.49, -1.1) & (-2.49, -1.1) \\ 
  -2.60 & sigma\_uu\_i & 1 & (-3.57, -1.64) & (-3.76, -1.45) \\ 
  -2.62 & sigma\_avg & 1 & (-3.67, -1.57) & (-3.84, -1.41) \\ 
  -2.55 & sigma\_zero & 1 & (-3.44, -1.66) & (-3.44, -1.66) \\ 
  -2.96 & sigma\_uu\_i & 2 & (-5.41, -0.51) & (-5.79, -0.13) \\ 
  -2.85 & sigma\_avg & 2 & (-5.28, -0.42) & (-5.6, -0.1) \\ 
  -3.11 & sigma\_zero & 2 & (-5.59, -0.63) & (-5.59, -0.63) \\ 
  -1.86 & sigma\_uu\_i & 3 & (-2.98, -0.74) & (-3.23, -0.49) \\ 
  -1.76 & sigma\_avg & 3 & (-3.03, -0.48) & (-3.06, -0.46) \\ 
  -1.98 & sigma\_zero & 3 & (-2.71, -1.24) & (-2.71, -1.24) \\ 
  -1.86 & sigma\_uu\_i & 4 & (-2.52, -1.21) & (-2.83, -0.9) \\ 
  -1.76 & sigma\_avg & 4 & (-2.55, -0.98) & (-2.68, -0.85) \\ 
  -1.94 & sigma\_zero & 4 & (-2.7, -1.18) & (-2.7, -1.18) \\ 
  -1.77 & sigma\_uu\_i & 5 & (-3.05, -0.5) & (-5.55, 2) \\ 
  -1.78 & sigma\_avg & 5 & (-2.67, -0.88) & (-2.7, -0.85) \\ 
  -1.83 & sigma\_zero & 5 & (-2.61, -1.04) & (-2.61, -1.04) \\ 
   \hline
\end{tabular}
   \caption{OATE treatment effect estimates and inference, primary dataset}
   \label{oateprimary}
\end{table}

Table \ref{oatesensitive} presents all point estimates calculate using the overlap weights.

\begin{table}[ht]
\centering
\begin{tabular}{lrrr}
  \hline
Sigma Estimate & Variables Excluded & Early Expansion Removed & Preferred \\
  \hline
sigma\_uu\_i & 0 & -1.73 & -1.64 \\ 
  sigma\_avg & 0 & -1.76 & -1.58 \\ 
  sigma\_zero & 0 & -1.95 & -1.80 \\ 
  sigma\_uu\_i & 1 & -2.35 & -2.60 \\ 
  sigma\_avg & 1 & -2.40 & -2.62 \\ 
  sigma\_zero & 1 & -2.51 & -2.55 \\ 
  sigma\_uu\_i & 2 & -3.25 & -2.96 \\ 
  sigma\_avg & 2 & -3.19 & -2.85 \\ 
  sigma\_zero & 2 & -3.25 & -3.11 \\ 
  sigma\_uu\_i & 3 & -2.18 & -1.86 \\ 
  sigma\_avg & 3 & -2.14 & -1.76 \\ 
  sigma\_zero & 3 & -2.12 & -1.98 \\ 
  sigma\_uu\_i & 4 & -2.06 & -1.86 \\ 
  sigma\_avg & 4 & -2.09 & -1.76 \\ 
  sigma\_zero & 4 & -2.10 & -1.94 \\ 
  sigma\_uu\_i & 5 & -1.91 & -1.77 \\ 
  sigma\_avg & 5 & -1.90 & -1.78 \\ 
  sigma\_zero & 5 & -2.00 & -1.83 \\ 
   \hline
\end{tabular}
\caption{OATE sensitivity analyses}
\label{oatesensitive}
\end{table}

Table \ref{oateloostate} presents the leave-one-out state analysis for the OATE. The primary estimate is in the left-hand column. The point estimate when leaving the state out conditional on the variable adjustment is the ``State Excl'' column, while the point estimate when re-running the entire procedure is in the ``Est Process'' column. Notice that these estimates are identical when the ``Sigma Estimate'' column is equal to ``sigma zero'' because this dataset did not adjust the covariate values. The dataset is filtered to only include the states that had the largest absolute magnitude change in point estimate for each specification. We also only include results for the first three variable groups. Additional results are available on request.

\begin{table}[ht]
\centering
\begin{tabular}{llrlll}
  \hline
Main Estimate & Sigma Estimate & Variables Excl & Stae Exl & Est Process & Est State \\ 
  \hline
-1.58 & sigma\_avg & 0 & OH & -1.8 & -1.72 \\ 
  -1.58 & sigma\_avg & 0 & ME & -1.77 & -1.75 \\ 
  -1.58 & sigma\_avg & 0 & FL & -1.73 & NA \\ 
  -1.58 & sigma\_avg & 0 & NJ & NA & -1.74 \\ 
  -1.64 & sigma\_uu\_i & 0 & OK & 0.41 & NA \\ 
  -1.64 & sigma\_uu\_i & 0 & FL & -1.89 & NA \\ 
  -1.64 & sigma\_uu\_i & 0 & OH & -1.86 & -1.86 \\ 
  -1.64 & sigma\_uu\_i & 0 & ME & NA & -1.82 \\ 
  -1.64 & sigma\_uu\_i & 0 & NJ & NA & -1.81 \\ 
  -1.8 & sigma\_zero & 0 & WI & -2 & -2 \\ 
  -1.8 & sigma\_zero & 0 & NJ & -1.95 & -1.95 \\ 
  -1.8 & sigma\_zero & 0 & AR & -1.66 & -1.66 \\ 
  -2.62 & sigma\_avg & 1 & KY & -2.12 & -2.19 \\ 
  -2.62 & sigma\_avg & 1 & FL & -2.81 & -2.76 \\ 
  -2.62 & sigma\_avg & 1 & WI & -2.79 & -2.77 \\ 
  -2.6 & sigma\_uu\_i & 1 & KY & -2.15 & -2.24 \\ 
  -2.6 & sigma\_uu\_i & 1 & FL & -2.76 & -2.74 \\ 
  -2.6 & sigma\_uu\_i & 1 & WI & -2.76 & -2.77 \\ 
  -2.55 & sigma\_zero & 1 & KY & -2.27 & -2.27 \\ 
  -2.55 & sigma\_zero & 1 & WI & -2.76 & -2.76 \\ 
  -2.55 & sigma\_zero & 1 & TX & -2.42 & -2.42 \\ 
  -2.85 & sigma\_avg & 2 & OH & -3.73 & -3.61 \\ 
  -2.85 & sigma\_avg & 2 & AZ & -2.23 & -2.33 \\ 
  -2.85 & sigma\_avg & 2 & FL & -2.34 & -2.23 \\ 
  -2.96 & sigma\_uu\_i & 2 & OH & -3.77 & -3.75 \\ 
  -2.96 & sigma\_uu\_i & 2 & AZ & -2.31 & -2.4 \\ 
  -2.96 & sigma\_uu\_i & 2 & FL & -2.49 & -2.38 \\ 
  -3.11 & sigma\_zero & 2 & OH & -3.82 & -3.82 \\ 
  -3.11 & sigma\_zero & 2 & FL & -2.49 & -2.49 \\ 
  -3.11 & sigma\_zero & 2 & AZ & -2.58 & -2.58 \\ 
   \hline
\end{tabular}
\caption{OATE leave-one-state-out analysis}
\label{oateloostate}
\end{table}

Finally, Figure XXX displays a heatmap visualizing these results for our preferred estimates and covariate groups of interest. EXPLAIN MORE HERE.


\subsection{Appendix E: SBW Program Details}

We implement SBW using a modification of Noah Griefer's ``optweight'' package available in R. The modifications are available on ``github.com/mrubinst757'', but are not documented. We use this program to generate weights that balance the means of the following covariates in the treated group to the control group within an error tolerance, $\delta$. When estimating the weights on different subsets of the data, $\delta^\star$ is not guaranteed to converge. We therefore modify the program so that if it does converge, it relaxes some of the constraints until the program converges. The program is available on github.com/mrubinst757/Medicaid-Expansion-Project/03\_RPrograms/03\_Analysis/02\_model-estimation.R and all R programs used to complete this analysis are available in the parent directory.

\end{document}






