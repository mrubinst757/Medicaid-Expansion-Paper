% Template for the submission to:
%   The Annals of Applied Statistics    [AOAS]
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% In this template, the places where you   %%
%% need to fill in your information are     %%
%% indicated by '???'.                      %%
%%                                          %%
%% Please do not use \input{...} to include %%
%% other tex files. Submit your LaTeX       %%
%% manuscript as one .tex document.         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[aoas]{imsart}

%% Packages
\RequirePackage{amsthm,amsmath,amsfonts,amssymb,centernot}
\RequirePackage{natbib}
%\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}
\RequirePackage{graphicx}% uncomment this for including figures

\startlocaldefs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Uncomment next line to change            %%
%% the type of equation numbering           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\numberwithin{equation}{section}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% For Axiom, Claim, Corollary, Hypothezis, %%
%% Lemma, Theorem, Proposition              %%
%% use \theoremstyle{plain}                 %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{axiom}{Axiom}
\newtheorem{claim}[axiom]{Claim}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}{Proposition}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% For Assumption, Definition, Example,     %%
%% Notation, Property, Remark, Fact         %%
%% use \theoremstyle{remark}                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{remark}
\newtheorem{remark}{remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\theoremstyle{plain}
%\newtheorem{???}{???}
%\newtheorem*{???}{???}
%\newtheorem{???}{???}[???]
%\newtheorem{???}[???]{???}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% For Assumption, Definition, Example,     %%
%% Notation, Property, Remark, Fact         %%
%% use \theoremstyle{remark}                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\theoremstyle{remark}
%\newtheorem{???}{???}
%\newtheorem*{???}{???}
%\newtheorem{???}{???}[???]
%\newtheorem{???}[???]{???}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Please put your definitions here:        %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endlocaldefs

\begin{document}

\begin{frontmatter}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{The Effect of Medicaid Expansion on Non-Elderly Adult Uninsurance Rates Among States that did not Expand Medicaid}
%\title{A sample article title with some additional note\thanksref{T1}}
\runtitle{}
%\thankstext{T1}{A sample of additional note to the title.}

\begin{aug}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%Only one address is permitted per author. %%
%%Only division, organization and e-mail is %%
%%included in the address.                  %%
%%Additional information can be included in %%
%%the Acknowledgments section if necessary. %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author[A]{\fnms{Max} \snm{Rubinstein}\ead[label=e1]{Heinz College and Department of Statistics and Data Science}} and
\author[A]{\fnms{Amelia} \snm{Haviland}\ead{Heinz College and Department of Statistics and Data Science}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Addresses                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\address[A]{Carnegie Mellon University, \printead{e1}}

\end{aug}

\begin{abstract}
We estimate the effect of Medicaid expansion on the adult uninsurance rate in states that did not expand Medicaid in 2014 using a novel extension of the synthetic controls approach (\cite{abadie2010synthetic}). The existing literature primarily estimates treatment effects on states that expanded Medicaid. We hypothesize these effects differ: prior to the 2014 expansion, evidence suggested that Medicaid take-up rates are lower among conservative states (\cite{sommers2012understanding}), and Republicans were more likely to govern non-expansion states. We therefore hypothesize that the treatment effect on states that did not expand Medicaid would have been closer to zero than for states that did expand Medicaid. Using data from the American Community Survey (ACS), we estimate the effect on non-expansion states by re-weighting expansion regions to approximately balance the covariates from non-expansion regions. We contribute to the literature on balancing weights by accounting for hierarchical data and measurement error in the covariates when calculating the weights. We estimate that Medicaid expansion would have changed the uninsurance rate by -2.17 percentage points (-3.41, -0.94). These results are smaller in absolute magnitude than existing estimates of the treatment effect on the treated (see, e.g., \cite{courtemanche2017early}). We provide evidence that factors associated with Republican governance may drive this difference.
\end{abstract}

\begin{keyword}
\kwd{Synthetic controls}
\kwd{Balancing weights}
\kwd{Medicaid expansion}
\end{keyword}

\end{frontmatter}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Please use \tableofcontents for articles %%
%% with 50 pages and more                   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Main text entry area:

\section{Introduction}

The 2010 Affordable Care Act (ACA) required states to expand their Medicaid eligibility requirements by 2014 to offer coverage to all adults with incomes at or below 138 percent of the federal poverty level (FPL). The United States Supreme Court ruled this requirement unconstitutional in 2012, allowing states to decide whether to expand Medicaid coverage. In 2014, twenty-six states and the District of Columbia expanded their Medicaid programs. From 2015 through 2020 an additional twelve states elected to expand their Medicaid programs. This first wave of expansions in 2014 enabled researchers to examine the effects of Medicaid expansion by using expansion states as ``treated'' states and non-expansion states as ``control'' states. Our primary goal in this paper is to estimate the effect of 2014 Medicaid expansion on non-elderly adult uninsurance rates among states that did not expand Medicaid.

We predict that the treatment effect on non-expansion effect will be smaller in absolute magnitude than in states that expanded Medicaid in 2014. Medicaid take-up rates are lower than 100 percent and historically have varied across states. This variation is partly a function of state discretion in administering programs: for example, program outreach, citizenship verification policies, and application processes differ across states (\cite{courtemanche2017early}). Here we consider how political composition may have driven differences in take-up rates between states. Prior to the 2014 Medicaid expansion, \cite{sommers2012understanding} found that conservative political ideology was associated with lower Medicaid enrollment rates, even after controlling for a variety of other policies. Most importantly, political ideology appears to have largely driven a state's decision to expand Medicaid in 2014. Figure~\ref{fig:stateideology} plots a measure of each state's 2013 institutional ideology score (\cite{berry1998measuring}) by their Medicaid expansion status. Higher values of this score correspond to more liberal government institutions. The red dashed line indicates the mean expansion state score and the gray dashed line indicates the mean non-expansion state score. Figure~\ref{fig:stateideology} illustrates that non-expansion states are more conservative than expansion states. If the differential take-up rates observed by \cite{sommers2012understanding} continue to hold post-expansion, we should expect treatment effects on non-expansion states to be smaller in absolute magnitude than treatment effects on expansion states. 

\begin{figure}
    \begin{center}
    \caption{Government ideology and Medicaid expansion}
    \label{fig:stateideology}
    \includegraphics[scale=0.6]{01_Plots/political-expansion-plot.png}
    \end{center}
\end{figure}

This paper makes two methodological contributions to the literature on balancing weights. First, we extend the ``synthetic controls'' framework to estimate the treatment effect on the controls (ETC) using longitudinal data and we clarify the required assumptions. In brief, while balancing on pre-treatment outcomes alone arguably suffices for some synthetic control applications (see, e.g., \cite{botosaru2017role}), because our goal in this setting is to estimate treatment response, we must therefore balance on all covariates that predict treatment response, not just the outcome level absent treatment. Moreover, we cannot simply leverage pre-treatment data to conduct variable selection in this setting. We instead use an implementation of Stable Balancing Weights (\cite{zubizarreta2015stable}) to estimate a set of positive weights to weight the expansion regions to approximately match the covariate distribution of the non-expansion regions. 

Our second contribution is to modify the Stable Balancing Weights (SBW) objective function to account for our data, which is both hierarchical and has several covariates measured with error. Specifically, we use data from the American Community Survey (ACS) aggregated to the consistent public use microdata area (CPUMA) level. These regions nest within states, and using these smaller regions allows us to get better covariate balance. However, as a result, our data both has a hierarchical structure (regions within states) and, because our region-level covariates are estimated from underlying survey data, the sampling variability from our covariate estimates is a form of measurement error which may bias our treatment effect estimates. We first propose a modification of the SBW criterion to account for the hierarchical nature of the data, which disperses the weights more evenly across states. We then leverage the replicate survey weights provided in the ACS microdata to estimate the covariance matrix associated with the sampling variability and use this information to correct for this bias, following the regression calibration literature (see, e.g., \cite{gleser1992importance}). This is the first study we are aware of that attempts to adjust for hierarchical data structure and measurement error in the covariates when using balancing weights. 

The remainder of this paper has the following structure. Section 2 provides an overview of the data and defines the study period, covariates, outcome, and treatment. Section 3 discusses our methods, beginning by defining our target estimand, and then outlining our identification, estimation, and inferential procedures. Section 4 presents our results and sensitivity analyses. Section 5 contains a discussion of the policy relevance of our findings, and Section 5 contains a brief concluding summary of the paper. The Appendices contain additional materials, including summary statistics and additional results.

\section{Data}

In this section we overview of our data source, the covariates, the outcome, and the treatment assignment.

\subsection{Data Source}

Our primary data source is the annual household and person public use microdata files from the American Community Survey (ACS) from 2011 through 2014. The ACS is an annual survey of approximately three million individuals across the United States. The public use microdata files include information on individuals in geographic areas greater than 65,000 people. The smallest geographic unit contained in these data are public-use microdata areas (PUMAs), arbitrary boundaries that nest within states but not within counties or other more commonly used geographic units. One limitation of these data is a 2012 change in the PUMA boundaries, which do not overlap well with the previous boundaries. As a result, the smallest possible geographic areas that nest both PUMA coding systems are known as consistent PUMAs (CPUMAs). The United States contains 1,075 total CPUMAs, with states ranging from having one CPUMA (South Dakota, Montana, and Idaho) to 123 CPUMAs (New York). The average total number of sampled individuals per CPUMA across the four years within our primary dataset of 929 CPUMAs (discussed in Section \ref{sssec:txassign}) is 1,001; the minimum number of people sampled was 334 and the maximum is 23,990. Importantly, this survey does not follow specific individuals over time but rather reflects a different sample of individuals each year.

\subsection{Study period}

We begin our analysis in 2011 following \cite{courtemanche2017early}, who note that several other aspects of the ACA were implemented in 2010 -- including the provision allowing for dependent coverage until age 26, and the elimination of co-payments for preventative care -- and likely induced differential shocks across states. We also restrict our post-treatment period to 2014: several additional states expanded Medicaid in 2015, including Indiana, Michigan, and Pennsylvania. However, these states did not expand Medicaid contemporaneously with the 2014 ACA provisions. Without additional assumptions, this second-year expansion cannot help us estimate the effect of the 2014 expansion. 

\subsection{Covariates}

We use the underlying individual-level ACS survey data and accompanying survey weights to aggregate the data at the CPUMA level. We choose our covariates to approximately align with those considered in \cite{courtemanche2017early} and that are likely to be potential confounders. Because we are ultimately interested in calculating rates, these variables include both the numerator and denominator counts.\footnote{When viewing the denominator variables as random, these ratio estimators will in general be biased. This bias, however, decreases quickly with the sample size (is $O(n^{-1})$). Given that our CPUMA sample sizes are all over 300, we treat these estimates as unbiased in our analysis.}

Using the ACS survey weights, we first estimate: the total non-elderly adult population for each year 2011-2014; the total labor force population (among non-elderly adults) for each year 2011-2013; and the total number of households averaged from 2011-2013. We also construct an average of the total non-elderly adult population from 2011-2013. These are our denominator variables. For our numerator counts, we estimate the total number of: females; whites; people of Hispanic ethnicity; people born outside of the United States; citizens; people with disabilities; married individuals; people with less than a high school education, high school degrees, some college, or college graduates or higher; people living under 138 percent of the FPL, between 139 and 299 percent, 300 and 499 percent, more than 500 percent, and who did not respond to the income survey question; people aged 19-29, 30-39, 40-49, 50-64; households with one, two, or three or more children, and households that did not respond about the number of children.\footnote{Number of children and income to poverty ratio were the only two variables with missing data in the underlying microdata.} We average these estimated counts using the ACS survey weights from 2011-2013. For each individual year from 2011-2013, we estimate the total number of people who were unemployed and uninsured at the time of the survey (calculated among all non-elderly adults and all non-elderly adults within the labor force, respectively). We divide the numerator counts by the corresponding denominator counts to estimate the percentage in each category. For the demographics, these include the average number of non-elderly adults from 2011-2013. For the time-varying variables, we use the corresponding year (where uninsurance rates are calculated as a fraction of the labor force rather than the non-elderly adult population). We also calculate the average non-elderly adult population growth and the average number of households to adults across 2011-2013. 

In addition to the ACS microdata, we use 2010 Census data to calculate the approximate percentage of people living within an ``urban'' area for each CPUMA. Finally, we include three state-level covariates reflecting the partisan composition of each state's government in 2013. Specifically, we use data from the National Conference of State Legislatures (NCLS) to generate an indicator for states with a Republican governor, an indicator for states with Republican control over the lower legislative chamber, and an indicator for states with Republican control over both chambers of the legislature and the governorship.\footnote{Nebraska is the only state with a unicameral legislature; moreover, the legislature is technically non-partisan. We nevertheless classified them as having Republican control of the legislature.} 

\subsection{Outcome}

Our outcome of interest is the non-elderly adult uninsurance rate in 2014, which we denote using $Y$. While take-up among the Medicaid-eligible population is a more natural outcome, we choose the non-elderly adult uninsurance rate for two reasons, one theoretic and one practical. First, Medicaid eligibility in the post-period is likely endogenous: Medicaid expansion may affect an individual's income and poverty levels, which in general define Medicaid eligibility. A second reason is to align our study with others to compare our results with the existing literature, and this is the outcome that \cite{courtemanche2017early} use. One drawback of using this outcome is that the simultaneous adoption of other ACA provisions in 2014 more clearly affects this rate in a way that a more targeted group might not be.

\subsection{Treatment assignment} \label{sssec:txassign}

While some states expanded Medicaid and other states did not, assigning a binary treatment status simplifies a more complex reality. There are three reasons to be cautious about this simplification. First, states differed substantially in their Medicaid coverage policies prior to 2014: with perfect data we might consider Medicaid expansion as a continuous treatment with values proportional to the number of newly eligible individuals. The challenge though is correctly identifying newly eligible individuals in the data (see \cite{frean2017premium}, who attempt to address this). Second, \cite{frean2017premium} note that five states (California, Connecticut, Minnesota, New Jersey, and Washington) and the District of Columbia adopted partial limited Medicaid expansions prior to 2014. \footnote{\cite{kaestner2017effects} and \cite{courtemanche2017early} also consider Arizona, Colorado, Hawaii, Illinois, Iowa, Maryland, and Oregon to have had early expansions.} Lastly, timing is an issue: among the states that expanded Medicaid in 2014, Michigan's expansion did not go into effect until April 2014, while New Hampshire's expansion did not occur until September 2014.

Our primary analysis excludes New York, Vermont, Massachusetts, Delaware, and the District of Columbia from our pool of expansion regions, because these regions had comparable Medicaid coverage policies prior to 2014 (\cite{kaestner2017effects}). We also exclude New Hampshire because it did not expand Medicaid until September 2014. While Michigan expanded Medicaid in April 2014, we leave this state in our pool of treated states. We consider the remaining expansion states as ``treated'' and the non-expansion states as ``control'' states. We later consider the sensitivity of our results to these classifications by removing the early expansion states noted by \cite{frean2017premium}. Our final dataset contains aggregated statistics for all of the above variables for 925 CPUMAs in our non-expansion and our pool of expansion states. There are 414 CPUMAs among 24 non-expansion states and 515 CPUMAs among 22 expansion states. When we exclude the early expansion states for sensitivity analyses, we are left with 296 CPUMAs across 17 states.

\section{Methods}
\label{sec:methods}

In this section we present our causal estimand, identifying assumptions, estimation strategy, and inferential procedure.

\subsection{Estimand}

Our goal is to estimate the average effect 2014 Medicaid expansion would have had on the non-elderly adult uninsurance rate in states that did not expand Medicaid. Let $c$ index a CPUMA, $s$ index the state, and $t$ index the time period. Let $n_1$ be the number of treated CPUMAs, $n_0$ be the number of control CPUMAs, and $n$ be the total number of CPUMAs. Similarly, let and $m = m_1 + m_0$ states (with $m_1$ and $m_0$ defined analogously). Each state has $p_s$ CPUMAs. Since we are only interested in the counterfactual at time $T = 2014$, we simplify notation by removing this variable and the subscript and write our formal estimand as:

\begin{equation}
\psi = \psi^1 - \psi^0 &= n_0^{-1}\sum_{s, c: A_s = 0} Y_{sc}^{A_s = 1} - Y_{sc}^{A_s = 0}
\end{equation}

The challenge is estimating $\psi^1$ using our pool of treated units. That is, we wish to predict the counterfactual uninsurance rates in 2014 for states that did not expand Medicaid expansion had they expanded their Medicaid eligibility requirements. \foonote{The 2014 Medicaid expansion occurred simultaneously with the implementation of several other major ACA provisions, including (but not limited to) the creation of the ACA-marketplace exchanges, the individual mandate, health insurance subsidies, and community-rating and guaranteed issue of insurance plans (\cite{courtemanche2017early}). Almost all states broadly implemented these reforms beginning January 2014. Conceptually we think of the other ACA components as a state-level treatment ($V$) separate from Medicaid expansion ($A$). Therefore, our total estimated effect may also include interactions between these policy changes; however, we do not attempt to separately identify these effects. Because the ACA implementation and Medicaid expansion may vary over time, we do not try to generalize these results beyond 2014.} 

\subsection{Identification}

The following causal assumptions are necessary (though not sufficient) to enable us to identify our target parameter from the data: consistency, no unmeasured confounding, no anticipatory treatment effects, and positivity of treatment assignment. We explain these assumptions in detail and their consequences below. We additionally invoke several parametric assumptions to help us identify our causal parameter given the measurement error in our covariates.

Consistency implies that a CPUMA's potential outcome under some treatment assignment is equal to the observed factual outcome given that same treatment assignment: 

\begin{align*}
Y_{sc}^{A_{sc} = a} = Y_{sc}(A_{sc} = a)
\end{align*}

In other words, we assume that one region's treatment assignment does not affect another region's observed outcome. This is a standard assumption, but is often not realistic. Violations of this assumption are likely in our setting: for example, \cite{frean2017premium} find evidence that Medicaid expansion drove previously eligible but uninsured individuals to enroll in Medicaid in both expansion and non-expansion states. Signing the potential bias from this violation requires redefining the causal estimand: for example, we might consider the treatment effect on the untreated given that all states have expanded Medicaid, where the contrast is against where only the observed expansion states expanded Medicaid. If spillovers occurred in equal proportions across each region, and the magnitude of the spillovers increase with the total number of treated regions, then the true effect would be larger in absolute magnitude than the estimated estimated using the observed data. We could consider other estimands or assumptions to get different predictions about the sign of the bias; however, this is beyond the scope of this paper.

We next assume that there were no anticipatory treatment effects. Letting treatment occur at time $T$, we have that for $t < T$:

\begin{align*}
Y_{sct} = Y_{sct}^0
\end{align*}

This assumption is necessary because we are conditioning on pre-treatment outcomes. If these outcomes were affected by the treatment before it were implemented, these covariates would be endogenous. Anticipatory treatment effects may occur if plans to expand Medicaid induce uninsured but Medicaid-eligible individuals to enroll in Medicaid prior to expansion. We do not think these violations occurred in large enough numbers to substantially affect our results. Instead, we address a more concerning version of this violation: the fact that several states allowed certain counties to expand Medicaid prior to 2014. We therefore test the sensitivity of our results to the exclusion of these states.

Third, we assume no unmeasured confounding; that is, that at time $T$ the potential outcomes for each CPUMA are independent of the state-level treatment assignment conditional on the population-level CPUMA and state-level covariates $X_{sc}$ (which includes pre-treatment outcomes):

\begin{align*}
Y_{sc}^a \perp A_{sc} \mid X_{sc}
\end{align*}

While unverifiable, we believe it is reasonable here given our rich covariate set. To be explicit, we believe that the potential uninsurance rates for each CPUMA are independent of the treatment assignment conditional on the percentage of uninsured individuals in each year of the pre-treatment period, the percentage of unemployed individuals in each year of the pre-treatment period, the average population growth, the average ratio of households to non-elderly adult population, the state's political composition, the average proportion of households with one, two, or three or more children during the pre-treatment period, the average proportion of households who did not respond about their number children, and the average proportion of individuals during the pre-treatment period with given demographics noted above (age group, sex, white, Hispanic ethnicity, U.S. citizenship, foreign born, income-to-poverty group (including non-response), disability status, urban residence, and educational attainment group). 

Finally, we assume positivity of treatment assignment; that is, that all states had some non-zero probability of being treated 

\begin{align*}
\pi(X_{1s}, ..., X_{p_ss}) > \epsilon
\end{align*}

where the propensity score is some function of the covariate values for each CPUMA and where $\epsilon > 0$. Positivity violations can cause a lack of covariate overlap in the observed data. Overlap is an issue in this study. We address this in multiple ways that we outline in our estimation strategy below. 

These assumptions are sufficient to non-parametrically identify our causal estimand if we observed the true outcomes and covariates. Unfortunately, because our covariates are estimated using the ACS data, we do not observe the true values but rather mean-unbiased estimates $J_{sc} = Y_{sc} + \xi_{sc}$ and $W_{sc} = X_{sc} + v_{sc}$. Importantly, $Y_{sc}^a \perp A_{sc} \mid X_{sc} \centernot\implies J_{sc}^a \perp A_{sc} \mid W_{sc}$. The use of these proxies may therefore bias our estimates. We rely on several modeling assumptions to correct for this bias.

We begin by placing restrictions on the errors in the outcome measurement $\xi_{sc}$. First, we assume that these errors are uncorrelated with the true values of $Y_{sc}$. Second, we assume that $\xi_{sc}$ is uncorrelated with $X_{sc}$. Third, we assume that $\xi_{sc}$ are uncorrelated with the errors in the covariate measurements ($v_{sc}$). This first and second assumptions are reasonable given that the measurement error is simply sampling variability. The third assumption is also reasonable because our outcomes are measured on a different cross-section of data than our covariates. 

We next assume that the potential outcomes are linear in the true covariates $X_{sc}$. Specifically, we assume that the following model generates the potential non-elderly adult uninsurance rate under treatment $A = a$:

\begin{equation}
Y_{sc}^a = \alpha_a + X_{sc}^T\beta_a + \epsilon_{sc} + c_s
\end{equation}

We assume that the errors $\epsilon_{sc}$ and $c_s$ are independent from each other and across time (i.e., we rule out serial-correlation), that these errors are invariant to the intervention, and are uncorrelated with the true covariates. This model then allows us to identify $\psi^a$ in terms of our model parameters (see Appendix A); specifically, we have that $\psi^a = \alpha_a + \bar{X}_0^T\beta_a$, where $\bar{X}_0$ is the vector of mean covariate values among the control units. Moreover, we can substitute $J_{sc}$ for $Y_{sc}$ in this equation, and add $\xi_{sc}$ to the error term without affecting this identification.\footnote{We also assume that $\xi_{sc}$ is uncorrelated with the errors in the outcome model, so there is no covariance term between any of these error components.} 

We still have the problem that we observe $W_{sc}$ instead of $X_{sc}$. We again assume that these errors are uncorrelated with the true covariate values (i.e. are sampling variability). Let $\mu_a = \mathbb{E}\{X_{sc} \mid W_{sc}, A = a\}$. By linearity, we know that

\begin{equation}
    J_{sc} = \eta_a(W_{sc})^T\beta + (X_{sc} - \eta_a(W_{sc}))^T\beta + \xi_{sc} + \epsilon_{sc} + v_s 
\end{equation}

If we knew $\eta_a$, we could estimate this model using the observed data $(J, W)$. The approach we follow here is known as ``regression calibration'' in the measurement-error literature. In particular, we assume the following model for $\eta_a$:

\begin{align*}
\eta_a(W_{sc}) = \mu_a + \kappa^T(W_{sc} - \mu_a)
\end{align*}

where $\kappa = (\Sigma_{XX} + \Sigma_{vv})^{-1}\Sigma_{XX}$. This model is motivated by the assumptions that $W_{sc} = X_{sc} + v_{sc}$, where $(X_{sc}, v_{sc}) \stackrel{iid}\sim MVN((\mu_a, 0)^T, \Sigma)$ and $\Sigma$ is block-diagonal consisting of elements $\Sigma_{XX}$ and $\Sigma_{vv}$. Given sufficient auxillary data to estimate $\kappa$, we can use these models to consistently estimate of $\psi$. We discuss this further below and in Appendix A (see also \cite{gleser1992importance}).

\subsection{Estimation}

We first outline our procedure to estimate the ETC given our assumptions above, using a novel extension of Stable Balancing Weights. Using this estimation method, we then outline our strategy to examine whether there might be treatment effect heterogeneity with respect to Republican governance.

\subsection{Estimating the ETC}

We outline our estimation strategy first emphasizing how our method differs from the synthetic controls approach, which motivates our use of the SBW objective. Second, we explain a modification we make to the SBW criterion to address the hierarchical data structure (which we call H-SBW) that reduces the variance of our estimator under our assumption of within-state correlation of our model errors. Third, we connect our estimator to the regression calibration literature by generating weights that balance a linear prediction of the true covariates $\hat{\eta}_a(W_{sc})$ using the observed covariates $W_{sc}$. 

We also test the sensitivity of our estimator to a ridge-augmented version, following the suggestion of \cite{ben2018augmented}; this allows us to achieve better covariate balance by extrapolating beyond the support of the data. As a separate sensitivity check, we estimate a different causal parameter -- the overlap average treatment effect (OATE) -- using overlap weights, as discussed in \cite{li2018balancing}. Estimating this effect does not require extrapolation, but rather changing the target estimand. We discuss this further below.

Similar to synthetic controls applications, we seek to generate a set of positive weights that balance the means of covariates for the treated units to the mean of covariates for the control units. Assume that we observe the true covariate matrices $X_1$ and $X_0$, and the true outcomes $Y$, and let $\bar{X}_0$ be the mean covariate values in the non-expansion region. Ideally, there exists some $\gamma^\star$ such that for $\delta = 0$: 

\begin{align*}
(\frac{1}{n_0}X_1^T\gamma^\star - \bar{X}_0) \le \delta, \gamma_i^\star > 0, \gamma_{sc}^\star^T1 = n_0
\end{align*}

We could then estimate $\psi$ as

\begin{equation}\label{eqn:psi}
\hat{\psi} = n_0^{-1}(\sum_{s: A_s = 1}^{m_1}\sum_{c = 1}^{p_s}\gamma_{sc}^\star Y_{sc} - \sum_{s: A_s = 0}^{m_0}\sum_{c = 1}^{p_s}Y_{sc})
\end{equation}

The assumption that the outcomes (absent treatment) follow a linear factor model frequently motivates the synthetic controls approach; here we instead assume no unobserved confounding and assume that the outcomes given treatment are a linear function of the covariates: $\mu_1(X_{sc}) = \alpha_1 + X_{sc}^T\beta_1$. The bias of our estimator (again assuming we observed $X_{sc}$), is therefore less than or equal to $\lvert\beta\rvert^T\delta = 0$ (see, e.g., \cite{zubizarreta2015stable}). The challenge, however, is that for any given dataset we have no guarantee that any such $\gamma^\star$ exists that exactly balances the covariates; we therefore need some method of determining how to prioritize which parts of the covariate distribution we wish to balance to minimize this bias.

This is where estimating the ETC contrasts with the commonly used synthetic control approach used to estimate the ETT: \cite{abadie2010synthetic} determine how to prioritize covariate balance by training their model on pre-treatment outcomes (\cite{kaul2015synthetic} shows that often the most relevant covariates simply become the pre-treatment outcomes). Because in that setting the counterfactual value $Y^0_{sct}$ is actually observed for $t \le T_0$, \cite{abadie2010synthetic} are able to leverage this data to select the covariates that best predict these values. By contrast we never observe $Y^1_{sct}$ (or a mean-unbiased proxy for it) prior to treatment. Without additional assumptions, we cannot use the pre-treatment data to learn which covariates matter most for determining this potential outcome.

Moreover, the problem of predicting treatment response also makes estimating the ETC more challenging to estimate than the ETT. In particular, we likely care more about balancing ``auxillary covariates'' (covariates that are not pre-treatment outcomes) in our setting than the traditional synthetic controls setting. To see this, assume that $\mu_0$ is linear in the covariates, including the pre-treatment outcomes. We might reasonably believe the coefficients on the auxillary covariates are close to zero once we condition on pre-treatment outcomes. As a result, the bias induced by remaining imbalances on the auxillary covariates would be small. On the other hand, assuming $\mu_1$ is also linear in the same covariates, the coefficients on this model could be much larger, even after conditioning on pre-treatment outcomes, because these coefficients are highly predictive of treatment response. If our weights fail to balance these covariates, we should expect that our estimates of $\mu_0$ will in general have less bias than our estimates of $\mu_1$. In summary, estimating the ETC requires a greater understanding of how the covariates are related to treatment response than the ETT; moreover, we cannot learn this information by using pre-treatment outcomes.

We therefore estimate the ETC by using a variation of SBW that we call H-SBW.\footnote{Specifically, we use a modified implementation of Noah Griefer's ``optweight'' package in R, available on github.com/mrubinst757} This procedure allows us to estimate the minimum variance weights that satisfy user-specified balance constraints. Let $\hat{\eta}_1(W_1)$ be a matrix of estimates of $\eta_1(W_1)$ and $\bar{W}_0$ be a vector of estimates of the covariates for the non-expansion region.\footnote{Because $\bar{W}_0$ and $\bar{X}_0$ are equal in expectation, the use of this target will not contribute to any asymptotic bias of our estimator.} We generate weights that solve the following objective:

$$
\gamma = \min_{\theta \in \Gamma} \sum_{s: A_s = 1}^{m_1}(\sum_{c = 1}^{p_s} \gamma_{sc}^2 + \sum_{c \ne d}\rho \gamma_{sc}\gamma_{sd})\\
$$

$$
\Gamma = \{\theta \mid \frac{1}{n_0}\hat{\eta}_1(W_{sc})^T\gamma - \bar{W}_0 \mid \le \delta, \gamma_{sc} > 0, \sum_{s,c}\gamma_{sc} = n_0\}
$$

We then estimate $\psi$ using Equation~\ref{eqn:psi}, substituting $J_{sc}$ for $Y_{sc}$.

This objective is a modification of the SBW objective, which sets $\rho = 0$ and balances on $W_{sc}$ rather than $\hat{\eta}_1(W_{sc})$. Importantly, both allow the user to specify covariate-level balance constraints using the vector $\delta$. When estimating the ETC, we lean heavily on assumptions to justify our choice of $\delta$; in particular, we use a priori domain knowledge about which covariates are most likely to be important predictors of treatment effect heterogeneity when setting $\delta$. However, we also must choose $\delta$ to something that is feasible given the data. 

For our application, we constrain $\delta$ to be 0.05 percentage points for pre-treatment outcomes, 0.15 percentage points for pre-treatment unemployment rates. We believe these are the most likely factors associated with treatment response, so we prioritize balancing these covariates. For the remaining covariates, we let $\delta$ be 0.5 percentage points for average population growth and household to adult ratio, 1 percentage point for female, Hispanic ethnicity, white race, age category, disability, and number of children category; 2 percentage points for urban, citizenship, education category, income-to-poverty category, student, and foreign-born; and 25 percentage points for the Republican governance indicators. We choose these constraints primarily on feasibility concerns, and for our variance estimates, we reduce these initial constraints when this constraint set becomes infeasible.

We now discuss how H-SBW differs from SBW, beginning with the criterion. The motivation of the SBW criterion, which is equivalent to ours with $\rho = 0$, is to produce the minimum variance weights for a fixed $\delta$. This produces the minimum variance estimator within the constraint set if, for example, the errors in the outcome model are independent and identically distributed. In our setting we have possible state-level dependencies, reducing the efficiency of the SBW estimator. To improve the efficiency, we add the tuning parameter $\rho$; this parameter attempts to uniformly disperse the weights across states. This objective produces the minimum variance estimator within the constraint set if we assume a constant (and known) within-state correlation of the errors ($\rho$) and constant variance across units. We discuss this objective in more detail and provide simulation results in Rubinstein et al. (2021) (pre-print not yet available); broadly speaking, we can think of H-SBW being to SBW what generalized least squares (GLS) is to ordinary least squares (OLS): both SBW and OLS can produce unbiased estimates of model parameters; however, H-SBW and GLS can produce efficient estimators assuming a particular block-matrix correlation structure in the outcome errors. 

A more important departure from SBW comes in the constraint set: rather than balancing on the observed covariate values $W_{sc}$, we instead balance on $\hat{\eta}_1(W_{sc})$. The estimation error in these CPUMA-level covariates can bias our estimate of $\psi^1$. In Appendix A, Proposition 1, we consider the super-population target $\psi^{1, sp} = \mathbb{E}\{Y_{sc}^1 \mid A_{sc} = 0\}$ and show that under the classical errors-in-variables model, the bias for the SBW estimator that balances on the observed covariates $W$ and sets $\delta = 0$ is equivalent to the bias of a linear combination of coefficient estimates from the OLS-based regression estimator. Specifically, for either estimator:

\begin{equation}
\mathbb{E}\{\hat{\psi}^{1} - \psi^{1, sp}\} = (\mu_0 - \mu_1)^T(\kappa - I_d)\beta
\end{equation}

The intuition for this result is as follows: exact balancing weights estimate an implicit $\beta$ on a subset of the data where we have sufficient overlap. We can therefore think of SBW as returning a solution to some weighted-least squares problem. If we assume that the outcome model holds across all of the data, WLS and OLS are estimating the same $\beta$; therefore, the bias that effects the least squares solution will have the same effect on the WLS, and therefore SBW, solution. In Appendix A, Proposition 2, we further show that if we had access to $\eta_1$, we could obtain an unbiased estimate by balancing on $\eta_1(W_{sc})$.\footnote{For the finite-sample parameter we're interested in here, the estimator will have some finite-sample bias.} Of course, in practice we do not know $\eta_1$ but must estimate it using auxillary data. In Appendix A, Proposition 3, we show that we can obtain a consistent of $\psi^{1, sp}$ when balancing on an estimate of $\eta_1$ using auxillary data. 

For our application we leverage the person-level replicate survey weights provided in the ACS microdata to estimate the variability in each CPUMA's observed covariate values. This allows us to estimate $\hat{\Sigma_{vv, sc}}$. We can then use this information along with the observed data to estimate $\hat{\eta}_a$. We consider two versions of this procedure: first, our preferred version which accounts for the fact that some covariates are estimated much more precisely than others. Specifically, letting $s_{sc}$ be the vector of sample sizes used to estimate each covariate, we use the model $\sqrt{s}_{sc}v_{sc} \stackrek{iid}MNV(0, \Sigma_{vv})$. This model assumes that all of the heterogeneity in these error terms is due to the sample sizes used to calculate each estimate. This allows us to generate a separate $\kappa_{sc}$ for each unit using getting the full sample efficiency of the data for each estimate. We also generate a second adjustment that follows the traditionally used approach which does not account for this differential measurement error, and instead averages over all observed variance estimates $\hat{\Sigma}_{vv, sc}$ to estimate a single $\kappa$ for all units. Further details about these covariate adjustment procedures are available in Appendix B.

This is the first application we are aware of to use regression calibration methods in the context of balancing weights. We emphasize two critical assumptions for using this procedure in our context: (1) the outcome model is linear in the true covariates; and (2) the measurement error in the outcome is uncorrelated with the measurement error in the covariates. The first assumption is strong, though often used in practice. The second assumption is reasonable, because our outcomes are estimated from a different cross-section of individuals than our covariates. 

Finally, because we are unable to reduce the balance constraints to an optimal level, following the recent literature on synthetic controls, we test the sensitivity of our results to these imbalances by using ridge-regression augmented weights \cite{ben2018augmented}. Letting $\hat{\eta}_1(W_1)$ be the matrix of adjusted covariates, and $\gamma^{hsbw}$ be our H-SBW weights, we standardize our weights to sum to one and estimate the regression-augmented weights:

\begin{equation}
\gamma^{aug} = \gamma^{hsbw} + (\hat{\eta}_1(W_1)^T\gamma^{hsbw} - \bar{W}_0)^T(\hat{\eta}_1(W_1)^T\Omega^{-1}\hat{\eta}_1(W_1) + \lambda I_d)^{-1}\hat{\eta}_1(W_1)^T\Omega^{-1}
\end{equation}

where $\Omega$ is a block diagonal matrix with diagonal entries equal to one and the within-group off diagonals equal to $\rho$. We choose $\lambda$ so that the remaining imbalances all fall within 0.1 percentage points (see \cite{ben2018augmented} for more details on the connection between these weights and ridge-regression). The cost of this procedure is that we must extrapolate from the support of the data, and therefore rely more heavily on our modeling assumptions. In our results we consider estimators using SBW ($\rho = 0$), H-SBW ($\rho = 0.2$), and ridge-augmented versions of SBW and H-SBW that we call BC-SBW and BC-HSBW. We focus our discussion on our preferred estimator, H-SBW, and its ridge augmented version BC-HSBW. 

\subsection{Republican governance}

Our secondary research hypothesis is the ETC is lower in absolute magnitude than the ETT due to treatment effect heterogeneity with respect to Republican governance. However, we are unable to directly estimate the ETT with our approach due to a lack of covariate overlap. Moreover, the ETT may also differ from the ETC due to other demographic differences between the treated and control states. 

[remove?]
We instead conduct the following two analysis: (1) we specifically try to estimate the heterogeneity associated with Republican governance within the support of the data; (2) we examine how removing different covariate sets impact our estimate of $\hat{\psi}^1$. The first analysis most directly answers our research hypothesis. Unfortunately, in practice this is challenging to estimate due to the lack of covariate overlap. 
The second question can only inform us about associations between the covariates and the outcome on the treated data, but is much easier to conduct. Moreover, it can better inform our understanding of which covariates mattered most in determining our estimate. However, it requires strong assumptions on the outcome model absent treatment to identify the heterogeneous treatment effect with respect to those covariates.
[end]

Partitioning the covariates $X$ into groups $(S, V)$, where $V$ are the Republican governance indicators and $S$ are all other covariates, we ideally would wish to estimate the following contrast:

$$
\Delta^\star_v = \mathbb{E}\{Y^1 - Y^0 \mid S = \bar{S}_0, V = \bar{V}_0 + \tau\} - \mathbb{E}\{Y^1 - Y^0 \mid S = \bar{S}_0, V = \bar{V}_0\}
$$

for some $\tau < 0$ (that is, we compare the effect to a less Republican region). Our research hypothesis is that this contrast is negative. However, this is challenging in practice because of the difficulty of the lack of covariate overlap, particularly among Republican governance indicators. 

We instead limit consideration to the association between the Republican governance indicators and the outcome among treated states setting $(S = \bar{S}_0 + \delta_s, V = \bar{V}_0 + \delta_v + \tau)$, where $\tau$ is a data-dependent quantity that fully relaxes the balance constraint on covariates $V$. In particular, we remove different covariate groups from the covariate set and recalculate an estimate $\hat{\psi}^1_v$. We then subtract our original point estimate $\hat{\psi}^1_0$. Call this difference $\hat{\Delta}^1_v$. This difference can more generally tell us how our covariates contribute to our estimate of $\hat{\psi}^1$. It also can inform us about the bias our estimate of $\hat{\psi}^1$ would suffer if we removed the balance constraints. Finally, and most importantly, assuming $\delta$ is small, this also approximates the association between the covariates and the outcome on the treated dataset for a data dependent $\tau$:

\begin{align*}
    \hat{\Delta}^1_v &= n_t^{-1}\sum_{s, c: A_s = 1}(\gamma_v - \gamma_0)J_{sc} \\ 
    &\approx (\bar{X}_1^T(\gamma_v - \gamma_0))^T\beta_1 \\
    &\approx (\bar{V}_1^T(\gamma_v - \gamma_0))^T\beta_{1, v} \\
    &\approx \mathbb{E}\{Y \mid A = 1, S = \bar{S}_0, V = \bar{V}_0 + \tau\} - \mathbb{E}\{Y \mid A = 1, S = \bar{S}_0 V = \bar{V}_0\} \\
    &= \mathbb{E}\{Y^1 \mid S = \bar{S}_0, V = \bar{V}_0 + \tau\} - \mathbb{E}\{Y^1 \mid S = \bar{S}_0, V = \bar{V}_0\} \\
\end{align*}

where the first equality holds by definition, the first approximation holds from the linearity of the outcome model (and is approximate due to error in the outcome model), the second approximation because we have only changed the error tolerances on covariates $V$ (and is approximate because some imbalances within $S$ might change within the specified error tolerances $\delta_s$), the third approximation using our outcome model assumptions (assuming $\delta$ is small), and the final equality by consistency. 

Finally, notice that $\hat{\Delta}^1_v$ approximates $\Delta^\star_v$ if the vector of coefficients on covariates $V$ for the outcome model absent treatment $\beta_{0, v} \approx 0$ (or more generally if any linear combination of these coefficients is approximately zero). Therefore, this quantity can inform us about the potential for treatment effect heterogeneity. In particular, if our research hypothesis is incorrect, we should not find a positive partial association between Republican governance and the uninsurance rate, i.e. $\hat{\Delta}^1 = 0$. However, if our research hypothesis is correct, it is likely that we will find a positive association, i.e, $\hat{\Delta}^1 < 0$. Nevertheless, the presence of an association does not imply treatment effect heterogeneity unless we make further assumptions on the outcome model absent treatment.

In addition to the Republican governance indicators, we also examine the influence of four other covariate groups: pre-treatment uninsurance rates and pre-treatment unemployment rates, and three sets of different demographic indicators. Specifically, the first group includes: urban residence, age group, education, citizenship, student, disability, female; the second, white race, Hispanic ethnicity, foreign-born, and income-to-poverty ratio; the third, children category (0, 1, 2, 3+, NA), household to population ratio, and population growth; however, we leave the presentation of these results to Appendix E.

[remove??]

Finally, we consider a more direct approach to estimating the heterogeneity. While we cannot directly target $\Delta^\star_v$ setting $(S = \bar{S}_0, V = \bar{V}_0)$, if our outcome model holds generally we know that

$$
\Delta^\star_v = \tau^T\beta_v
$$

As a result, we can fix $(S = s, V = v)$ for any $(s, v)$ within the support of the data to estimate $\Delta^\star_v$. 

Following \cite{li2018balancing}, we use logistic regression to generate overlap weights to find one such $(s, v)$ where exact overlap is possible. Let $\gamma$ be weights that satisfy $\sum_{s,c: A_s = 1} \hat{\eta}_0(W_{sc})\gamma_{sc} = \sum_{s, c: A_s = 0} \hat{\eta}_1(W_{sc})\gamma_{sc} = \bar{X}_l$ (with each set of weights standardized to sum to one). We first use the logistic regression weights to calculate $\bar{X}_l$ (see \cite{li2018balancing}) and then use the H-SBW objective to re-estimate the weights targeting $\bar{X}_l$ and then $(\bar{S}_l, \bar{V}_l + \tau)$. We can then estimate $\hat{\Delta}^\star_v$ using the difference in means using the H-SBW weights.

$$
\hat{\Delta}^\star_v = \sum_{s,c: A_s = 1}(\gamma_{sc}^v - \gamma_{sc})J_{sc} - \sum_{s,c: A_s = 0}(\gamma_{sc}^v - \gamma_{sc})J_{sc}
$$

(where we standardized each set of weights to sum to 1). One challenge, however, the ``Republican Total Control'' indicator is perfectly collinear with Republican Governor and Republican Lower Legislature control indicators on the untreated data. Letting $\tau^e_3$ be the effective $\tau$ on this covariate when targeting the other two covariate to $\tau*$, we find that the effective difference on Republican Total Control $\tau^e_3 \approx 2\tau*$. This suggests directly setting $\tau = (\tau*, \tau*, 2\tau*)$ for the treated data. The challenge is finding a $\tau$ small enough that we don't have to substantially change the imbalances $\delta$ on the other covariates. We set $\tau = 5$ and $\delta = 0$ at the outset and relax delta by $0.01$ increments until it converges (or fails to converge after 50 iterations).

[end of remove]

\subsection{Inference}

We first consider $Var(\hat{\psi}^1)$. Because we view the unobserved covariates $X$ and the observed $W$ as fixed, the variability in this estimator comes from (1) the errors in our outcome model; (2) the variability in our estimator $\hat{\eta}_1$.\footnote{If we viewed $X$ as random, we would also have to consider terms induced by $Cov(X \mid W)$ (see Appendix A).} We use the leave-one-state-out jackknife to estimate the variance $Var(\hat{\psi}^1 \mid W)$ (\cite{cameron2015practitioner}), where we hold our targeted mean fixed at $\bar{W}_0$, which is an unbiased estimate of $\bar{X}_0$. When our preferred initial choice of $\delta$ does not converge, we programmatically reduce the constraints until the program converges. 

We calculate this estimator in two ways: first, we condition on our covariate adjustment $\hat{\eta}_1$ -- that is, we treat $\hat{\eta}_1$ as $\eta_1$. This is our preferred estimator. We also calculate $\hat{\eta}_1$ omitting each state in the jackknife procedure. We leave these secondary results results to the Appendix.

To estimate $Var(\hat{\psi}^0 \mid W)$ we use an auxillary regression model and use the CR-2 standard error adjustment to estimate the variance of the linear combination $\bar{W}_0^T\hat{\beta}_0$ (using the ``clubSandwich'' package in R). Notice that we can run this regression on the original data because $\bar{W}_0^T\hat{\beta}_0 = \bar{J}_0$ (which is unbiased for $\psi^0$). In general we expect that the variance of $\hat{\psi}^1$ will dominate the variance of $\hat{\psi}^0$ because in practice the balance constraints will substantially reduce the effective sample size of the treated data. 

\section{Results}

This section presents the results from our analyses. We begin by presenting statistics on the imbalances in the covariates between the treatment, control, and weighted treatment groups. We then present our primary results, including both our treatment effect estimates and our analysis of the association of Republican governance on our estimates. We conclude by reviewing a series of sensitivity analyses that check the robustness of our results to using an alternative dataset and target estimand.

\subsection{Covariate Balance}

Figure~\ref{fig:loveplotc1} shows how our balancing weights reduce the imbalances among covariates with greater than one percentage point difference between the targeted mean in the expansion region and the mean values in the non-expansion region (we target the population-weighted mean of the untreated region).\footnote{The reweighted treatment values use our preferred covariate adjustment $\hat{\eta}_1(W_{sc})$.} Before applying our weights, we see that there are substantial imbalances in the Republican governance indicators, as well as pre-treatment uninsurance and unemployment rates. Our weights drastically reduce these differences; however, some imbalances remain. In particular, imbalances remain in the Republican governance indicators. A complete balance table is available in Appendix D, Table~\ref{tab:baltab1}. Appendix C contains additional summary statistics. 

\begin{figure}[B]
\begin{center}
    \caption{Balance plot, primary dataset}
    \label{fig:loveplotc1}
    \includegraphics[scale=0.6]{01_Plots/balance-plot-etu.png}
\end{center}
\end{figure}

As discussed above, we use a ridge-regression augmentation to extrapolate from the data in order to reduce all imbalances within 0.5 percentage points. Figure~\ref{fig:statewghts} shows the total weights summed across states for each estimator: H-SBW and BC-HSBW. This figure sums the negative weights separately from the positive weights to show the extent of the extrapolation. We see that BC-HSBW extrapolates heavily in order to estimate the counterfactual, particularly for CPUMAS in California. Due to this extensive extrapolation, we therefore prefer the H-SBW estimator, though we compare results against BC-HSBW as a robustness check.

\begin{figure}[B]
\begin{center}
    \caption{Total weights summed by state, primary dataset}
    \label{fig:statewghts}
    \includegraphics[scale=0.6]{01_Plots/weights-by-state-hsbw-c1.png}
\end{center}
\end{figure}

\subsection{Primary Results}

Using H-SBW we calculate an estimated effect of -2.17 (-3.41, -0.94). In other words, we estimate that had states that did not expand Medicaid in 2014 done so, they would have seen a 2.17 percentage point reduction in their uninsurance rates that year. While remaining imbalances are quite large, the bias-correction makes little substantive difference, yielding an estimate of -2.13 (-3.55, -0.71). These estimates differ somewhat from the estimates we find running the procedure on our unadjusted covariate estimates: here H-SBW gives an estimated effect of -2.35 (-3.09, -1.61), and the bias corrected estimator yields -2.39 (-3.33, -1.46). Using the adjusted covariate set appears to both move our estimate closer in absolute magnitude towards zero and decreases the width of the estimated confidence intervals. Figure~\ref{fig:estimators} displays the point estimates from these weighting estimators, as well as estimators using SBW, on the adjusted and unadjusted datasets. Additional results are available in Appendix E.

\begin{figure}
\begin{center}
    \caption{Point estimates}
    \label{fig:estimators}
    \includegraphics[scale=0.6]{01_Plots/point-estimates-c1.png}
\end{center}
\end{figure}

We examine the robustness of our point estimates to the removal of individual states (note that these are the point estimates used to calculate our confidence intervals). Figure~\ref{fig:loostateplot} shows how the point estimates change for both the adjusted (``sigma\_uu\_i\_modeled'') and unadjusted (``sigma\_zero'') datasets. We see similar results in either case: removing Ohio and Arkansas tends to increase the absolute magnitude of the point estimates. By contrast, removing California decreases the absolute magnitude of the estimators, particularly for estimators that are not bias-corrected. The results are quite similar when using different covariate adjustments and when recalculating the entire procedure (additional results are available in Appendix E, Table~\ref{tab:loostatec1}). 

\begin{figure}
\begin{center}
    \caption{Estimator sensitivity to states}
    \label{fig:loostateplot}
    \includegraphics[scale=0.6]{01_Plots/loostate-sensitivityc1-state-uu-i.png}
\end{center}
\end{figure}

We now consider our second research question: whether Republican governance might be an effect modifier for the treatment effect. Let $\hat{\Delta}^1$ be the difference in estimators when removing the Republican governance indicators compared to the original estimate. For the H-SBW estimator we calculate $\hat{\Delta}$ equal to -0.67 (-1.63, 0.28) for BC-HSBW and -0.74 (-1.86, 0.39). We see similar differentials on our unadjusted dataset (-0.65 (-1.20, -0.09) and -0.70 (-1.48, 0.08), respectively). These results are consistent with our hypothesis that Republican governance drives heterogeneity in the effect of Medicaid expansion. While our confidence intervals include zero, we find that these differences are negative for all estimators we consider when removing each state (conditional on the covariate adjustment). That is, the sign of the differences in the contrasts remains negative for every specification that we run.\footnote{When rerunning the entire preferred covariate adjustment procedure, the only specification that is greater than zero occurs when removing Illinois. For our secondary adjustment (results available in Appendix E), the results are sensitive to the removal of both Illinois and California. None of the leave-one-state-out estimates are greater than zero when removing the early expansion states.} Overall we view this as suggestive (though not definitive) evidence consistent with our research hypothesis.

Appendix E Figure~\ref{fig:rdiffc1state} and Figure~\ref{fig:rdiffc1proc} display all estimates $\hat{\Delta}^1$ with each state removed, both conditional on the covariate adjustment and recalculating the covariate adjustment, respectively. We also consider four other covariate sets and present these results in Appendix E, Table~\ref{tab:ptests}. None of these results are especially surprising, though we do see that controlling for pre-treatment outcomes and unemployment rates matters substantially for our point estimates. The other results are slightly sensitive to the removal of different covariate groups, but the changes when removing the pre-treatment unemployment and uninsurance rates or the Republican governance indicators are the strongest and most consistent. Additional results for different estimators are available in Appendix E, Table~\ref{tab:deltac1}.

\subsection{Sensitivity Analyses} \label{sssec:sensitivity}

We examine the sensitivity of our analysis to violations of two key causal assumptions: (1) no anticipatory treatment effects, and (2) positivity violations. To the first point, several states had partial limited expansions prior to 2014. Following \cite{frean2017premium}, these states are California, Connecticut, Minnesota, New Jersey, and Washington. We rerun our analyses excluding CPUMAs from all five of these states. It is unclear how removing these states might affect our estimates: on the one hand, states that expanded early might have a smaller treatment effect after 2014 because they already enrolled newly eligible individuals. On the other hand, if these states were also more motivated to enroll people in Medicaid, they might have larger post-expansion coverage gains. Figure~\ref{fig:weightsbystatec2} displays the H-SBW weights summed by state alongside BC-HSBW. We again see that the BC-HSBW estimator extrapolates heavily to reduce the imbalances. A complete balance table is available in Appendix D, Table~\ref{tab:baltab1} and Table~\ref{tab:baltab2}.

\begin{figure}
\begin{center}
    \caption{Total weights summed by state, early expansion removed}
    \label{fig:weightsbystatec2}
    \includegraphics[scale=0.6]{01_Plots/weights-by-state-hsbw-c2.png}
\end{center}
\end{figure}

On this dataset we estimate an effect of -2.04 (-3.10, -1.00) using H-SBW weights; BC-HSBW yields an estimate of -2.13 (-3.63, -0.64). While the point estimate of the H-SBW estimator decreases slightly, overall we view this as evidence that our primary point estimates are fairly robust to the exclusion of these states. Table~\ref{tab:confintmainc2} and Table~\ref{tab:secondaryptests} in Appendix E display additional results. 

We also find that our estimates $\hat{\Delta}$ increase in absolute magnitude. Specifically, we find -0.80 (-1.69, 0.09) percentage point decrease for the H-SBW estimator when excluding the Republican governance indicators and a -0.85 (-2.16, 0.46) increase for BC-HSBW. Figure~\ref{fig:repub} displays these differences in the contrasts against those from our primary dataset. On our unadjusted dataset we estimate contrasts of -0.76 (-1.52, -0.01) and -0.69 (-1.90, 0.52). While these confidence intervals mostly contain zero, we find that all individual differences between the leave-one-out-states estimated contrasts are less than zero. These results again are consistent with our hypothesis that factors associated with Republican governance reduce the effect size of Medicaid expansion. Additional results are available in Appendix E, Table~\ref{tab:deltac2}. 

\begin{figure}
\begin{center}
    \caption{Removing Republican Governance Indicators}
    \label{fig:repub}
    \includegraphics[scale=0.6]{01_Plots/repub-diff-c1c2.png}
\end{center}
\end{figure}

We conclude by considering an alternative method to account for positivity violations. To this point we have relied on either (1) retaining a potentially biased estimate from weights that do not provide exact balance, or (2) producing a more model-dependent estimate that relies on extrapolation. Overall we found that the results did not change substantially either way. Here we consider a third option: changing our target estimand. In particular, we consider the overlap average treatment effect (OATE), proposed by \cite{li2018balancing}. This is the treatment effect on the subset of the entire dataset where we have overlap. It is a data-dependent treatment effect, and is not the same as the treatment effect on the untreated; however, we believe that this effect will be more similar to the ETC than the ETT, particularly because there were no Democratic controlled states that did not expand Medicaid. Indeed, after generating overlap weights on our primary dataset we find that across all covariates, the mean average absolute distance from the overlap region to the untreated region is 2.24 and to the treated region is 7.55.\footnote{This distance is calculated on the adjusted dataset. When excluding early expansion states the distance is 2.21 to the untreated and 5.19 to the treated region.} Figure~\ref{fig:oatearea} displays the distance between covariates with greater than one percentage point distance from the overlap region to either the control or treated region. We see that the overlap region is substantially more Republican than the treated region, as expected. This region is also less Hispanic, more white, less rural, and more educated than either the expansion or non-expansion region. Table~\ref{tab:oatedist1} and Table~\ref{tab:oatedist2} in Appendix D show additional statistics on the OATE region versus the treatment and control regions for all covariates.

\begin{figure}
\begin{center}
    \caption{Overlap area compared to treated, untreated regions}
    \label{fig:oateimbalance}
    \includegraphics[scale=0.6]{01_Plots/oate-imbalances.png}
\end{center}
\end{figure}

Figure~\ref{fig:oateimbalance} displays the sum of the weights within each state by treatment group. Ohio, Michigan, and Arkansas, which all expanded Medicaid, are the most heavily weighted states (the weights are standardized within each treatment group to sum to 100). The weights are more evenly dispersed among the non-expansion regions, though Pennsylvania, Missouri, Wisconsin, and Florida are given the most weight. We note that this region is specific to the preferred covariate adjustment; the results are quite similar for the unadjusted and less preferred covariate adjustment and are available in Appendix D, Table ~\ref{tab:oatestateweights}.

\begin{figure}
\begin{center}
    \caption{Overlap weights by state}
    \label{oatearea}
    \includegraphics[scale=0.6]{01_Plots/oate-region-c1-a.png}
\end{center}
\end{figure}

We find similar results to our primary analysis: within the overlap region we estimate a treatment effect -1.74 (-2.35, -1.14) when including all treatment states in our primary analysis, and of -1.89 (-2.47, -1.32) when excluding the early expansion states. The results are quite similar when we use the unadjusted datasets: -1.80 (-2.50, -1.10) on the primary dataset and -1.95 (-2.65, -1.25) when excluding early expansion states. 

We again find a negative difference when comparing an estimate excluding the Republican governance indicators against our primary estimate: specifically, we find that the estimate decreases by -0.90 (-1.09, -0.70) percentage points on the primary dataset and by -0.67 (-0.90, -0.44) percentage points when removing early expansion states. \footnote{Unlike the previous analysis, this contrast is a function of the differences in the weighted covariates among both the treated and control regions. We might expect this contrast to be slightly larger because the overlap treated area will becomes more Democratic and the overlap untreated area becomes Republican relative to when we include all covariates.} Notice that both of these estimates were statistically significant. Moreover, this negative difference in estimated contrasts holds for each excluded state, regardless of whether we conditioned on the adjustment or recalculated it. Additional results are available in Appendix E, Table~\ref{tab:oateconfint} and Table~\ref{tab:oatesensitive}. This result again supports our hypothesis that factors associated with Republican governance drive heterogeneity in the estimated treatment effects.

\section{Discussion}

We estimate that had states that did not expand Medicaid in 2014 instead expanded their programs, they would have seen a -2.00 (-3.59, -0.40) percentage point change in the adult uninsurance rate. Existing estimates place the ETT between -3 and -6 percentage points; these estimates vary depending on the targeted sub-population of interest, the data used, and the modeling approach (see, e.g., \cite{courtemanche2017early}, \cite{kaestner2017effects}, \cite{frean2017premium}). This ETC estimate is therefore closer to zero than these ETT estimates, supporting our original hypothesis that the treatment effect on non-expansion states would be smaller in absolute magnitude. Moreover, we also find suggestive evidence that factors associated with Republican governance may drive this differential. While much of this evidence was statistically insignificant, we believe that the consistency of this finding to many of our modeling specifications supports this hypothesis.

We also make several methodological contributions to the literature on balancing weights. First, we extend the synthetic controls literature to estimate the treatment effect on the controls. The key challenge is that we need to predict treatment response rather than the outcome absent treatment. Unlike when estimating the treatment effect on the treated, we cannot use pre-treatment outcomes to conduct variable selection, run placebo tests, or train our model in some other way. This is a fundamentally more difficult problem that requires greater modeling assumptions. Second, we extend the Stable Balancing Weights objective function for use with hierarchical data and covariates measured with error. We modify the criterion to more evenly disperse the weights across states, and the constraint set to balance on a linear approximation to the true covariate values using regression-calibration techniques (\cite{gleser1992importance}).

Our study's approach also has bearing on estimating and understanding the ETT using a differences-in-differences design when estimating the 2014 effects of Medicaid expansion. If we believe that Republican governance is associated with changes in trends over time, then we need to control for this factor. However, there is likely insufficient overlap to control for these factors without significantly extrapolating from the data. We see that the ETC requires less extrapolation than the ETT with respect to governance, and is therefore in some sense a more estimable quantity.\footnote{We note, however, that the standard parallel trends assumption used to identify the ETT is different to the no unmeasured confounding assumption we made here.} 

More generally, our results also suggest that we should not use estimates of the ETT to make inferences about the ETC. Because almost every outcome of interest is largely mediated through increasing the number of insured individuals, and because we have shown that there is likely treatment effect heterogeneity with respect to governance, projecting findings from an estimate of the ETT to the ETC would lead to inaccurate inferences. For example, \cite{miller2019medicaid} study the effect of Medicaid expansion on mortality. Using their estimate of the ETT they project that had all states expanded Medicaid, 15,600 deaths would have been avoided during their study's time-period. If we believe that the ETT were further away from zero than the ETC, we should expect that this projection is an overestimate. Directly estimating the ETC can therefore also help us better model interesting downstream effects mediated through increasing the number of insured individuals. 

Our results come with three major caveats: (1) we rely on strong parametric assumptions about the outcome model to estimate our causal effect; (2) our identification assumes no unmeasured confounding given the true covariates; (3) our estimated associations between Republican governance and our estimated treatment effect largely fall within our estimated margins of error. 

We conclude by discussing the policy implications of these findings. First, we note that a reduction of adult uninsurance rates by -2.00 percentage points represents approximately a 10 percent reduction in the uninsurance rate among non-expansion states. As observed previously, this estimated treatment effect is closer to zero than corresponding estimates of the ETT (see, e.g., \cite{courtemanche2017early}), and we may therefore expect that downstream effects that move away from zero monotonically with the number of uninsured are also closer to zero than estimates of the ETT. Second, we emphasize that the association we find between Republican governance and the estimated treatment effect is only an association: this finding does not imply, for example, that states with more conservative governments in general deliberately make Medicaid enrollment more difficult relative to Democratic states. As \cite{sommers2012understanding} notes, people may be less likely to enroll in Medicaid in conservative states due to social stigma and/or personal beliefs about the welfare state. Regardless of the true cause, to evaluate the policy implications of this finding, we compare this result against Congress's goal in implementing Medicaid expansion in the 2010 ACA, which was to increase health insurance coverage. Measured against this intent, better federal policies should encourage states to make Medicaid enrollment easier, for example, by making enrollment automatic. 

\section{Conclusion}

This is the first study to directly estimate the foregone coverage expansions of Medicaid expansion on states that did not expand Medicaid in 2014. We also contribute to the methodological literature on synthetic controls by clarifying the assumptions required to use longitudinal data to estimate the ETC rather than the ETT, and to the balancing weights literature more generally by considering the case where we have hierarchical data and covariates measured with error. We estimate that had states that did not expand Medicaid in 2014 done so, they would have seen a -2.00 (-3.59, -0.40) percentage point change in their uninsurance rate. This is substantially closer to zero than existing estimates of the ETT, which range between -3 and -6 percentage points. These estimates are robust to different model specifications and sensitivity analyses examining potential violations of the assumptions of no anticipatory treatment effects and positivity violations.

We also find evidence that Republican governance is associated with estimated effect sizes closer to zero. This association is not statistically significant, but is consistent across our sensitivity analyses. Moreover, it is consistent with existing estimates of the ETT that are also farther away from zero, and the finding that Medicaid take-up rates are lower in Republican-governed states prior to Medicaid expansion in 2014 (\cite{sommers2012understanding}). If the goal of Medicaid expansion is to increase access to insurance for low-income adults, state and federal governments may wish to adopt policies that make Medicaid enrollment automatic, or at least easier.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Single Appendix:                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{appendix}
%\section*{???}%% if no title is needed, leave empty \section*{}.
%\end{appendix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Multiple Appendixes:                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{appendix}

\input{Text_files/proof}

\input{Text_files/summary-tabs}

\input{Text_files/balance-tables}

\input{Text_files/results-tabs}

\end{appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Support information (funding), if any,   %%
%% should be provided in the                %%
%% Acknowledgements section.                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgements}

The authors gratefully acknowledge invaluable advice and comments from Zachary Branson, Dave Choi, Edward Kennedy, Brian Kovak, Akshaya Jha, Lowell Taylor, and Jose Zubizaretta.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Supplementary Material, if any, should   %%
%% be provided in {supplement} environment  %%
%% with title and short description.        %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{supplement}
Analysis programs and supporting materials are available online at github.com/mrubinst757
\end{supplement}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  imsart-nameyear.bst  will be used to                   %%
%%  create a .BBL file for submission.                     %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%  MR numbers will be added by VTeX.                      %%
%%                                                         %%
%%  Use \cite{...} to cite references in text.             %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% if your bibliography is in bibtex format, uncomment commands:
\bibliographystyle{imsart-nameyear} % Style BST file
\bibliography{research.bib}       % Bibliography file (usually '*.bib')

%% or include bibliography directly:
% \begin{thebibliography}{}
% \bibitem[\protect\citeauthoryear{???}{???}]{b1}
% \end{thebibliography}

\end{document}
