The 2010 Affordable Care Act (ACA) required states to expand their Medicaid eligibility requirements by 2014 to offer coverage to all adults with incomes at or below 138 percent of the federal poverty level (FPL). The United States Supreme Court ruled this requirement unconstitutional in 2012, allowing states to decide whether to expand Medicaid coverage. In 2014, twenty-six states and the District of Columbia expanded their Medicaid programs. From 2015 through 2020 an additional twelve states elected to expand their Medicaid programs. This first wave of expansions in 2014 enabled researchers to examine the effects of Medicaid expansion by using expansion states as ``treated'' states and non-expansion states as ``control'' states. 

Medicaid enrollment is not automatic, and Medicaid take-up rates have historically have varied across states. This variation is partly a function of state discretion in administering programs: for example, program outreach, citizenship verification policies, and application processes differ across states (\cite{courtemanche2017early}). While states expanded their eligibility requirements, the number that actually enrolled in Medicaid afterwards is some random number of the total number of eligible individuals. Understanding how Medicaid eligibility expansion actually affected the number of uninsured individuals is therefore an important effect. Existing studies have estimated that Medicaid expansion reduced the number of uninsured adults between three and six percentage points among states that expanded Medicaid. These estimates differed depending on the data used, specific target population, study design, and level of analysis (see, e.g., \cite{kaestner2017effects}, \cite{courtemanche2017early}, \cite{frean2017premium}). However, none of these studies have directly estimated the treatment effect on the controls (ETC). 

We therefore propose to study the effect of 2014 Medicaid expansion on adult uninsurance rates among states that did not expand Medicaid. Moreover, we use approximate balancing weights to estimate this effect (\cite{wang2017minimal}). Approximate balancing weights are a popular estimation method in causal inference. Using simple optimization methods, several recent papers have proposed objectives to generate weights that enforce covariate balance between the treated and control units (see, e.g., \cite{abadie2010synthetic}, \cite{zubizarreta2015stable}). From an applied perspective, there are at least three benefits of this approach: first, it does not require using outcomes in the modeling stage. This mitigates the risk of cherry-picking model specifications. Second, these methods often constrain the weights to be positive, preventing extrapolation from the data and reducing model dependence \cite{zubizarreta2015stable}. Third, the estimates are interpretable: by making the comparison group explicit, it is easy to communicate exactly which units contributed to the counterfactual estimate.

To date most proposed methods in the balancing weights (though not synthetic controls) literature assume two key assumptions: (1) the covariates are measured without error, and (2) the observations are independent. We use data from the American Community Survey (ACS) aggregated to the consistent public use microdata area (CPUMA) level. Because our region-level covariates are estimated from underlying survey data, the sampling variability in the covariate estimates is a form of measurement error that may bias our effect estimates. Moreover, our study uses region-level data that nest within states (the level of treatment assignment). A common assumption in the applied literature is that regions within states contain dependencies that can worsen the efficiency of standard estimation procedures (see, e.g., \cite{cameron2015practitioner}). We therefore use regression calibration techniques to reduce the bias from the estimation error of our covariates \cite{gleser1992importance}. Using the assumed correlation structure outlined in \cite{kloek1981ols}, we modify the stable balancing weights objective to account for potential state-level dependencies in the outcomes. 

Our approach also relates to the ``synthetic controls'' literature. Synthetic controls a popular method in the applied economics literature when studying the effects of policy changes using region-level time series cross-sectional data. The typical estimand in the synthetic controls literature is the treatment effect on the treated (ETT) (\cite{abadie2010synthetic}). By contrast, we consider the problem of estimating the ETC. This treatment effect is often an estimand of substantive interest. For example, \cite{miller2019medicaid} used their estimates of the ETT to predict that had states that did not expand Medicaid done so, they would have seen 15,000 fewer deaths during their study period. However, we cannot in general assume that estimates of the ETT should provide good counterfactual estimates of the ETC. More recently, \cite{born2020lockdowns} estimated the effect a lockdown would have had on Sweden on COVID-19 cases and deaths. While \cite{born2020lockdowns} directly estimate the relevant counterfactual, they follow the traditional synthetic controls approach without noting that they are estimating a different treatment effect than synthetic controls were designed to predict. It is important to estimate the causal estimand of substantive interest, as well as to clarify the assumptions used to estimate this effect. A third contribution of our paper is therefore to clarify a set of assumptions required to appropriately use ``synthetic controls'' to estimate the ETC. One takeaway is that we caution against using pre-treatment outcomes to conduct variable selection. 

The remainder of this paper has the following structure. Section 2 provides an overview of the data and defines the study period, covariates, outcome, and treatment. Section 3 discusses our methods, beginning by defining our target estimand, and then outlining our identification, estimation, and inferential procedures. Section 4 presents our results, sensitivity analyses, and investigation of treatment effect heterogeneity. Section 5 contains a discussion of the policy relevance of our findings, and Section 6 contains a brief summary. The Appendices contain additional materials, including proofs, summary statistics, and additional results.
